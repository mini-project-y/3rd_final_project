{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 'train'과 'val'로 성공적으로 분리되었습니다!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 원본 데이터 디렉터리 및 새로운 디렉터리 경로 설정\n",
    "original_data_dir = \"D:\\ko_food\\한국_음식\"\n",
    "output_dir = \"D:\\ko_food\\한국_음식\"\n",
    "\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "val_dir = os.path.join(output_dir, \"val\")\n",
    "\n",
    "# train/val 디렉터리 생성\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# 데이터 분리 비율 설정\n",
    "val_split = 0.2  # 20% 데이터를 검증 데이터로 분리\n",
    "\n",
    "# 각 대분류(category)의 하위 음식별 데이터를 처리\n",
    "for category in os.listdir(original_data_dir):\n",
    "    category_path = os.path.join(original_data_dir, category)\n",
    "    if not os.path.isdir(category_path):\n",
    "        continue\n",
    "    \n",
    "    for food in os.listdir(category_path):\n",
    "        food_path = os.path.join(category_path, food)\n",
    "        if not os.path.isdir(food_path):\n",
    "            continue\n",
    "        \n",
    "        # 이미지 파일 수집\n",
    "        images = [os.path.join(food_path, img) for img in os.listdir(food_path) if img.endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "        \n",
    "        # train/val로 분리\n",
    "        train_images, val_images = train_test_split(images, test_size=val_split, random_state=42)\n",
    "        \n",
    "        # 각 데이터셋으로 복사\n",
    "        for img_path in train_images:\n",
    "            dest_dir = os.path.join(train_dir, category, food)\n",
    "            os.makedirs(dest_dir, exist_ok=True)\n",
    "            shutil.copy(img_path, dest_dir)\n",
    "        \n",
    "        for img_path in val_images:\n",
    "            dest_dir = os.path.join(val_dir, category, food)\n",
    "            os.makedirs(dest_dir, exist_ok=True)\n",
    "            shutil.copy(img_path, dest_dir)\n",
    "\n",
    "print(\"데이터가 'train'과 'val'로 성공적으로 분리되었습니다!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 32\n",
    "image_size = (224, 224)\n",
    "num_classes = 150\n",
    "learning_rate = 0.001\n",
    "epochs = 25\n",
    "\n",
    "# 데이터 증강 및 변환 설정\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# 데이터 로드\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'D:/ko_food/reduced_음식/train_processed',  # train 경로\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    'D:/ko_food/reduced_음식/val_processed',  # val 경로\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    'D:/ko_food/reduced_음식/test_processed',  # test 경로\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Pre-trained 모델 로드 및 fine-tuning 설정\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # 사전 학습된 레이어 고정\n",
    "\n",
    "# 모델 구성\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # 150 클래스로 설정\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 모델 저장\n",
    "model.save('foodnet_finetuned_model.h5')\n",
    "\n",
    "# 사전 학습된 레이어 미세 조정 (fine-tuning)\n",
    "base_model.trainable = True\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=learning_rate * 0.1),  # 학습률 낮춤\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tuning 학습\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=25,  # 추가 학습 에포크\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 테스트 데이터셋 평가\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 23811 images belonging to 150 classes.\n",
      "Found 5889 images belonging to 150 classes.\n",
      "Found 5889 images belonging to 150 classes.\n",
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Epoch 1/25\n",
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "745/745 [==============================] - 968s 1s/step - loss: 5.0193 - accuracy: 0.0050 - val_loss: 5.0105 - val_accuracy: 0.0073 - lr: 0.0010\n",
      "Epoch 2/25\n",
      "745/745 [==============================] - 748s 1s/step - loss: 5.0118 - accuracy: 0.0068 - val_loss: 5.0212 - val_accuracy: 0.0073 - lr: 0.0010\n",
      "Epoch 3/25\n",
      "745/745 [==============================] - 763s 1s/step - loss: 5.0117 - accuracy: 0.0070 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 0.0010\n",
      "Epoch 4/25\n",
      "745/745 [==============================] - 782s 1s/step - loss: 5.0116 - accuracy: 0.0060 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 0.0010\n",
      "Epoch 5/25\n",
      "745/745 [==============================] - 807s 1s/step - loss: 5.0115 - accuracy: 0.0070 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 0.0010\n",
      "Epoch 6/25\n",
      "745/745 [==============================] - 871s 1s/step - loss: 5.0115 - accuracy: 0.0069 - val_loss: 5.0135 - val_accuracy: 0.0073 - lr: 0.0010\n",
      "Epoch 7/25\n",
      "745/745 [==============================] - 820s 1s/step - loss: 5.0115 - accuracy: 0.0068 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 0.0010\n",
      "Epoch 8/25\n",
      "745/745 [==============================] - 697s 936ms/step - loss: 5.0110 - accuracy: 0.0068 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 5.0000e-04\n",
      "Epoch 9/25\n",
      "745/745 [==============================] - 682s 916ms/step - loss: 5.0110 - accuracy: 0.0071 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 5.0000e-04\n",
      "Epoch 10/25\n",
      "745/745 [==============================] - 684s 918ms/step - loss: 5.0110 - accuracy: 0.0061 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 5.0000e-04\n",
      "Epoch 11/25\n",
      "745/745 [==============================] - 684s 918ms/step - loss: 5.0106 - accuracy: 0.0071 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 2.5000e-04\n",
      "Epoch 12/25\n",
      "745/745 [==============================] - 683s 916ms/step - loss: 5.0106 - accuracy: 0.0074 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 2.5000e-04\n",
      "Epoch 13/25\n",
      "745/745 [==============================] - 682s 915ms/step - loss: 5.0107 - accuracy: 0.0071 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 2.5000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "745/745 [==============================] - 694s 923ms/step - loss: 5.1040 - accuracy: 0.0071 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "745/745 [==============================] - 685s 919ms/step - loss: 5.0486 - accuracy: 0.0079 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "745/745 [==============================] - 685s 919ms/step - loss: 5.0364 - accuracy: 0.0065 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "745/745 [==============================] - 686s 921ms/step - loss: 5.0256 - accuracy: 0.0066 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "745/745 [==============================] - 687s 922ms/step - loss: 5.0224 - accuracy: 0.0076 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 5.0000e-05\n",
      "Epoch 6/10\n",
      "745/745 [==============================] - 684s 919ms/step - loss: 5.0200 - accuracy: 0.0077 - val_loss: 5.0104 - val_accuracy: 0.0073 - lr: 5.0000e-05\n",
      "185/185 [==============================] - 137s 740ms/step - loss: 5.0104 - accuracy: 0.0073\n",
      "Test Accuracy: 0.73%\n",
      "Test Loss: 5.0104\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 32\n",
    "image_size = (224, 224)\n",
    "num_classes = 150\n",
    "learning_rate = 0.001\n",
    "epochs_initial = 25  # 초기 학습 에포크\n",
    "epochs_finetune = 10  # fine-tuning 에포크\n",
    "\n",
    "# 데이터 증강 및 변환 설정 (train 데이터셋에서 val 및 test 데이터셋 분리)\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.3,\n",
    "    validation_split=0.2  # 전체 데이터의 20%를 val/test로 분리\n",
    ")\n",
    "\n",
    "# 데이터 로드\n",
    "data_path = 'D:/ko_food/한국_음식/val_processed'\n",
    "\n",
    "# Train 데이터 생성기 (80% 사용)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',  # 80% 훈련 데이터\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Validation 데이터 생성기 (10% 사용)\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # 20% 중 10%는 val\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Test 데이터 생성기 (나머지 10% 사용, shuffle=False)\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    data_path,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # 동일한 val 데이터를 사용\n",
    "    shuffle=False  # 평가 시 데이터 순서 고정\n",
    ")\n",
    "\n",
    "# Pre-trained 모델 로드 및 초기 설정\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # 사전 학습된 레이어 고정\n",
    "\n",
    "# 모델 구성\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # 150 클래스로 설정\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# EarlyStopping 및 ReduceLROnPlateau 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "# 초기 학습\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs_initial,\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 모델 저장\n",
    "model.save('foodnet_finetuned_model_initial.h5')\n",
    "\n",
    "# 일부 레이어 열기\n",
    "for layer in base_model.layers[:-20]:  # 상위 20개 레이어 제외하고 고정\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[-20:]:  # 상위 20개 레이어만 학습 가능\n",
    "    layer.trainable = True\n",
    "\n",
    "# 모델 재컴파일\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=learning_rate * 0.1),  # 낮은 학습률로 재설정\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Fine-tuning 학습\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs_finetune,\n",
    "    callbacks=[early_stopping, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fine-tuning 후 모델 저장\n",
    "model.save('foodnet_finetuned_model_final.h5')\n",
    "\n",
    "# 테스트 데이터셋 평가\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human-dl-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
