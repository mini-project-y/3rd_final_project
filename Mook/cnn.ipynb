{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# 원본 데이터 경로\n",
    "original_train_dir = \"path/to/original/train\"\n",
    "original_val_dir = \"path/to/original/val\"\n",
    "\n",
    "# 결과 저장 경로\n",
    "output_dir = \"path/to/output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 데이터셋 분할 경로\n",
    "train_output = os.path.join(output_dir, \"train\")\n",
    "val_output = os.path.join(output_dir, \"val\")\n",
    "test_output = os.path.join(output_dir, \"test\")\n",
    "\n",
    "# 각 폴더 생성\n",
    "os.makedirs(train_output, exist_ok=True)\n",
    "os.makedirs(val_output, exist_ok=True)\n",
    "os.makedirs(test_output, exist_ok=True)\n",
    "\n",
    "# 카테고리별로 데이터를 나누는 함수\n",
    "def split_data(input_dir, train_out, val_out, test_out, train_size=600, val_size=100, test_from_train=100):\n",
    "    categories = os.listdir(input_dir)  # 카테고리 폴더 리스트\n",
    "    for category in categories:\n",
    "        category_dir = os.path.join(input_dir, category)\n",
    "        if not os.path.isdir(category_dir):\n",
    "            continue  # 폴더가 아닌 경우 건너뜀\n",
    "\n",
    "        # 저장 폴더 생성\n",
    "        train_cat_dir = os.path.join(train_out, category)\n",
    "        val_cat_dir = os.path.join(val_out, category)\n",
    "        test_cat_dir = os.path.join(test_out, category)\n",
    "        os.makedirs(train_cat_dir, exist_ok=True)\n",
    "        os.makedirs(val_cat_dir, exist_ok=True)\n",
    "        os.makedirs(test_cat_dir, exist_ok=True)\n",
    "\n",
    "        # 이미지 파일 가져오기\n",
    "        images = os.listdir(category_dir)\n",
    "        random.shuffle(images)\n",
    "\n",
    "        # train, val, test 데이터 분리\n",
    "        train_images = images[:train_size]\n",
    "        val_images = images[-val_size:]\n",
    "        test_images = train_images[:test_from_train]\n",
    "\n",
    "        # 파일 복사\n",
    "        for img in train_images:\n",
    "            shutil.copy(os.path.join(category_dir, img), os.path.join(train_cat_dir, img))\n",
    "\n",
    "        for img in val_images:\n",
    "            shutil.copy(os.path.join(category_dir, img), os.path.join(val_cat_dir, img))\n",
    "\n",
    "        for img in test_images:\n",
    "            shutil.copy(os.path.join(category_dir, img), os.path.join(test_cat_dir, img))\n",
    "\n",
    "# train 데이터에서 분할\n",
    "split_data(original_train_dir, train_output, val_output, test_output)\n",
    "\n",
    "print(\"데이터 분할 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 75000 images belonging to 150 classes.\n",
      "Found 15000 images belonging to 150 classes.\n",
      "Found 15000 images belonging to 150 classes.\n",
      "Step 1: Training with Frozen Base Model...\n",
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "171446536/171446536 [==============================] - 15s 0us/step\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "  87/4688 [..............................] - ETA: 1:42:14 - loss: 5.3296 - accuracy: 0.0101"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\PIL\\Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3806/4688 [=======================>......] - ETA: 19:54 - loss: 3.8147 - accuracy: 0.1401"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\PIL\\TiffImagePlugin.py:900: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - ETA: 0s - loss: 3.7221 - accuracy: 0.1521\n",
      "Epoch 1: val_loss improved from inf to 2.51230, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\anaconda3\\envs\\human-dl-env2\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4688/4688 [==============================] - 7615s 2s/step - loss: 3.7221 - accuracy: 0.1521 - val_loss: 2.5123 - val_accuracy: 0.3759 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 3.2380 - accuracy: 0.2173\n",
      "Epoch 2: val_loss improved from 2.51230 to 2.41425, saving model to resnet101_feature_extraction.h5\n",
      "4688/4688 [==============================] - 7534s 2s/step - loss: 3.2380 - accuracy: 0.2173 - val_loss: 2.4143 - val_accuracy: 0.3983 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 3.1839 - accuracy: 0.2270\n",
      "Epoch 3: val_loss improved from 2.41425 to 2.39790, saving model to resnet101_feature_extraction.h5\n",
      "4688/4688 [==============================] - 7538s 2s/step - loss: 3.1839 - accuracy: 0.2270 - val_loss: 2.3979 - val_accuracy: 0.4029 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 3.1841 - accuracy: 0.2305\n",
      "Epoch 4: val_loss did not improve from 2.39790\n",
      "4688/4688 [==============================] - 7543s 2s/step - loss: 3.1841 - accuracy: 0.2305 - val_loss: 2.4238 - val_accuracy: 0.4085 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 3.1838 - accuracy: 0.2310\n",
      "Epoch 5: val_loss did not improve from 2.39790\n",
      "4688/4688 [==============================] - 7530s 2s/step - loss: 3.1838 - accuracy: 0.2310 - val_loss: 2.4260 - val_accuracy: 0.4002 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 3.1873 - accuracy: 0.2312\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 6: val_loss did not improve from 2.39790\n",
      "4688/4688 [==============================] - 7508s 2s/step - loss: 3.1873 - accuracy: 0.2312 - val_loss: 2.4197 - val_accuracy: 0.3989 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 3.0622 - accuracy: 0.2549\n",
      "Epoch 7: val_loss improved from 2.39790 to 2.27333, saving model to resnet101_feature_extraction.h5\n",
      "4688/4688 [==============================] - 7501s 2s/step - loss: 3.0622 - accuracy: 0.2549 - val_loss: 2.2733 - val_accuracy: 0.4382 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 3.0297 - accuracy: 0.2601\n",
      "Epoch 8: val_loss improved from 2.27333 to 2.25269, saving model to resnet101_feature_extraction.h5\n",
      "4688/4688 [==============================] - 7562s 2s/step - loss: 3.0297 - accuracy: 0.2601 - val_loss: 2.2527 - val_accuracy: 0.4379 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 3.0044 - accuracy: 0.2645\n",
      "Epoch 9: val_loss improved from 2.25269 to 2.23364, saving model to resnet101_feature_extraction.h5\n",
      "4688/4688 [==============================] - 7573s 2s/step - loss: 3.0044 - accuracy: 0.2645 - val_loss: 2.2336 - val_accuracy: 0.4504 - lr: 5.0000e-04\n",
      "Epoch 10/10\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 2.9912 - accuracy: 0.2695\n",
      "Epoch 10: val_loss did not improve from 2.23364\n",
      "4688/4688 [==============================] - 7696s 2s/step - loss: 2.9912 - accuracy: 0.2695 - val_loss: 2.2513 - val_accuracy: 0.4525 - lr: 5.0000e-04\n",
      "Step 2: Fine-tuning the Base Model...\n",
      "Epoch 1/20\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 3.0462 - accuracy: 0.3122\n",
      "Epoch 1: val_loss improved from inf to 1.57712, saving model to resnet101_finetuned.h5\n",
      "4688/4688 [==============================] - 9186s 2s/step - loss: 3.0462 - accuracy: 0.3122 - val_loss: 1.5771 - val_accuracy: 0.6075 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 1.6922 - accuracy: 0.5671\n",
      "Epoch 2: val_loss improved from 1.57712 to 1.28144, saving model to resnet101_finetuned.h5\n",
      "4688/4688 [==============================] - 8467s 2s/step - loss: 1.6922 - accuracy: 0.5671 - val_loss: 1.2814 - val_accuracy: 0.6741 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 1.2482 - accuracy: 0.6704\n",
      "Epoch 3: val_loss improved from 1.28144 to 1.21950, saving model to resnet101_finetuned.h5\n",
      "4688/4688 [==============================] - 8443s 2s/step - loss: 1.2482 - accuracy: 0.6704 - val_loss: 1.2195 - val_accuracy: 0.6990 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 0.9634 - accuracy: 0.7372\n",
      "Epoch 4: val_loss improved from 1.21950 to 1.16558, saving model to resnet101_finetuned.h5\n",
      "4688/4688 [==============================] - 8450s 2s/step - loss: 0.9634 - accuracy: 0.7372 - val_loss: 1.1656 - val_accuracy: 0.7118 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.7945\n",
      "Epoch 5: val_loss did not improve from 1.16558\n",
      "4688/4688 [==============================] - 8438s 2s/step - loss: 0.7395 - accuracy: 0.7945 - val_loss: 1.2441 - val_accuracy: 0.7133 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 0.5650 - accuracy: 0.8379\n",
      "Epoch 6: val_loss did not improve from 1.16558\n",
      "4688/4688 [==============================] - 8440s 2s/step - loss: 0.5650 - accuracy: 0.8379 - val_loss: 1.2634 - val_accuracy: 0.7269 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 0.4470 - accuracy: 0.8705\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 7: val_loss did not improve from 1.16558\n",
      "4688/4688 [==============================] - 8388s 2s/step - loss: 0.4470 - accuracy: 0.8705 - val_loss: 1.3387 - val_accuracy: 0.7285 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 0.2396 - accuracy: 0.9293\n",
      "Epoch 8: val_loss did not improve from 1.16558\n",
      "4688/4688 [==============================] - 8940s 2s/step - loss: 0.2396 - accuracy: 0.9293 - val_loss: 1.3135 - val_accuracy: 0.7511 - lr: 5.0000e-05\n",
      "Epoch 9/20\n",
      "4688/4688 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.9499"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_dir2 = \"D:/ko_food/train\"\n",
    "val_dir2 = \"D:/ko_food/val\"\n",
    "test_dir2 = \"D:/ko_food/test\"\n",
    "\n",
    "# 데이터 전처리\n",
    "train_datagen2 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_test_datagen2 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator2 = train_datagen2.flow_from_directory(\n",
    "    train_dir2,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator2 = val_test_datagen2.flow_from_directory(\n",
    "    val_dir2,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator2 = val_test_datagen2.flow_from_directory(\n",
    "    test_dir2,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 사전학습 및 Fine-tuning 모델 정의\n",
    "def create_model(num_classes, fine_tune_at=None):\n",
    "    # 사전학습된 ResNet101 모델 로드\n",
    "    base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # 특정 레이어 이후부터 Fine-tuning 설정\n",
    "    if fine_tune_at is not None:\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "            layer.trainable = False  # 하위 레이어는 고정\n",
    "        for layer in base_model.layers[fine_tune_at:]:\n",
    "            layer.trainable = True  # 상위 레이어는 학습 가능\n",
    "    else:\n",
    "        base_model.trainable = False  # 전체 레이어 고정\n",
    "\n",
    "    # 모델 구성\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.5),  # 과적합 방지용 Dropout\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation='softmax')  # 분류 레이어\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 학습 함수\n",
    "def train_model(train_generator, val_generator, test_generator, num_classes):\n",
    "    # 1단계: Feature Extraction (사전학습 모델 고정)\n",
    "    print(\"Step 1: Training with Frozen Base Model...\")\n",
    "    model = create_model(num_classes, fine_tune_at=None)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "        ModelCheckpoint('resnet101_feature_extraction.h5', save_best_only=True, monitor='val_loss', verbose=1)\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=10,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # 2단계: Fine-tuning (사전학습 모델의 상위 레이어 열기)\n",
    "    print(\"Step 2: Fine-tuning the Base Model...\")\n",
    "    fine_tune_at = -30  # 상위 30개 레이어만 학습 가능\n",
    "    model = create_model(num_classes, fine_tune_at=fine_tune_at)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.0001),  # 낮은 학습률로 설정\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    callbacks[2] = ModelCheckpoint('resnet101_finetuned.h5', save_best_only=True, monitor='val_loss', verbose=1)\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=20,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # 테스트 데이터셋 평가\n",
    "    print(\"\\nEvaluating on the test dataset...\")\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    # 최종 모델 저장\n",
    "    model.save('resnet101_korean_food_final_finetuned.h5')\n",
    "\n",
    "# 학습 실행\n",
    "if __name__ == \"__main__\":\n",
    "    num_classes = 150  # 클래스 수\n",
    "    train_model(train_generator2, val_generator2, test_generator2, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version: 3.8.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Keras Version:\", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 | packaged by Anaconda, Inc. | (main, Jul  5 2023, 19:01:18) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105000 images belonging to 150 classes.\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Step 1: Training with Frozen Base Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\anaconda3\\envs\\final-pj-env\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1102 - loss: 5.5817\n",
      "Epoch 1: val_loss improved from inf to 3.85201, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13184s\u001b[0m 2s/step - accuracy: 0.1103 - loss: 5.5816 - val_accuracy: 0.3329 - val_loss: 3.8520 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1840 - loss: 4.4048\n",
      "Epoch 2: val_loss improved from 3.85201 to 3.74438, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13127s\u001b[0m 2s/step - accuracy: 0.1840 - loss: 4.4048 - val_accuracy: 0.3552 - val_loss: 3.7444 - learning_rate: 9.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1926 - loss: 4.3185\n",
      "Epoch 3: val_loss improved from 3.74438 to 3.70513, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12968s\u001b[0m 2s/step - accuracy: 0.1926 - loss: 4.3185 - val_accuracy: 0.3615 - val_loss: 3.7051 - learning_rate: 9.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1988 - loss: 4.2399\n",
      "Epoch 4: val_loss improved from 3.70513 to 3.68364, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12178s\u001b[0m 2s/step - accuracy: 0.1988 - loss: 4.2399 - val_accuracy: 0.3838 - val_loss: 3.6836 - learning_rate: 8.1000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2005 - loss: 4.2184\n",
      "Epoch 5: val_loss improved from 3.68364 to 3.57802, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12275s\u001b[0m 2s/step - accuracy: 0.2005 - loss: 4.2184 - val_accuracy: 0.3867 - val_loss: 3.5780 - learning_rate: 7.2900e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2072 - loss: 4.1468\n",
      "Epoch 6: val_loss improved from 3.57802 to 3.57800, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12220s\u001b[0m 2s/step - accuracy: 0.2072 - loss: 4.1468 - val_accuracy: 0.3921 - val_loss: 3.5780 - learning_rate: 7.2900e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2119 - loss: 4.1007\n",
      "Epoch 7: val_loss improved from 3.57800 to 3.52686, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12143s\u001b[0m 2s/step - accuracy: 0.2119 - loss: 4.1007 - val_accuracy: 0.4022 - val_loss: 3.5269 - learning_rate: 6.5610e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2155 - loss: 4.0748\n",
      "Epoch 8: val_loss improved from 3.52686 to 3.45628, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12994s\u001b[0m 2s/step - accuracy: 0.2155 - loss: 4.0748 - val_accuracy: 0.4189 - val_loss: 3.4563 - learning_rate: 5.9049e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2197 - loss: 4.0191\n",
      "Epoch 9: val_loss improved from 3.45628 to 3.42800, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13513s\u001b[0m 2s/step - accuracy: 0.2197 - loss: 4.0191 - val_accuracy: 0.4040 - val_loss: 3.4280 - learning_rate: 5.9049e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2275 - loss: 3.9816\n",
      "Epoch 10: val_loss improved from 3.42800 to 3.42474, saving model to resnet101_feature_extraction.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13088s\u001b[0m 2s/step - accuracy: 0.2275 - loss: 3.9816 - val_accuracy: 0.4280 - val_loss: 3.4247 - learning_rate: 5.3144e-04\n",
      "Step 2: Fine-tuning the Base Model...\n",
      "Epoch 1/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3575 - loss: 3.1550\n",
      "Epoch 1: val_loss improved from inf to 1.88434, saving model to resnet101_finetuned.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16017s\u001b[0m 2s/step - accuracy: 0.3575 - loss: 3.1549 - val_accuracy: 0.6348 - val_loss: 1.8843 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5457 - loss: 2.2294\n",
      "Epoch 2: val_loss improved from 1.88434 to 1.64370, saving model to resnet101_finetuned.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15959s\u001b[0m 2s/step - accuracy: 0.5457 - loss: 2.2294 - val_accuracy: 0.6824 - val_loss: 1.6437 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6329 - loss: 1.8846\n",
      "Epoch 3: val_loss improved from 1.64370 to 1.56221, saving model to resnet101_finetuned.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15890s\u001b[0m 2s/step - accuracy: 0.6329 - loss: 1.8846 - val_accuracy: 0.7119 - val_loss: 1.5622 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6967 - loss: 1.6425\n",
      "Epoch 4: val_loss improved from 1.56221 to 1.50069, saving model to resnet101_finetuned.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15868s\u001b[0m 2s/step - accuracy: 0.6967 - loss: 1.6425 - val_accuracy: 0.7314 - val_loss: 1.5007 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7441 - loss: 1.4588\n",
      "Epoch 5: val_loss improved from 1.50069 to 1.48269, saving model to resnet101_finetuned.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15952s\u001b[0m 2s/step - accuracy: 0.7441 - loss: 1.4588 - val_accuracy: 0.7391 - val_loss: 1.4827 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7861 - loss: 1.2996\n",
      "Epoch 6: val_loss did not improve from 1.48269\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16089s\u001b[0m 2s/step - accuracy: 0.7860 - loss: 1.2996 - val_accuracy: 0.7388 - val_loss: 1.5007 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8187 - loss: 1.1693\n",
      "Epoch 7: val_loss improved from 1.48269 to 1.45750, saving model to resnet101_finetuned.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16024s\u001b[0m 2s/step - accuracy: 0.8187 - loss: 1.1693 - val_accuracy: 0.7508 - val_loss: 1.4575 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8480 - loss: 1.0538\n",
      "Epoch 8: val_loss did not improve from 1.45750\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16022s\u001b[0m 2s/step - accuracy: 0.8480 - loss: 1.0538 - val_accuracy: 0.7474 - val_loss: 1.4937 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8696 - loss: 0.9657\n",
      "Epoch 9: val_loss did not improve from 1.45750\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15872s\u001b[0m 2s/step - accuracy: 0.8696 - loss: 0.9657 - val_accuracy: 0.7540 - val_loss: 1.4854 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8911 - loss: 0.8826\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.45750\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15992s\u001b[0m 2s/step - accuracy: 0.8911 - loss: 0.8826 - val_accuracy: 0.7544 - val_loss: 1.4858 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9237 - loss: 0.7403\n",
      "Epoch 11: val_loss improved from 1.45750 to 1.37762, saving model to resnet101_finetuned.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16030s\u001b[0m 2s/step - accuracy: 0.9237 - loss: 0.7403 - val_accuracy: 0.7779 - val_loss: 1.3776 - learning_rate: 5.0000e-05\n",
      "Epoch 12/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9435 - loss: 0.6494\n",
      "Epoch 12: val_loss did not improve from 1.37762\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15969s\u001b[0m 2s/step - accuracy: 0.9435 - loss: 0.6494 - val_accuracy: 0.7759 - val_loss: 1.3981 - learning_rate: 5.0000e-05\n",
      "Epoch 13/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9543 - loss: 0.6005\n",
      "Epoch 13: val_loss did not improve from 1.37762\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15996s\u001b[0m 2s/step - accuracy: 0.9543 - loss: 0.6005 - val_accuracy: 0.7750 - val_loss: 1.3952 - learning_rate: 5.0000e-05\n",
      "Epoch 14/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9614 - loss: 0.5630\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.37762\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15944s\u001b[0m 2s/step - accuracy: 0.9614 - loss: 0.5630 - val_accuracy: 0.7735 - val_loss: 1.4133 - learning_rate: 5.0000e-05\n",
      "Epoch 15/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9703 - loss: 0.5162\n",
      "Epoch 15: val_loss improved from 1.37762 to 1.34233, saving model to resnet101_finetuned.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16263s\u001b[0m 2s/step - accuracy: 0.9703 - loss: 0.5162 - val_accuracy: 0.7850 - val_loss: 1.3423 - learning_rate: 2.5000e-05\n",
      "Epoch 16/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9773 - loss: 0.4771\n",
      "Epoch 16: val_loss did not improve from 1.34233\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16919s\u001b[0m 3s/step - accuracy: 0.9773 - loss: 0.4771 - val_accuracy: 0.7826 - val_loss: 1.3536 - learning_rate: 2.5000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9797 - loss: 0.4577\n",
      "Epoch 17: val_loss improved from 1.34233 to 1.33393, saving model to resnet101_finetuned.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16069s\u001b[0m 2s/step - accuracy: 0.9797 - loss: 0.4577 - val_accuracy: 0.7857 - val_loss: 1.3339 - learning_rate: 2.5000e-05\n",
      "Epoch 18/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9828 - loss: 0.4406\n",
      "Epoch 18: val_loss did not improve from 1.33393\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16296s\u001b[0m 2s/step - accuracy: 0.9828 - loss: 0.4406 - val_accuracy: 0.7819 - val_loss: 1.3431 - learning_rate: 2.5000e-05\n",
      "Epoch 19/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.4283\n",
      "Epoch 19: val_loss did not improve from 1.33393\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16221s\u001b[0m 2s/step - accuracy: 0.9844 - loss: 0.4283 - val_accuracy: 0.7837 - val_loss: 1.3486 - learning_rate: 2.5000e-05\n",
      "Epoch 20/20\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9853 - loss: 0.4145\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.33393\n",
      "\u001b[1m6563/6563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16631s\u001b[0m 3s/step - accuracy: 0.9853 - loss: 0.4145 - val_accuracy: 0.7834 - val_loss: 1.3432 - learning_rate: 2.5000e-05\n",
      "\n",
      "Evaluating on the test dataset...\n",
      "\u001b[1m1313/1313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2349s\u001b[0m 2s/step - accuracy: 0.7774 - loss: 1.3722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.3274\n",
      "Test Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecays\n",
    "\n",
    "# 데이터 경로 설정\n",
    "train_dir2 = \"D:/K_food_for_corab/train\"\n",
    "val_dir2 = \"D:/K_food_for_corab/validation\"\n",
    "test_dir2 = \"D:/K_food_for_corab/test\"\n",
    "\n",
    "# 데이터 생성기 설정 (입력 크기 통일)\n",
    "train_datagen2 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_test_datagen2 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "target_size = (256, 256)  # 입력 크기 통일\n",
    "\n",
    "train_generator2 = train_datagen2.flow_from_directory(\n",
    "    train_dir2,\n",
    "    target_size=target_size,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator2 = val_test_datagen2.flow_from_directory(\n",
    "    val_dir2,\n",
    "    target_size=target_size,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator2 = val_test_datagen2.flow_from_directory(\n",
    "    test_dir2,\n",
    "    target_size=target_size,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# 사전학습 및 Fine-tuning 모델 정의\n",
    "def create_model(num_classes, fine_tune_at=None):\n",
    "    base_model = ResNet101(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "    if fine_tune_at is not None:\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "            layer.trainable = False\n",
    "        for layer in base_model.layers[fine_tune_at:]:\n",
    "            layer.trainable = True\n",
    "    else:\n",
    "        base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.6),\n",
    "        layers.Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        layers.Dropout(0.6),\n",
    "        layers.Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01))\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "# 학습 함수\n",
    "def train_model(train_generator, val_generator, test_generator, num_classes):\n",
    "    # 학습률 스케줄러 정의\n",
    "    lr_schedule = ExponentialDecay(\n",
    "        initial_learning_rate=0.001,\n",
    "        decay_steps=10000,\n",
    "        decay_rate=0.9,\n",
    "        staircase=True\n",
    "    )\n",
    "\n",
    "    # 1단계: Feature Extraction (사전학습 모델 고정)\n",
    "    print(\"Step 1: Training with Frozen Base Model...\")\n",
    "    model = create_model(num_classes, fine_tune_at=None)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=lr_schedule),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "        ModelCheckpoint('resnet101_feature_extraction.h5', save_best_only=True, monitor='val_loss', verbose=1)\n",
    "    ]\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=10,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # 2단계: Fine-tuning (사전학습 모델의 상위 레이어 열기)\n",
    "    print(\"Step 2: Fine-tuning the Base Model...\")\n",
    "    model.layers[0].trainable = True  # Base model 수정 가능 설정\n",
    "    for layer in model.layers[0].layers[:-30]:  # 특정 레이어까지만 고정\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    callbacks[2] = ModelCheckpoint('resnet101_finetuned.h5', save_best_only=True, monitor='val_loss', verbose=1)\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        validation_data=val_generator,\n",
    "        epochs=20,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # 테스트 데이터셋 평가\n",
    "    print(\"\\nEvaluating on the test dataset...\")\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    # 최종 모델 저장\n",
    "    model.save('resnet101_korean_food_final_finetuned.h5')\n",
    "\n",
    "# 학습 실행\n",
    "if __name__ == \"__main__\":\n",
    "    num_classes = 150\n",
    "    train_model(train_generator2, val_generator2, test_generator2, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('resnet101_korean_food_final_finetuned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    }
   ],
   "source": [
    "model.save('model.keras', save_format='keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105000 images belonging to 150 classes.\n",
      "{'가지볶음': 0, '간장게장': 1, '갈비구이': 2, '갈비찜': 3, '갈비탕': 4, '갈치구이': 5, '갈치조림': 6, '감자전': 7, '감자조림': 8, '감자채볶음': 9, '감자탕': 10, '갓김치': 11, '건새우볶음': 12, '경단': 13, '계란국': 14, '계란말이': 15, '계란찜': 16, '계란후라이': 17, '고등어구이': 18, '고등어조림': 19, '고사리나물': 20, '고추장진미채볶음': 21, '고추튀김': 22, '곰탕_설렁탕': 23, '곱창구이': 24, '곱창전골': 25, '과메기': 26, '김밥': 27, '김치볶음밥': 28, '김치전': 29, '김치찌개': 30, '김치찜': 31, '깍두기': 32, '깻잎장아찌': 33, '꼬막찜': 34, '꽁치조림': 35, '꽈리고추무침': 36, '꿀떡': 37, '나박김치': 38, '누룽지': 39, '닭갈비': 40, '닭계장': 41, '닭볶음탕': 42, '더덕구이': 43, '도라지무침': 44, '도토리묵': 45, '동그랑땡': 46, '동태찌개': 47, '된장찌개': 48, '두부김치': 49, '두부조림': 50, '땅콩조림': 51, '떡갈비': 52, '떡국_만두국': 53, '떡꼬치': 54, '떡볶이': 55, '라면': 56, '라볶이': 57, '막국수': 58, '만두': 59, '매운탕': 60, '멍게': 61, '메추리알장조림': 62, '멸치볶음': 63, '무국': 64, '무생채': 65, '물냉면': 66, '물회': 67, '미역국': 68, '미역줄기볶음': 69, '배추김치': 70, '백김치': 71, '보쌈': 72, '부추김치': 73, '북엇국': 74, '불고기': 75, '비빔냉면': 76, '비빔밥': 77, '산낙지': 78, '삼겹살': 79, '삼계탕': 80, '새우볶음밥': 81, '새우튀김': 82, '생선전': 83, '소세지볶음': 84, '송편': 85, '수육': 86, '수정과': 87, '수제비': 88, '숙주나물': 89, '순대': 90, '순두부찌개': 91, '시금치나물': 92, '시래기국': 93, '식혜': 94, '알밥': 95, '애호박볶음': 96, '약과': 97, '약식': 98, '양념게장': 99, '양념치킨': 100, '어묵볶음': 101, '연근조림': 102, '열무국수': 103, '열무김치': 104, '오이소박이': 105, '오징어채볶음': 106, '오징어튀김': 107, '우엉조림': 108, '유부초밥': 109, '육개장': 110, '육회': 111, '잔치국수': 112, '잡곡밥': 113, '잡채': 114, '장어구이': 115, '장조림': 116, '전복죽': 117, '젓갈': 118, '제육볶음': 119, '조개구이': 120, '조기구이': 121, '족발': 122, '주꾸미볶음': 123, '주먹밥': 124, '짜장면': 125, '짬뽕': 126, '쫄면': 127, '찜닭': 128, '총각김치': 129, '추어탕': 130, '칼국수': 131, '코다리조림': 132, '콩국수': 133, '콩나물국': 134, '콩나물무침': 135, '콩자반': 136, '파김치': 137, '파전': 138, '편육': 139, '피자': 140, '한과': 141, '해물찜': 142, '호박전': 143, '호박죽': 144, '홍어무침': 145, '황태구이': 146, '회무침': 147, '후라이드치킨': 148, '훈제오리': 149}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          import ImageDataGenerator\n",
    "\n",
    "data_gen = ImageDataGenerator()\n",
    "train_data = data_gen.flow_from_directory('D:/K_food_for_corab/train')\n",
    "\n",
    "print(train_data.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21000 images belonging to 150 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator2 = val_test_datagen2.flow_from_directory(\n",
    "    test_dir2,\n",
    "    target_size=target_size,\n",
    "    batch_size=16,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# 검증 데이터 경로\n",
    "validation_dir = \"D:/K_food_for_corab/validation\"\n",
    "\n",
    "# 데이터셋 생성 함수\n",
    "def load_images_with_labels(directory, image_size=(256, 256), batch_size=32):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(directory))  # 한글 폴더 이름을 클래스 이름으로 사용\n",
    "    \n",
    "    for label, class_name in enumerate(class_names):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        for file in os.listdir(class_path):\n",
    "            try:\n",
    "                # 이미지 로드 및 크기 조정\n",
    "                img_path = os.path.join(class_path, file)\n",
    "                img = tf.keras.utils.load_img(img_path, target_size=image_size)\n",
    "                img_array = tf.keras.utils.img_to_array(img)\n",
    "                images.append(img_array)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    # 텐서로 변환\n",
    "    images = tf.convert_to_tensor(images)\n",
    "    labels = tf.convert_to_tensor(labels)\n",
    "    return tf.data.Dataset.from_tensor_slices((images, labels)).batch(batch_size), class_names\n",
    "\n",
    "# 검증 데이터셋 로드\n",
    "val_dataset, class_names = load_images_with_labels(validation_dir)\n",
    "print(\"클래스 이름:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-pj-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
