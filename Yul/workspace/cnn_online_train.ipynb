{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tf_keras\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "from tensorflow.keras.mixed_precision import set_global_policy, LossScaleOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 온라인 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계 함수\n",
    "def create_model(input_shape=(256, 256, 3), num_classes=150):\n",
    "    base_model = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Conv1 ~ Conv3 freeze, Conv4 ~ Conv5 학습\n",
    "    for layer in base_model.layers[:143]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in base_model.layers[143:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # 완전 연결층 추가\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)  # 150개의 클래스\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    optimizer = SGD(learning_rate=0.01, momentum=0.9, decay=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정 함수\n",
    "def get_callbacks(model_save_path='D:/Work/3rd_pj/k_food_datasets/model_best.keras'):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    return [early_stopping, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 제너레이터 함수\n",
    "def get_data_generators(dataset_dir, target_size=(256, 256), batch_size=16):\n",
    "    # ImageDataGenerator 설정\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/train\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/validation\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/test\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 및 평가 함수\n",
    "def train_and_evaluate_model(model, train_generator, val_generator, test_generator, \n",
    "                             callbacks, epochs=30, batch_size=16):\n",
    "    # 모델 훈련\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // batch_size,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # 테스트 데이터로 성능 평가\n",
    "    test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 학습 함수\n",
    "def run_training_on_datasets(base_dir, dataset_from, dataset_to, initial_model_path='../model/best_model_with_rn101.keras'):\n",
    "    # 모델이 주어지지 않으면 새로 생성, 또는 기존에 저장된 모델 불러오기\n",
    "    if os.path.exists(initial_model_path):\n",
    "        model = load_model(initial_model_path)  # 기존에 저장된 모델을 불러옴\n",
    "        print(f\"Loaded model from {initial_model_path}\")\n",
    "    else:\n",
    "        model = create_model()  # 처음부터 모델을 새로 생성\n",
    "        print(\"No existing model found, creating a new one.\")\n",
    "\n",
    "    # 지정한 범위 내 데이터셋만 학습\n",
    "    for i in range(dataset_from, dataset_to):\n",
    "        dataset_dir = f\"{base_dir}/dataset{i}\"\n",
    "        \n",
    "        # 모델 저장 경로 (최고 성능 모델을 이 파일에 저장)\n",
    "        model_save_path = initial_model_path  # 경로와 이름을 그대로 사용\n",
    "        \n",
    "        # 콜백 설정\n",
    "        callbacks = get_callbacks(model_save_path)\n",
    "        \n",
    "        # 데이터 제너레이터 생성\n",
    "        train_generator, val_generator, test_generator = get_data_generators(dataset_dir)\n",
    "        \n",
    "        # 모델 훈련 및 성능 평가\n",
    "        test_acc = train_and_evaluate_model(model, train_generator, val_generator, test_generator, callbacks)\n",
    "        \n",
    "        print(f\"Dataset {i} - Test accuracy: {test_acc}\")\n",
    "\n",
    "    return model  # 학습이 끝난 모델을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing model found, creating a new one.\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.0076 - loss: 5.6983\n",
      "Epoch 1: val_loss improved from inf to 4.83258, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6706s\u001b[0m 5s/step - accuracy: 0.0076 - loss: 5.6981 - val_accuracy: 0.0116 - val_loss: 4.8326 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:29\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 4.9045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 4.83258 to 4.83192, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 361ms/step - accuracy: 0.0000e+00 - loss: 4.9045 - val_accuracy: 0.0111 - val_loss: 4.8319 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0145 - loss: 4.8225\n",
      "Epoch 3: val_loss did not improve from 4.83192\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6209s\u001b[0m 5s/step - accuracy: 0.0145 - loss: 4.8224 - val_accuracy: 0.0309 - val_loss: 4.8342 - learning_rate: 0.0100\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:28\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.6935\n",
      "Epoch 4: val_loss did not improve from 4.83192\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 350ms/step - accuracy: 0.0000e+00 - loss: 4.6935 - val_accuracy: 0.0309 - val_loss: 4.8530 - learning_rate: 0.0100\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0260 - loss: 4.4706\n",
      "Epoch 5: val_loss improved from 4.83192 to 4.12353, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6237s\u001b[0m 5s/step - accuracy: 0.0260 - loss: 4.4705 - val_accuracy: 0.0830 - val_loss: 4.1235 - learning_rate: 0.0100\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:15\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.3030\n",
      "Epoch 6: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 350ms/step - accuracy: 0.0000e+00 - loss: 4.3030 - val_accuracy: 0.0810 - val_loss: 4.1308 - learning_rate: 0.0100\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0734 - loss: 4.0419\n",
      "Epoch 7: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6183s\u001b[0m 5s/step - accuracy: 0.0734 - loss: 4.0417 - val_accuracy: 0.1552 - val_loss: 36.2028 - learning_rate: 0.0100\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 4s/step - accuracy: 0.0625 - loss: 4.1591\n",
      "Epoch 8: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 355ms/step - accuracy: 0.0625 - loss: 4.1591 - val_accuracy: 0.1559 - val_loss: 35.8441 - learning_rate: 0.0100\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1770 - loss: 3.3432\n",
      "Epoch 9: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6180s\u001b[0m 5s/step - accuracy: 0.1770 - loss: 3.3432 - val_accuracy: 0.3263 - val_loss: 4.1579 - learning_rate: 0.0100\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:54\u001b[0m 4s/step - accuracy: 0.2500 - loss: 2.7067\n",
      "Epoch 10: val_loss improved from 4.12353 to 4.11211, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 355ms/step - accuracy: 0.2500 - loss: 2.7067 - val_accuracy: 0.3265 - val_loss: 4.1121 - learning_rate: 0.0100\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2465 - loss: 2.9563\n",
      "Epoch 11: val_loss did not improve from 4.11211\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6197s\u001b[0m 5s/step - accuracy: 0.2465 - loss: 2.9563 - val_accuracy: 0.0914 - val_loss: 288.3196 - learning_rate: 0.0100\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:35\u001b[0m 4s/step - accuracy: 0.4375 - loss: 2.5502\n",
      "Epoch 12: val_loss did not improve from 4.11211\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 356ms/step - accuracy: 0.4375 - loss: 2.5502 - val_accuracy: 0.0932 - val_loss: 282.4831 - learning_rate: 0.0100\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2928 - loss: 2.7582\n",
      "Epoch 13: val_loss improved from 4.11211 to 2.06562, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6189s\u001b[0m 5s/step - accuracy: 0.2928 - loss: 2.7582 - val_accuracy: 0.4444 - val_loss: 2.0656 - learning_rate: 0.0100\n",
      "Epoch 14/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:53\u001b[0m 4s/step - accuracy: 0.3125 - loss: 2.3432\n",
      "Epoch 14: val_loss did not improve from 2.06562\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 354ms/step - accuracy: 0.3125 - loss: 2.3432 - val_accuracy: 0.4437 - val_loss: 2.0665 - learning_rate: 0.0100\n",
      "Epoch 15/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3611 - loss: 2.4022\n",
      "Epoch 15: val_loss did not improve from 2.06562\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6192s\u001b[0m 5s/step - accuracy: 0.3611 - loss: 2.4021 - val_accuracy: 0.4824 - val_loss: 2.4574 - learning_rate: 0.0100\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 2s/step - accuracy: 0.4629 - loss: 2.0375\n",
      "Dataset 0 - Test accuracy: 0.4528469741344452\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.2875 - loss: 2.8132\n",
      "Epoch 1: val_loss improved from inf to 1.88420, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6410s\u001b[0m 5s/step - accuracy: 0.2875 - loss: 2.8131 - val_accuracy: 0.4996 - val_loss: 1.8842 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:10\u001b[0m 4s/step - accuracy: 0.2500 - loss: 2.7772\n",
      "Epoch 2: val_loss did not improve from 1.88420\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 362ms/step - accuracy: 0.2500 - loss: 2.7772 - val_accuracy: 0.4973 - val_loss: 1.8853 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001b[1m 779/1312\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m39:29\u001b[0m 4s/step - accuracy: 0.3884 - loss: 2.3034"
     ]
    }
   ],
   "source": [
    "# 첫날 학습\n",
    "best_model_day1 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets', \n",
    "    dataset_from=0, \n",
    "    dataset_to=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3753 - loss: 2.3215\n",
      "Epoch 1: val_loss improved from inf to 1.81550, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6226s\u001b[0m 5s/step - accuracy: 0.3753 - loss: 2.3215 - val_accuracy: 0.5122 - val_loss: 1.8155 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:31\u001b[0m 4s/step - accuracy: 0.5000 - loss: 2.3280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.81550 to 1.81311, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 354ms/step - accuracy: 0.5000 - loss: 2.3280 - val_accuracy: 0.5125 - val_loss: 1.8131 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4507 - loss: 2.0064\n",
      "Epoch 3: val_loss improved from 1.81311 to 1.62616, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.4507 - loss: 2.0064 - val_accuracy: 0.5614 - val_loss: 1.6262 - learning_rate: 0.0100\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:18\u001b[0m 4s/step - accuracy: 0.4375 - loss: 2.1665\n",
      "Epoch 4: val_loss did not improve from 1.62616\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 355ms/step - accuracy: 0.4375 - loss: 2.1665 - val_accuracy: 0.5616 - val_loss: 1.6288 - learning_rate: 0.0100\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5173 - loss: 1.7296\n",
      "Epoch 5: val_loss improved from 1.62616 to 1.62431, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6087s\u001b[0m 5s/step - accuracy: 0.5173 - loss: 1.7296 - val_accuracy: 0.5596 - val_loss: 1.6243 - learning_rate: 0.0100\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:22\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.6187\n",
      "Epoch 6: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 343ms/step - accuracy: 0.5000 - loss: 1.6187 - val_accuracy: 0.5596 - val_loss: 1.6287 - learning_rate: 0.0100\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5669 - loss: 1.4853\n",
      "Epoch 7: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6290s\u001b[0m 5s/step - accuracy: 0.5669 - loss: 1.4854 - val_accuracy: 0.5494 - val_loss: 1.7073 - learning_rate: 0.0100\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:02\u001b[0m 4s/step - accuracy: 0.6875 - loss: 1.2153\n",
      "Epoch 8: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 351ms/step - accuracy: 0.6875 - loss: 1.2153 - val_accuracy: 0.5463 - val_loss: 1.7165 - learning_rate: 0.0100\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6256 - loss: 1.2650\n",
      "Epoch 9: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6209s\u001b[0m 5s/step - accuracy: 0.6256 - loss: 1.2650 - val_accuracy: 0.5576 - val_loss: 1.7150 - learning_rate: 0.0100\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:51\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.3297\n",
      "Epoch 10: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 343ms/step - accuracy: 0.5000 - loss: 1.3297 - val_accuracy: 0.5565 - val_loss: 1.7180 - learning_rate: 0.0100\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7244 - loss: 0.9106\n",
      "Epoch 11: val_loss improved from 1.62431 to 1.61108, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6082s\u001b[0m 5s/step - accuracy: 0.7244 - loss: 0.9106 - val_accuracy: 0.6056 - val_loss: 1.6111 - learning_rate: 0.0050\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:51\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.6271\n",
      "Epoch 12: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.5000 - loss: 1.6271 - val_accuracy: 0.6039 - val_loss: 1.6131 - learning_rate: 0.0050\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7967 - loss: 0.6572\n",
      "Epoch 13: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.7967 - loss: 0.6573 - val_accuracy: 0.5979 - val_loss: 1.7200 - learning_rate: 0.0050\n",
      "Epoch 14/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:09\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.7110\n",
      "Epoch 14: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 343ms/step - accuracy: 0.8125 - loss: 0.7110 - val_accuracy: 0.5985 - val_loss: 1.7185 - learning_rate: 0.0050\n",
      "Epoch 15/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8278 - loss: 0.5445\n",
      "Epoch 15: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6088s\u001b[0m 5s/step - accuracy: 0.8278 - loss: 0.5445 - val_accuracy: 0.5876 - val_loss: 1.8881 - learning_rate: 0.0050\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 2s/step - accuracy: 0.5784 - loss: 1.6641\n",
      "Dataset 1 - Test accuracy: 0.5787366628646851\n"
     ]
    }
   ],
   "source": [
    "# 두번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day2 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=1,\n",
    "    dataset_to=2,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4479 - loss: 2.2937\n",
      "Epoch 1: val_loss improved from inf to 1.37227, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6286s\u001b[0m 5s/step - accuracy: 0.4479 - loss: 2.2935 - val_accuracy: 0.6259 - val_loss: 1.3723 - learning_rate: 0.0050\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:28\u001b[0m 4s/step - accuracy: 0.4375 - loss: 2.9725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 348ms/step - accuracy: 0.4375 - loss: 2.9725 - val_accuracy: 0.6252 - val_loss: 1.3727 - learning_rate: 0.0050\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5715 - loss: 1.5536\n",
      "Epoch 3: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6096s\u001b[0m 5s/step - accuracy: 0.5715 - loss: 1.5536 - val_accuracy: 0.6210 - val_loss: 1.3816 - learning_rate: 0.0050\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:50\u001b[0m 4s/step - accuracy: 0.3125 - loss: 2.3637\n",
      "Epoch 4: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 345ms/step - accuracy: 0.3125 - loss: 2.3637 - val_accuracy: 0.6208 - val_loss: 1.3805 - learning_rate: 0.0050\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6502 - loss: 1.2152\n",
      "Epoch 5: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6053s\u001b[0m 5s/step - accuracy: 0.6502 - loss: 1.2152 - val_accuracy: 0.6161 - val_loss: 1.4329 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:51\u001b[0m 4s/step - accuracy: 0.6250 - loss: 1.6757\n",
      "Epoch 6: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.6250 - loss: 1.6757 - val_accuracy: 0.6172 - val_loss: 1.4319 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7437 - loss: 0.8655\n",
      "Epoch 7: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6228s\u001b[0m 5s/step - accuracy: 0.7437 - loss: 0.8655 - val_accuracy: 0.6426 - val_loss: 1.3994 - learning_rate: 0.0025\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:17\u001b[0m 5s/step - accuracy: 0.6250 - loss: 0.7405\n",
      "Epoch 8: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 383ms/step - accuracy: 0.6250 - loss: 0.7405 - val_accuracy: 0.6430 - val_loss: 1.4002 - learning_rate: 0.0025\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 2s/step - accuracy: 0.6304 - loss: 1.3595\n",
      "Dataset 2 - Test accuracy: 0.6270017623901367\n"
     ]
    }
   ],
   "source": [
    "# 세번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day3 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=2,\n",
    "    dataset_to=3,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4838 - loss: 1.9577\n",
      "Epoch 1: val_loss improved from inf to 1.32763, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6549s\u001b[0m 5s/step - accuracy: 0.4838 - loss: 1.9577 - val_accuracy: 0.6312 - val_loss: 1.3276 - learning_rate: 0.0050\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:18\u001b[0m 4s/step - accuracy: 0.4375 - loss: 1.7730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.32763 to 1.32750, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 354ms/step - accuracy: 0.4375 - loss: 1.7730 - val_accuracy: 0.6306 - val_loss: 1.3275 - learning_rate: 0.0050\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5628 - loss: 1.5639\n",
      "Epoch 3: val_loss improved from 1.32750 to 1.31480, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6692s\u001b[0m 5s/step - accuracy: 0.5628 - loss: 1.5640 - val_accuracy: 0.6346 - val_loss: 1.3148 - learning_rate: 0.0050\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:32\u001b[0m 5s/step - accuracy: 0.5625 - loss: 1.8617\n",
      "Epoch 4: val_loss improved from 1.31480 to 1.31355, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 382ms/step - accuracy: 0.5625 - loss: 1.8617 - val_accuracy: 0.6352 - val_loss: 1.3135 - learning_rate: 0.0050\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6373 - loss: 1.2348\n",
      "Epoch 5: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6413s\u001b[0m 5s/step - accuracy: 0.6373 - loss: 1.2348 - val_accuracy: 0.6123 - val_loss: 1.4146 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:31\u001b[0m 5s/step - accuracy: 0.6250 - loss: 0.9826\n",
      "Epoch 6: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 368ms/step - accuracy: 0.6250 - loss: 0.9826 - val_accuracy: 0.6137 - val_loss: 1.4145 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7008 - loss: 0.9985\n",
      "Epoch 7: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6349s\u001b[0m 5s/step - accuracy: 0.7008 - loss: 0.9985 - val_accuracy: 0.6137 - val_loss: 1.4485 - learning_rate: 0.0050\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:23\u001b[0m 5s/step - accuracy: 0.6875 - loss: 0.8997\n",
      "Epoch 8: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 344ms/step - accuracy: 0.6875 - loss: 0.8997 - val_accuracy: 0.6099 - val_loss: 1.4507 - learning_rate: 0.0050\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7658 - loss: 0.7708\n",
      "Epoch 9: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6076s\u001b[0m 5s/step - accuracy: 0.7658 - loss: 0.7708 - val_accuracy: 0.6008 - val_loss: 1.5466 - learning_rate: 0.0050\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:15\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.7469\n",
      "Epoch 10: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 347ms/step - accuracy: 0.7500 - loss: 0.7469 - val_accuracy: 0.6012 - val_loss: 1.5488 - learning_rate: 0.0025\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8252 - loss: 0.5677\n",
      "Epoch 11: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6070s\u001b[0m 5s/step - accuracy: 0.8252 - loss: 0.5677 - val_accuracy: 0.6383 - val_loss: 1.4237 - learning_rate: 0.0025\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 2s/step - accuracy: 0.6355 - loss: 1.3219\n",
      "Dataset 3 - Test accuracy: 0.6323398351669312\n"
     ]
    }
   ],
   "source": [
    "# 4번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day4 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=3,\n",
    "    dataset_to=4,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5190 - loss: 1.8278\n",
      "Epoch 1: val_loss improved from inf to 1.24370, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6180s\u001b[0m 5s/step - accuracy: 0.5190 - loss: 1.8278 - val_accuracy: 0.6615 - val_loss: 1.2437 - learning_rate: 0.0050\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:34\u001b[0m 4s/step - accuracy: 0.4375 - loss: 1.9475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 1.24370\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.4375 - loss: 1.9475 - val_accuracy: 0.6613 - val_loss: 1.2448 - learning_rate: 0.0050\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5989 - loss: 1.4193\n",
      "Epoch 3: val_loss improved from 1.24370 to 1.22720, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6134s\u001b[0m 5s/step - accuracy: 0.5989 - loss: 1.4193 - val_accuracy: 0.6581 - val_loss: 1.2272 - learning_rate: 0.0050\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:22\u001b[0m 4s/step - accuracy: 0.6250 - loss: 0.9612\n",
      "Epoch 4: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 350ms/step - accuracy: 0.6250 - loss: 0.9612 - val_accuracy: 0.6581 - val_loss: 1.2286 - learning_rate: 0.0050\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6751 - loss: 1.1224\n",
      "Epoch 5: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6122s\u001b[0m 5s/step - accuracy: 0.6751 - loss: 1.1224 - val_accuracy: 0.6446 - val_loss: 1.2865 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:31\u001b[0m 4s/step - accuracy: 0.6250 - loss: 1.4102\n",
      "Epoch 6: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.6250 - loss: 1.4102 - val_accuracy: 0.6435 - val_loss: 1.2889 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7458 - loss: 0.8687\n",
      "Epoch 7: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6123s\u001b[0m 5s/step - accuracy: 0.7458 - loss: 0.8687 - val_accuracy: 0.6479 - val_loss: 1.4055 - learning_rate: 0.0050\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:44\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.5852\n",
      "Epoch 8: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 345ms/step - accuracy: 0.7500 - loss: 0.5852 - val_accuracy: 0.6472 - val_loss: 1.3998 - learning_rate: 0.0050\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8185 - loss: 0.5974\n",
      "Epoch 9: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6110s\u001b[0m 5s/step - accuracy: 0.8185 - loss: 0.5973 - val_accuracy: 0.6628 - val_loss: 1.3402 - learning_rate: 0.0025\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:24\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.2563\n",
      "Epoch 10: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.9375 - loss: 0.2563 - val_accuracy: 0.6630 - val_loss: 1.3408 - learning_rate: 0.0025\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 2s/step - accuracy: 0.6532 - loss: 1.2287\n",
      "Dataset 4 - Test accuracy: 0.6499110460281372\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5582 - loss: 1.6624\n",
      "Epoch 1: val_loss improved from inf to 1.06614, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6180s\u001b[0m 5s/step - accuracy: 0.5582 - loss: 1.6623 - val_accuracy: 0.7046 - val_loss: 1.0661 - learning_rate: 0.0025\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:12\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.6704\n",
      "Epoch 2: val_loss did not improve from 1.06614\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 351ms/step - accuracy: 0.5625 - loss: 1.6704 - val_accuracy: 0.7035 - val_loss: 1.0664 - learning_rate: 0.0025\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6304 - loss: 1.3113\n",
      "Epoch 3: val_loss improved from 1.06614 to 1.02690, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6133s\u001b[0m 5s/step - accuracy: 0.6304 - loss: 1.3113 - val_accuracy: 0.7151 - val_loss: 1.0269 - learning_rate: 0.0025\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:07\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.9041\n",
      "Epoch 4: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.7500 - loss: 0.9041 - val_accuracy: 0.7153 - val_loss: 1.0271 - learning_rate: 0.0025\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6952 - loss: 1.0673\n",
      "Epoch 5: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6170s\u001b[0m 5s/step - accuracy: 0.6952 - loss: 1.0673 - val_accuracy: 0.7113 - val_loss: 1.0454 - learning_rate: 0.0025\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:51\u001b[0m 5s/step - accuracy: 0.6250 - loss: 1.0419\n",
      "Epoch 6: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 347ms/step - accuracy: 0.6250 - loss: 1.0419 - val_accuracy: 0.7106 - val_loss: 1.0464 - learning_rate: 0.0025\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7456 - loss: 0.8663\n",
      "Epoch 7: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6102s\u001b[0m 5s/step - accuracy: 0.7456 - loss: 0.8663 - val_accuracy: 0.7066 - val_loss: 1.0963 - learning_rate: 0.0025\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:46\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6310\n",
      "Epoch 8: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 343ms/step - accuracy: 0.7500 - loss: 0.6310 - val_accuracy: 0.7073 - val_loss: 1.0971 - learning_rate: 0.0025\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8144 - loss: 0.6240\n",
      "Epoch 9: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6109s\u001b[0m 5s/step - accuracy: 0.8144 - loss: 0.6240 - val_accuracy: 0.7117 - val_loss: 1.0786 - learning_rate: 0.0012\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:25\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.7847\n",
      "Epoch 10: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 353ms/step - accuracy: 0.5625 - loss: 1.7847 - val_accuracy: 0.7124 - val_loss: 1.0785 - learning_rate: 0.0012\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 2s/step - accuracy: 0.7040 - loss: 1.0268\n",
      "Dataset 5 - Test accuracy: 0.6977313160896301\n"
     ]
    }
   ],
   "source": [
    "# 5번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day5 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=4,\n",
    "    dataset_to=6,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5965 - loss: 1.5135\n",
      "Epoch 1: val_loss improved from inf to 0.96269, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6129s\u001b[0m 5s/step - accuracy: 0.5965 - loss: 1.5135 - val_accuracy: 0.7260 - val_loss: 0.9627 - learning_rate: 0.0025\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:17\u001b[0m 4s/step - accuracy: 0.5000 - loss: 2.2539\n",
      "Epoch 2: val_loss did not improve from 0.96269\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.5000 - loss: 2.2539 - val_accuracy: 0.7260 - val_loss: 0.9629 - learning_rate: 0.0025\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6685 - loss: 1.1742\n",
      "Epoch 3: val_loss improved from 0.96269 to 0.95593, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6017s\u001b[0m 5s/step - accuracy: 0.6685 - loss: 1.1742 - val_accuracy: 0.7320 - val_loss: 0.9559 - learning_rate: 0.0025\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 4s/step - accuracy: 0.6875 - loss: 0.8449\n",
      "Epoch 4: val_loss improved from 0.95593 to 0.95541, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 347ms/step - accuracy: 0.6875 - loss: 0.8449 - val_accuracy: 0.7322 - val_loss: 0.9554 - learning_rate: 0.0025\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7258 - loss: 0.9246\n",
      "Epoch 5: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6021s\u001b[0m 5s/step - accuracy: 0.7258 - loss: 0.9246 - val_accuracy: 0.7240 - val_loss: 0.9961 - learning_rate: 0.0025\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:40\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4129\n",
      "Epoch 6: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 347ms/step - accuracy: 0.8750 - loss: 0.4129 - val_accuracy: 0.7240 - val_loss: 0.9967 - learning_rate: 0.0025\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7788 - loss: 0.7477\n",
      "Epoch 7: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6015s\u001b[0m 5s/step - accuracy: 0.7788 - loss: 0.7477 - val_accuracy: 0.7293 - val_loss: 1.0039 - learning_rate: 0.0025\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:28\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.5739\n",
      "Epoch 8: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.8125 - loss: 0.5739 - val_accuracy: 0.7293 - val_loss: 1.0043 - learning_rate: 0.0025\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8219 - loss: 0.5659\n",
      "Epoch 9: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6015s\u001b[0m 5s/step - accuracy: 0.8219 - loss: 0.5659 - val_accuracy: 0.7166 - val_loss: 1.0863 - learning_rate: 0.0025\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:55\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4695\n",
      "Epoch 10: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 341ms/step - accuracy: 0.8750 - loss: 0.4695 - val_accuracy: 0.7146 - val_loss: 1.0895 - learning_rate: 0.0012\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8743 - loss: 0.4157\n",
      "Epoch 11: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6035s\u001b[0m 5s/step - accuracy: 0.8743 - loss: 0.4157 - val_accuracy: 0.7233 - val_loss: 1.0669 - learning_rate: 0.0012\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 2s/step - accuracy: 0.7364 - loss: 0.9066\n",
      "Dataset 6 - Test accuracy: 0.7364323735237122\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5870 - loss: 1.5514\n",
      "Epoch 1: val_loss improved from inf to 0.98256, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6094s\u001b[0m 5s/step - accuracy: 0.5870 - loss: 1.5514 - val_accuracy: 0.7260 - val_loss: 0.9826 - learning_rate: 0.0012\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:35\u001b[0m 5s/step - accuracy: 0.6250 - loss: 2.2156\n",
      "Epoch 2: val_loss did not improve from 0.98256\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 340ms/step - accuracy: 0.6250 - loss: 2.2156 - val_accuracy: 0.7246 - val_loss: 0.9827 - learning_rate: 0.0012\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6502 - loss: 1.2657\n",
      "Epoch 3: val_loss improved from 0.98256 to 0.96856, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6032s\u001b[0m 5s/step - accuracy: 0.6502 - loss: 1.2657 - val_accuracy: 0.7273 - val_loss: 0.9686 - learning_rate: 0.0012\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.7102\n",
      "Epoch 4: val_loss improved from 0.96856 to 0.96816, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.5625 - loss: 1.7102 - val_accuracy: 0.7275 - val_loss: 0.9682 - learning_rate: 0.0012\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6938 - loss: 1.0840\n",
      "Epoch 5: val_loss improved from 0.96816 to 0.95314, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6039s\u001b[0m 5s/step - accuracy: 0.6938 - loss: 1.0840 - val_accuracy: 0.7324 - val_loss: 0.9531 - learning_rate: 0.0012\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:46\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.2286\n",
      "Epoch 6: val_loss improved from 0.95314 to 0.95232, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 342ms/step - accuracy: 0.5000 - loss: 1.2286 - val_accuracy: 0.7318 - val_loss: 0.9523 - learning_rate: 0.0012\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7381 - loss: 0.9098\n",
      "Epoch 7: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6008s\u001b[0m 5s/step - accuracy: 0.7381 - loss: 0.9098 - val_accuracy: 0.7351 - val_loss: 0.9675 - learning_rate: 0.0012\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:15\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.9006\n",
      "Epoch 8: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 339ms/step - accuracy: 0.8125 - loss: 0.9006 - val_accuracy: 0.7358 - val_loss: 0.9660 - learning_rate: 0.0012\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7795 - loss: 0.7446\n",
      "Epoch 9: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6004s\u001b[0m 5s/step - accuracy: 0.7795 - loss: 0.7446 - val_accuracy: 0.7200 - val_loss: 1.0399 - learning_rate: 0.0012\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:07\u001b[0m 4s/step - accuracy: 0.6875 - loss: 0.7904\n",
      "Epoch 10: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.6875 - loss: 0.7904 - val_accuracy: 0.7211 - val_loss: 1.0399 - learning_rate: 0.0012\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8224 - loss: 0.5913\n",
      "Epoch 11: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6001s\u001b[0m 5s/step - accuracy: 0.8224 - loss: 0.5914 - val_accuracy: 0.7102 - val_loss: 1.0788 - learning_rate: 0.0012\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:12\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6758\n",
      "Epoch 12: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.7500 - loss: 0.6758 - val_accuracy: 0.7089 - val_loss: 1.0828 - learning_rate: 6.2500e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8698 - loss: 0.4491\n",
      "Epoch 13: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5915s\u001b[0m 5s/step - accuracy: 0.8698 - loss: 0.4491 - val_accuracy: 0.7280 - val_loss: 1.0448 - learning_rate: 6.2500e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 2s/step - accuracy: 0.7303 - loss: 0.9197\n",
      "Dataset 7 - Test accuracy: 0.7333185076713562\n"
     ]
    }
   ],
   "source": [
    "# 6번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day6 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=6,\n",
    "    dataset_to=8,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6155 - loss: 1.4214\n",
      "Epoch 1: val_loss improved from inf to 0.91524, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6065s\u001b[0m 5s/step - accuracy: 0.6155 - loss: 1.4214 - val_accuracy: 0.7335 - val_loss: 0.9152 - learning_rate: 0.0012\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:12\u001b[0m 4s/step - accuracy: 0.5625 - loss: 0.9799\n",
      "Epoch 2: val_loss improved from 0.91524 to 0.91380, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 337ms/step - accuracy: 0.5625 - loss: 0.9799 - val_accuracy: 0.7342 - val_loss: 0.9138 - learning_rate: 0.0012\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6678 - loss: 1.1860\n",
      "Epoch 3: val_loss improved from 0.91380 to 0.90831, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5951s\u001b[0m 5s/step - accuracy: 0.6678 - loss: 1.1860 - val_accuracy: 0.7344 - val_loss: 0.9083 - learning_rate: 0.0012\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:35\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.7118\n",
      "Epoch 4: val_loss improved from 0.90831 to 0.90796, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.5625 - loss: 1.7118 - val_accuracy: 0.7353 - val_loss: 0.9080 - learning_rate: 0.0012\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7236 - loss: 0.9656\n",
      "Epoch 5: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6030s\u001b[0m 5s/step - accuracy: 0.7236 - loss: 0.9656 - val_accuracy: 0.7375 - val_loss: 0.9112 - learning_rate: 0.0012\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:55\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.7175\n",
      "Epoch 6: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 340ms/step - accuracy: 0.8750 - loss: 0.7175 - val_accuracy: 0.7391 - val_loss: 0.9107 - learning_rate: 0.0012\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7694 - loss: 0.7893\n",
      "Epoch 7: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6036s\u001b[0m 5s/step - accuracy: 0.7694 - loss: 0.7894 - val_accuracy: 0.7375 - val_loss: 0.9247 - learning_rate: 0.0012\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:03\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.6214\n",
      "Epoch 8: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.8750 - loss: 0.6214 - val_accuracy: 0.7387 - val_loss: 0.9252 - learning_rate: 0.0012\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8145 - loss: 0.6265\n",
      "Epoch 9: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5936s\u001b[0m 5s/step - accuracy: 0.8145 - loss: 0.6265 - val_accuracy: 0.7320 - val_loss: 0.9747 - learning_rate: 0.0012\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:14\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.3501\n",
      "Epoch 10: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 333ms/step - accuracy: 0.8750 - loss: 0.3501 - val_accuracy: 0.7322 - val_loss: 0.9750 - learning_rate: 6.2500e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8634 - loss: 0.4749\n",
      "Epoch 11: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5900s\u001b[0m 4s/step - accuracy: 0.8634 - loss: 0.4749 - val_accuracy: 0.7398 - val_loss: 0.9673 - learning_rate: 6.2500e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 2s/step - accuracy: 0.7547 - loss: 0.8819\n",
      "Dataset 8 - Test accuracy: 0.7473309636116028\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6499 - loss: 1.2749\n",
      "Epoch 1: val_loss improved from inf to 0.78872, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5989s\u001b[0m 5s/step - accuracy: 0.6499 - loss: 1.2749 - val_accuracy: 0.7680 - val_loss: 0.7887 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:28\u001b[0m 4s/step - accuracy: 0.6875 - loss: 1.5735\n",
      "Epoch 2: val_loss improved from 0.78872 to 0.78713, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 340ms/step - accuracy: 0.6875 - loss: 1.5735 - val_accuracy: 0.7685 - val_loss: 0.7871 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6875 - loss: 1.1323\n",
      "Epoch 3: val_loss improved from 0.78713 to 0.77820, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5957s\u001b[0m 5s/step - accuracy: 0.6875 - loss: 1.1323 - val_accuracy: 0.7700 - val_loss: 0.7782 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:11\u001b[0m 4s/step - accuracy: 0.7500 - loss: 1.2073\n",
      "Epoch 4: val_loss did not improve from 0.77820\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 334ms/step - accuracy: 0.7500 - loss: 1.2073 - val_accuracy: 0.7702 - val_loss: 0.7788 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7158 - loss: 0.9906\n",
      "Epoch 5: val_loss improved from 0.77820 to 0.76484, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5923s\u001b[0m 5s/step - accuracy: 0.7158 - loss: 0.9906 - val_accuracy: 0.7729 - val_loss: 0.7648 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:50\u001b[0m 4s/step - accuracy: 0.6875 - loss: 0.9255\n",
      "Epoch 6: val_loss improved from 0.76484 to 0.76300, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 343ms/step - accuracy: 0.6875 - loss: 0.9255 - val_accuracy: 0.7734 - val_loss: 0.7630 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7487 - loss: 0.8777\n",
      "Epoch 7: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6424s\u001b[0m 5s/step - accuracy: 0.7487 - loss: 0.8777 - val_accuracy: 0.7705 - val_loss: 0.7730 - learning_rate: 6.2500e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:26\u001b[0m 4s/step - accuracy: 0.4375 - loss: 1.2839\n",
      "Epoch 8: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 353ms/step - accuracy: 0.4375 - loss: 1.2839 - val_accuracy: 0.7702 - val_loss: 0.7721 - learning_rate: 6.2500e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7802 - loss: 0.7496\n",
      "Epoch 9: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6560s\u001b[0m 5s/step - accuracy: 0.7802 - loss: 0.7496 - val_accuracy: 0.7682 - val_loss: 0.7893 - learning_rate: 6.2500e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:00\u001b[0m 5s/step - accuracy: 0.7500 - loss: 0.6175\n",
      "Epoch 10: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 382ms/step - accuracy: 0.7500 - loss: 0.6175 - val_accuracy: 0.7685 - val_loss: 0.7898 - learning_rate: 6.2500e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8052 - loss: 0.6558\n",
      "Epoch 11: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6187s\u001b[0m 5s/step - accuracy: 0.8052 - loss: 0.6558 - val_accuracy: 0.7700 - val_loss: 0.7995 - learning_rate: 6.2500e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:04\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.3186\n",
      "Epoch 12: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 361ms/step - accuracy: 0.8750 - loss: 0.3186 - val_accuracy: 0.7707 - val_loss: 0.8001 - learning_rate: 3.1250e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8437 - loss: 0.5482\n",
      "Epoch 13: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6418s\u001b[0m 5s/step - accuracy: 0.8437 - loss: 0.5482 - val_accuracy: 0.7669 - val_loss: 0.8014 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 2s/step - accuracy: 0.7690 - loss: 0.7846\n",
      "Dataset 9 - Test accuracy: 0.7702401876449585\n"
     ]
    }
   ],
   "source": [
    "# 7번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=8,\n",
    "    dataset_to=10,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6224 - loss: 1.3886\n",
      "Epoch 1: val_loss improved from inf to 0.92480, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6415s\u001b[0m 5s/step - accuracy: 0.6224 - loss: 1.3886 - val_accuracy: 0.7411 - val_loss: 0.9248 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:53\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.9614\n",
      "Epoch 2: val_loss improved from 0.92480 to 0.92296, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 353ms/step - accuracy: 0.5625 - loss: 1.9614 - val_accuracy: 0.7418 - val_loss: 0.9230 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6733 - loss: 1.1813\n",
      "Epoch 3: val_loss improved from 0.92296 to 0.91048, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6089s\u001b[0m 5s/step - accuracy: 0.6733 - loss: 1.1813 - val_accuracy: 0.7418 - val_loss: 0.9105 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:38\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.8616\n",
      "Epoch 4: val_loss improved from 0.91048 to 0.90927, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 348ms/step - accuracy: 0.8125 - loss: 0.8616 - val_accuracy: 0.7418 - val_loss: 0.9093 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7124 - loss: 1.0065\n",
      "Epoch 5: val_loss improved from 0.90927 to 0.90107, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6098s\u001b[0m 5s/step - accuracy: 0.7124 - loss: 1.0065 - val_accuracy: 0.7476 - val_loss: 0.9011 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:01\u001b[0m 5s/step - accuracy: 0.6250 - loss: 0.8521\n",
      "Epoch 6: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.6250 - loss: 0.8521 - val_accuracy: 0.7469 - val_loss: 0.9016 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7420 - loss: 0.8837\n",
      "Epoch 7: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6096s\u001b[0m 5s/step - accuracy: 0.7420 - loss: 0.8837 - val_accuracy: 0.7400 - val_loss: 0.9204 - learning_rate: 6.2500e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:20\u001b[0m 5s/step - accuracy: 0.8750 - loss: 0.4177\n",
      "Epoch 8: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 348ms/step - accuracy: 0.8750 - loss: 0.4177 - val_accuracy: 0.7409 - val_loss: 0.9195 - learning_rate: 6.2500e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7808 - loss: 0.7525\n",
      "Epoch 9: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6102s\u001b[0m 5s/step - accuracy: 0.7808 - loss: 0.7525 - val_accuracy: 0.7364 - val_loss: 0.9273 - learning_rate: 6.2500e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:38\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.8019\n",
      "Epoch 10: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 351ms/step - accuracy: 0.7500 - loss: 0.8019 - val_accuracy: 0.7369 - val_loss: 0.9288 - learning_rate: 6.2500e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8163 - loss: 0.6151\n",
      "Epoch 11: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6110s\u001b[0m 5s/step - accuracy: 0.8163 - loss: 0.6151 - val_accuracy: 0.7373 - val_loss: 0.9304 - learning_rate: 3.1250e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:47\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.3962\n",
      "Epoch 12: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.9375 - loss: 0.3962 - val_accuracy: 0.7375 - val_loss: 0.9291 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 2s/step - accuracy: 0.7316 - loss: 0.9292\n",
      "Dataset 0 - Test accuracy: 0.7388790249824524\n"
     ]
    }
   ],
   "source": [
    "# 8번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=0,\n",
    "    dataset_to=1,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7498 - loss: 0.8574\n",
      "Epoch 1: val_loss improved from inf to 0.94312, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6263s\u001b[0m 5s/step - accuracy: 0.7498 - loss: 0.8573 - val_accuracy: 0.7411 - val_loss: 0.9431 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:55\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.9336\n",
      "Epoch 2: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.7500 - loss: 0.9336 - val_accuracy: 0.7413 - val_loss: 0.9433 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8081 - loss: 0.6584\n",
      "Epoch 3: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6127s\u001b[0m 5s/step - accuracy: 0.8081 - loss: 0.6584 - val_accuracy: 0.7329 - val_loss: 0.9729 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:50\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.4767\n",
      "Epoch 4: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 347ms/step - accuracy: 0.9375 - loss: 0.4767 - val_accuracy: 0.7331 - val_loss: 0.9721 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8349 - loss: 0.5611\n",
      "Epoch 5: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6099s\u001b[0m 5s/step - accuracy: 0.8349 - loss: 0.5611 - val_accuracy: 0.7322 - val_loss: 0.9981 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:52\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.8940\n",
      "Epoch 6: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 344ms/step - accuracy: 0.7500 - loss: 0.8940 - val_accuracy: 0.7329 - val_loss: 0.9985 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8607 - loss: 0.4789\n",
      "Epoch 7: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6093s\u001b[0m 5s/step - accuracy: 0.8607 - loss: 0.4788 - val_accuracy: 0.7338 - val_loss: 1.0056 - learning_rate: 3.1250e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:19\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.3969\n",
      "Epoch 8: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.9375 - loss: 0.3969 - val_accuracy: 0.7344 - val_loss: 1.0044 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 2s/step - accuracy: 0.7391 - loss: 0.9222\n",
      "Dataset 1 - Test accuracy: 0.7315391302108765\n"
     ]
    }
   ],
   "source": [
    "# 9번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=1,\n",
    "    dataset_to=2,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6545 - loss: 1.2665\n",
      "Epoch 1: val_loss improved from inf to 0.93930, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6228s\u001b[0m 5s/step - accuracy: 0.6545 - loss: 1.2665 - val_accuracy: 0.7369 - val_loss: 0.9393 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:32\u001b[0m 5s/step - accuracy: 0.6250 - loss: 1.1542\n",
      "Epoch 2: val_loss did not improve from 0.93930\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.6250 - loss: 1.1542 - val_accuracy: 0.7362 - val_loss: 0.9401 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7007 - loss: 1.0596\n",
      "Epoch 3: val_loss improved from 0.93930 to 0.93840, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6153s\u001b[0m 5s/step - accuracy: 0.7007 - loss: 1.0596 - val_accuracy: 0.7391 - val_loss: 0.9384 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:09\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.1254\n",
      "Epoch 4: val_loss improved from 0.93840 to 0.93696, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 351ms/step - accuracy: 0.5625 - loss: 1.1254 - val_accuracy: 0.7389 - val_loss: 0.9370 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7387 - loss: 0.8996\n",
      "Epoch 5: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6080s\u001b[0m 5s/step - accuracy: 0.7387 - loss: 0.8996 - val_accuracy: 0.7371 - val_loss: 0.9477 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:30\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6344\n",
      "Epoch 6: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.7500 - loss: 0.6344 - val_accuracy: 0.7378 - val_loss: 0.9472 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7773 - loss: 0.7678\n",
      "Epoch 7: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6115s\u001b[0m 5s/step - accuracy: 0.7773 - loss: 0.7679 - val_accuracy: 0.7329 - val_loss: 0.9686 - learning_rate: 6.2500e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:51\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.3235\n",
      "Epoch 8: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.9375 - loss: 0.3235 - val_accuracy: 0.7335 - val_loss: 0.9697 - learning_rate: 6.2500e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8029 - loss: 0.6517\n",
      "Epoch 9: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6098s\u001b[0m 5s/step - accuracy: 0.8029 - loss: 0.6517 - val_accuracy: 0.7226 - val_loss: 0.9975 - learning_rate: 6.2500e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:24\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4287\n",
      "Epoch 10: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 344ms/step - accuracy: 0.8750 - loss: 0.4287 - val_accuracy: 0.7222 - val_loss: 0.9967 - learning_rate: 3.1250e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8430 - loss: 0.5202\n",
      "Epoch 11: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6074s\u001b[0m 5s/step - accuracy: 0.8430 - loss: 0.5202 - val_accuracy: 0.7226 - val_loss: 1.0159 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 2s/step - accuracy: 0.7459 - loss: 0.8915\n",
      "Dataset 2 - Test accuracy: 0.7404359579086304\n"
     ]
    }
   ],
   "source": [
    "# 10번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=2,\n",
    "    dataset_to=3,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7710 - loss: 0.7729\n",
      "Epoch 1: val_loss improved from inf to 0.89490, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6454s\u001b[0m 5s/step - accuracy: 0.7710 - loss: 0.7729 - val_accuracy: 0.7424 - val_loss: 0.8949 - learning_rate: 3.9062e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:29\u001b[0m 5s/step - accuracy: 0.8750 - loss: 0.4717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.89490 to 0.89433, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 357ms/step - accuracy: 0.8750 - loss: 0.4717 - val_accuracy: 0.7438 - val_loss: 0.8943 - learning_rate: 3.9062e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7884 - loss: 0.7217\n",
      "Epoch 3: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6386s\u001b[0m 5s/step - accuracy: 0.7884 - loss: 0.7217 - val_accuracy: 0.7444 - val_loss: 0.8967 - learning_rate: 3.9062e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:23\u001b[0m 5s/step - accuracy: 0.8125 - loss: 0.5526\n",
      "Epoch 4: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 372ms/step - accuracy: 0.8125 - loss: 0.5526 - val_accuracy: 0.7447 - val_loss: 0.8952 - learning_rate: 3.9062e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7840 - loss: 0.7209\n",
      "Epoch 5: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6468s\u001b[0m 5s/step - accuracy: 0.7840 - loss: 0.7209 - val_accuracy: 0.7473 - val_loss: 0.9015 - learning_rate: 3.9062e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:28\u001b[0m 5s/step - accuracy: 0.8750 - loss: 0.5420\n",
      "Epoch 6: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 363ms/step - accuracy: 0.8750 - loss: 0.5420 - val_accuracy: 0.7469 - val_loss: 0.9013 - learning_rate: 3.9062e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7961 - loss: 0.6960\n",
      "Epoch 7: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6403s\u001b[0m 5s/step - accuracy: 0.7961 - loss: 0.6960 - val_accuracy: 0.7433 - val_loss: 0.9048 - learning_rate: 3.9062e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:58\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.9318\n",
      "Epoch 8: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 402ms/step - accuracy: 0.8125 - loss: 0.9318 - val_accuracy: 0.7438 - val_loss: 0.9042 - learning_rate: 1.9531e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8051 - loss: 0.6576\n",
      "Epoch 9: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7666s\u001b[0m 6s/step - accuracy: 0.8051 - loss: 0.6576 - val_accuracy: 0.7411 - val_loss: 0.9044 - learning_rate: 1.9531e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59:35\u001b[0m 5s/step - accuracy: 0.6875 - loss: 0.5889\n",
      "Epoch 10: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 422ms/step - accuracy: 0.6875 - loss: 0.5889 - val_accuracy: 0.7420 - val_loss: 0.9044 - learning_rate: 1.9531e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8102 - loss: 0.6513\n",
      "Epoch 11: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7146s\u001b[0m 5s/step - accuracy: 0.8102 - loss: 0.6513 - val_accuracy: 0.7442 - val_loss: 0.9007 - learning_rate: 1.9531e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:06\u001b[0m 5s/step - accuracy: 0.7500 - loss: 0.7896\n",
      "Epoch 12: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 375ms/step - accuracy: 0.7500 - loss: 0.7896 - val_accuracy: 0.7440 - val_loss: 0.9008 - learning_rate: 1.9531e-05\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 2s/step - accuracy: 0.7552 - loss: 0.8923\n",
      "Dataset 0 - Test accuracy: 0.7415480613708496\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8095 - loss: 0.6410\n",
      "Epoch 1: val_loss improved from inf to 0.95901, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6927s\u001b[0m 5s/step - accuracy: 0.8095 - loss: 0.6409 - val_accuracy: 0.7353 - val_loss: 0.9590 - learning_rate: 9.7656e-06\n",
      "Epoch 2/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:45\u001b[0m 5s/step - accuracy: 0.9375 - loss: 0.1869\n",
      "Epoch 2: val_loss improved from 0.95901 to 0.95867, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 400ms/step - accuracy: 0.9375 - loss: 0.1869 - val_accuracy: 0.7355 - val_loss: 0.9587 - learning_rate: 9.7656e-06\n",
      "Epoch 3/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8204 - loss: 0.6135\n",
      "Epoch 3: val_loss did not improve from 0.95867\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6870s\u001b[0m 5s/step - accuracy: 0.8204 - loss: 0.6135 - val_accuracy: 0.7347 - val_loss: 0.9619 - learning_rate: 9.7656e-06\n",
      "Epoch 4/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:09\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6150\n",
      "Epoch 4: val_loss did not improve from 0.95867\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 355ms/step - accuracy: 0.7500 - loss: 0.6150 - val_accuracy: 0.7360 - val_loss: 0.9608 - learning_rate: 9.7656e-06\n",
      "Epoch 5/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8184 - loss: 0.6110\n",
      "Epoch 5: val_loss improved from 0.95867 to 0.95648, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6190s\u001b[0m 5s/step - accuracy: 0.8184 - loss: 0.6110 - val_accuracy: 0.7369 - val_loss: 0.9565 - learning_rate: 9.7656e-06\n",
      "Epoch 6/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:22\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.6789\n",
      "Epoch 6: val_loss did not improve from 0.95648\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.8125 - loss: 0.6789 - val_accuracy: 0.7371 - val_loss: 0.9570 - learning_rate: 9.7656e-06\n",
      "Epoch 7/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8220 - loss: 0.6012\n",
      "Epoch 7: val_loss did not improve from 0.95648\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6117s\u001b[0m 5s/step - accuracy: 0.8220 - loss: 0.6012 - val_accuracy: 0.7329 - val_loss: 0.9593 - learning_rate: 9.7656e-06\n",
      "Epoch 8/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:46\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.9156\n",
      "Epoch 8: val_loss did not improve from 0.95648\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 343ms/step - accuracy: 0.7500 - loss: 0.9156 - val_accuracy: 0.7342 - val_loss: 0.9573 - learning_rate: 9.7656e-06\n",
      "Epoch 9/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8254 - loss: 0.5902\n",
      "Epoch 9: val_loss improved from 0.95648 to 0.95436, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6112s\u001b[0m 5s/step - accuracy: 0.8254 - loss: 0.5902 - val_accuracy: 0.7349 - val_loss: 0.9544 - learning_rate: 9.7656e-06\n",
      "Epoch 10/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:30\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.6295\n",
      "Epoch 10: val_loss improved from 0.95436 to 0.95376, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.8125 - loss: 0.6295 - val_accuracy: 0.7349 - val_loss: 0.9538 - learning_rate: 9.7656e-06\n",
      "Epoch 11/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8216 - loss: 0.5940\n",
      "Epoch 11: val_loss did not improve from 0.95376\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.8216 - loss: 0.5940 - val_accuracy: 0.7369 - val_loss: 0.9549 - learning_rate: 9.7656e-06\n",
      "Epoch 12/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:09\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4559\n",
      "Epoch 12: val_loss did not improve from 0.95376\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.8750 - loss: 0.4559 - val_accuracy: 0.7367 - val_loss: 0.9565 - learning_rate: 9.7656e-06\n",
      "Epoch 13/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8239 - loss: 0.5875\n",
      "Epoch 13: val_loss improved from 0.95376 to 0.95259, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.8239 - loss: 0.5875 - val_accuracy: 0.7395 - val_loss: 0.9526 - learning_rate: 9.7656e-06\n",
      "Epoch 14/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:26\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.5394\n",
      "Epoch 14: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.8125 - loss: 0.5394 - val_accuracy: 0.7387 - val_loss: 0.9551 - learning_rate: 9.7656e-06\n",
      "Epoch 15/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8264 - loss: 0.5778\n",
      "Epoch 15: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6112s\u001b[0m 5s/step - accuracy: 0.8264 - loss: 0.5778 - val_accuracy: 0.7398 - val_loss: 0.9546 - learning_rate: 9.7656e-06\n",
      "Epoch 16/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:12\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.4422\n",
      "Epoch 16: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.7500 - loss: 0.4422 - val_accuracy: 0.7400 - val_loss: 0.9554 - learning_rate: 9.7656e-06\n",
      "Epoch 17/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8254 - loss: 0.5818\n",
      "Epoch 17: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6111s\u001b[0m 5s/step - accuracy: 0.8254 - loss: 0.5818 - val_accuracy: 0.7369 - val_loss: 0.9565 - learning_rate: 9.7656e-06\n",
      "Epoch 18/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:46\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.5332\n",
      "Epoch 18: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.8125 - loss: 0.5332 - val_accuracy: 0.7369 - val_loss: 0.9578 - learning_rate: 9.7656e-06\n",
      "Epoch 19/30\n",
      "\u001b[1m1006/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:14\u001b[0m 4s/step - accuracy: 0.8276 - loss: 0.5753"
     ]
    }
   ],
   "source": [
    "# 11번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day11 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=0,\n",
    "    dataset_to=10,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류를 잘 못하는 클래스 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 약식을 위한 dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 원본 데이터 경로와 생성할 데이터 경로 설정\n",
    "original_dataset_dir = r\"D:\\Work\\all_project\\3rd_final_project\\k_food_for_colab\"    # test: class별 140장\n",
    "test_dataset_dir = r\"D:\\Work\\all_project\\3rd_final_project\\k_food_datasets\\dataset_test\"\n",
    "\n",
    "# 폴더 생성 함수\n",
    "def create_directory_structure(base_dir, class_names):\n",
    "    for split in [\"test\"]:\n",
    "        split_dir = os.path.join(base_dir, split)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        for class_name in class_names:\n",
    "            os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n",
    "\n",
    "# 샘플링 및 파일 복사 함수\n",
    "def sample_and_copy_files(original_dir, target_dir, class_names, sampling_ratios):\n",
    "    for split, ratio in sampling_ratios.items():\n",
    "        for class_name in class_names:\n",
    "            original_class_dir = os.path.join(original_dir, split, class_name)\n",
    "            target_class_dir = os.path.join(target_dir, split, class_name)\n",
    "\n",
    "            # 원본 이미지 리스트 가져오기\n",
    "            all_files = os.listdir(original_class_dir)\n",
    "            sampled_files = random.sample(all_files, int(len(all_files) * ratio))\n",
    "\n",
    "            # 파일 복사\n",
    "            for file_name in sampled_files:\n",
    "                src = os.path.join(original_class_dir, file_name)\n",
    "                dst = os.path.join(target_class_dir, file_name)\n",
    "                shutil.copy(src, dst)\n",
    "\n",
    "# 메인 함수\n",
    "def create_mini_dataset(original_dir, mini_dir, sampling_ratio=0.4):\n",
    "    # 10% : 14, 20% : 28, 30% : 42, 40% : 56, 50% : 70, 60% : 84, 70% : 98, 80% : 112, 90% : 126\n",
    "\n",
    "    # 클래스 이름 추출 (test 폴더 기준)\n",
    "    class_names = os.listdir(os.path.join(original_dir, \"test\"))\n",
    "\n",
    "    # 새로운 데이터셋 폴더 구조 생성\n",
    "    create_directory_structure(mini_dir, class_names)\n",
    "\n",
    "    # 샘플링 비율 설정 (train, test, validation 각각 10%)\n",
    "    sampling_ratios = {\"test\": sampling_ratio}\n",
    "\n",
    "    # 데이터 복사 및 샘플링\n",
    "    sample_and_copy_files(original_dir, mini_dir, class_names, sampling_ratios)\n",
    "    print(f\"Mini dataset created at {mini_dir}\")\n",
    "\n",
    "# 실행\n",
    "create_mini_dataset(original_dataset_dir, test_dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 경로\n",
    "model_path = r\"D:\\Work\\all_project\\3rd_final_project\\3rd_final_project\\Yul\\model\\best_model_with_rn101.keras\"\n",
    "\n",
    "# 모델 불러오기\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4500 images belonging to 150 classes.\n",
      "Test generator prepared!!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "\n",
    "# 미니 데이터셋 경로\n",
    "test_dataset_dir = \"D:/Work/all_project/3rd_final_project/k_food_datasets/dataset0\"\n",
    "\n",
    "# 데이터 제너레이터 설정\n",
    "def get_test_generator(dataset_dir, target_size=(256, 256), batch_size=16):\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/test\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False  # 순서를 고정하여 클래스별 매핑이 유지되도록 설정\n",
    "    )\n",
    "    return test_generator\n",
    "\n",
    "# Test 데이터 로드\n",
    "test_generator = get_test_generator(test_dataset_dir)\n",
    "print(\"Test generator prepared!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        가지볶음     0.5758    0.6333    0.6032        30\n",
      "        간장게장     0.7419    0.7667    0.7541        30\n",
      "        갈비구이     0.4000    0.4000    0.4000        30\n",
      "         갈비찜     0.7500    0.7000    0.7241        30\n",
      "         갈비탕     0.6970    0.7667    0.7302        30\n",
      "        갈치구이     0.8750    0.7000    0.7778        30\n",
      "        갈치조림     0.6316    0.4000    0.4898        30\n",
      "         감자전     0.7273    0.5333    0.6154        30\n",
      "        감자조림     0.7857    0.7333    0.7586        30\n",
      "       감자채볶음     0.9355    0.9667    0.9508        30\n",
      "         감자탕     0.7037    0.6333    0.6667        30\n",
      "         갓김치     0.8077    0.7000    0.7500        30\n",
      "       건새우볶음     0.8621    0.8333    0.8475        30\n",
      "          경단     0.9259    0.8333    0.8772        30\n",
      "         계란국     0.7500    0.7000    0.7241        30\n",
      "        계란말이     0.7857    0.7333    0.7586        30\n",
      "         계란찜     0.8438    0.9000    0.8710        30\n",
      "       계란후라이     0.9062    0.9667    0.9355        30\n",
      "       고등어구이     0.6341    0.8667    0.7324        30\n",
      "       고등어조림     0.2703    0.3333    0.2985        30\n",
      "       고사리나물     0.8286    0.9667    0.8923        30\n",
      "    고추장진미채볶음     0.4359    0.5667    0.4928        30\n",
      "        고추튀김     0.7931    0.7667    0.7797        30\n",
      "      곰탕_설렁탕     0.8333    0.6667    0.7407        30\n",
      "        곱창구이     0.8065    0.8333    0.8197        30\n",
      "        곱창전골     0.5000    0.4667    0.4828        30\n",
      "         과메기     0.9355    0.9667    0.9508        30\n",
      "          김밥     0.9375    1.0000    0.9677        30\n",
      "       김치볶음밥     0.7742    0.8000    0.7869        30\n",
      "         김치전     0.7097    0.7333    0.7213        30\n",
      "        김치찌개     0.6296    0.5667    0.5965        30\n",
      "         김치찜     0.4762    0.6667    0.5556        30\n",
      "         깍두기     0.8333    0.8333    0.8333        30\n",
      "       깻잎장아찌     0.9200    0.7667    0.8364        30\n",
      "         꼬막찜     1.0000    0.8333    0.9091        30\n",
      "        꽁치조림     0.7273    0.5333    0.6154        30\n",
      "      꽈리고추무침     0.8929    0.8333    0.8621        30\n",
      "          꿀떡     0.8621    0.8333    0.8475        30\n",
      "        나박김치     0.8667    0.8667    0.8667        30\n",
      "         누룽지     0.7826    0.6000    0.6792        30\n",
      "         닭갈비     0.6471    0.7333    0.6875        30\n",
      "         닭계장     0.5714    0.6667    0.6154        30\n",
      "        닭볶음탕     0.7647    0.8667    0.8125        30\n",
      "        더덕구이     0.8750    0.7000    0.7778        30\n",
      "       도라지무침     0.6800    0.5667    0.6182        30\n",
      "        도토리묵     0.7500    0.7000    0.7241        30\n",
      "        동그랑땡     0.8462    0.7333    0.7857        30\n",
      "        동태찌개     0.3889    0.4667    0.4242        30\n",
      "        된장찌개     0.7500    0.7000    0.7241        30\n",
      "        두부김치     0.8750    0.9333    0.9032        30\n",
      "        두부조림     0.7083    0.5667    0.6296        30\n",
      "        땅콩조림     0.8750    0.9333    0.9032        30\n",
      "         떡갈비     0.8000    0.8000    0.8000        30\n",
      "      떡국_만두국     0.6061    0.6667    0.6349        30\n",
      "         떡꼬치     0.7812    0.8333    0.8065        30\n",
      "         떡볶이     0.6957    0.5333    0.6038        30\n",
      "          라면     0.8077    0.7000    0.7500        30\n",
      "         라볶이     0.7742    0.8000    0.7869        30\n",
      "         막국수     0.8400    0.7000    0.7636        30\n",
      "          만두     0.8462    0.7333    0.7857        30\n",
      "         매운탕     0.3462    0.3000    0.3214        30\n",
      "          멍게     0.5000    0.6000    0.5455        30\n",
      "     메추리알장조림     0.8077    0.7000    0.7500        30\n",
      "        멸치볶음     0.8400    0.7000    0.7636        30\n",
      "          무국     0.6857    0.8000    0.7385        30\n",
      "         무생채     0.7419    0.7667    0.7541        30\n",
      "         물냉면     0.8065    0.8333    0.8197        30\n",
      "          물회     0.7407    0.6667    0.7018        30\n",
      "         미역국     0.9000    0.9000    0.9000        30\n",
      "      미역줄기볶음     1.0000    0.9333    0.9655        30\n",
      "        배추김치     0.8077    0.7000    0.7500        30\n",
      "         백김치     0.8710    0.9000    0.8852        30\n",
      "          보쌈     0.6333    0.6333    0.6333        30\n",
      "        부추김치     0.6842    0.8667    0.7647        30\n",
      "         북엇국     0.7742    0.8000    0.7869        30\n",
      "         불고기     0.6154    0.5333    0.5714        30\n",
      "        비빔냉면     0.8387    0.8667    0.8525        30\n",
      "         비빔밥     0.6000    0.7000    0.6462        30\n",
      "         산낙지     0.7742    0.8000    0.7869        30\n",
      "         삼겹살     0.7500    0.7000    0.7241        30\n",
      "         삼계탕     0.7778    0.7000    0.7368        30\n",
      "       새우볶음밥     0.8333    1.0000    0.9091        30\n",
      "        새우튀김     0.6538    0.5667    0.6071        30\n",
      "         생선전     0.6970    0.7667    0.7302        30\n",
      "       소세지볶음     0.6944    0.8333    0.7576        30\n",
      "          송편     0.7576    0.8333    0.7937        30\n",
      "          수육     0.5588    0.6333    0.5938        30\n",
      "         수정과     0.9655    0.9333    0.9492        30\n",
      "         수제비     0.5769    0.5000    0.5357        30\n",
      "        숙주나물     0.8333    0.8333    0.8333        30\n",
      "          순대     0.8261    0.6333    0.7170        30\n",
      "       순두부찌개     0.6452    0.6667    0.6557        30\n",
      "       시금치나물     0.9091    1.0000    0.9524        30\n",
      "        시래기국     0.7188    0.7667    0.7419        30\n",
      "          식혜     0.8529    0.9667    0.9062        30\n",
      "          알밥     0.9583    0.7667    0.8519        30\n",
      "       애호박볶음     0.9667    0.9667    0.9667        30\n",
      "          약과     0.7429    0.8667    0.8000        30\n",
      "          약식     0.8571    0.8000    0.8276        30\n",
      "        양념게장     0.7586    0.7333    0.7458        30\n",
      "        양념치킨     0.6216    0.7667    0.6866        30\n",
      "        어묵볶음     0.6875    0.7333    0.7097        30\n",
      "        연근조림     1.0000    0.9667    0.9831        30\n",
      "        열무국수     0.8065    0.8333    0.8197        30\n",
      "        열무김치     0.9500    0.6333    0.7600        30\n",
      "       오이소박이     0.9091    1.0000    0.9524        30\n",
      "      오징어채볶음     0.3333    0.2667    0.2963        30\n",
      "       오징어튀김     0.4595    0.5667    0.5075        30\n",
      "        우엉조림     0.9130    0.7000    0.7925        30\n",
      "        유부초밥     0.8387    0.8667    0.8525        30\n",
      "         육개장     0.4828    0.4667    0.4746        30\n",
      "          육회     0.7879    0.8667    0.8254        30\n",
      "        잔치국수     0.7931    0.7667    0.7797        30\n",
      "         잡곡밥     0.8788    0.9667    0.9206        30\n",
      "          잡채     0.8125    0.8667    0.8387        30\n",
      "        장어구이     0.7619    0.5333    0.6275        30\n",
      "         장조림     0.7667    0.7667    0.7667        30\n",
      "         전복죽     0.8750    0.9333    0.9032        30\n",
      "          젓갈     0.5238    0.7333    0.6111        30\n",
      "        제육볶음     0.4762    0.6667    0.5556        30\n",
      "        조개구이     0.8529    0.9667    0.9062        30\n",
      "        조기구이     0.9615    0.8333    0.8929        30\n",
      "          족발     0.7419    0.7667    0.7541        30\n",
      "       주꾸미볶음     0.4390    0.6000    0.5070        30\n",
      "         주먹밥     0.8621    0.8333    0.8475        30\n",
      "         짜장면     0.9200    0.7667    0.8364        30\n",
      "          짬뽕     0.9259    0.8333    0.8772        30\n",
      "          쫄면     0.7667    0.7667    0.7667        30\n",
      "          찜닭     0.8276    0.8000    0.8136        30\n",
      "        총각김치     0.8235    0.9333    0.8750        30\n",
      "         추어탕     0.8235    0.4667    0.5957        30\n",
      "         칼국수     0.6176    0.7000    0.6562        30\n",
      "       코다리조림     0.4194    0.4333    0.4262        30\n",
      "         콩국수     0.8966    0.8667    0.8814        30\n",
      "        콩나물국     0.6923    0.6000    0.6429        30\n",
      "       콩나물무침     0.9231    0.8000    0.8571        30\n",
      "         콩자반     0.9310    0.9000    0.9153        30\n",
      "         파김치     0.7812    0.8333    0.8065        30\n",
      "          파전     0.8387    0.8667    0.8525        30\n",
      "          편육     0.4583    0.3667    0.4074        30\n",
      "          피자     0.7632    0.9667    0.8529        30\n",
      "          한과     0.9677    1.0000    0.9836        30\n",
      "         해물찜     0.5882    0.6667    0.6250        30\n",
      "         호박전     0.6857    0.8000    0.7385        30\n",
      "         호박죽     0.9655    0.9333    0.9492        30\n",
      "        홍어무침     0.6154    0.5333    0.5714        30\n",
      "        황태구이     0.5385    0.7000    0.6087        30\n",
      "         회무침     0.5926    0.5333    0.5614        30\n",
      "      후라이드치킨     0.9355    0.9667    0.9508        30\n",
      "        훈제오리     0.5938    0.6333    0.6129        30\n",
      "\n",
      "    accuracy                         0.7438      4500\n",
      "   macro avg     0.7518    0.7438    0.7436      4500\n",
      "weighted avg     0.7518    0.7438    0.7436      4500\n",
      "\n",
      "Confusion Matrix:\n",
      " [[19  1  0 ...  0  0  0]\n",
      " [ 1 23  0 ...  0  0  0]\n",
      " [ 1  0 12 ...  0  0  3]\n",
      " ...\n",
      " [ 0  0  0 ... 16  0  0]\n",
      " [ 0  0  0 ...  0 29  0]\n",
      " [ 0  0  0 ...  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 모델로 예측 수행\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 예측 클래스\n",
    "y_true = test_generator.classes             # 실제 클래스\n",
    "\n",
    "# 클래스 이름 가져오기\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# 분류 보고서 생성\n",
    "report = classification_report(y_true, y_pred_classes, target_names=class_labels, digits=4)\n",
    "print(report)\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report 분석\n",
    "import pandas as pd\n",
    "\n",
    "# Report 문자열을 DataFrame으로 변환\n",
    "report_dict = classification_report(y_true, y_pred_classes, target_names=class_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes with the lowest F1-scores:\n",
      "           precision    recall  f1-score  support\n",
      "오징어채볶음     0.333333  0.266667  0.296296     30.0\n",
      "고등어조림      0.270270  0.333333  0.298507     30.0\n",
      "매운탕        0.346154  0.300000  0.321429     30.0\n",
      "갈비구이       0.400000  0.400000  0.400000     30.0\n",
      "편육         0.458333  0.366667  0.407407     30.0\n",
      "동태찌개       0.388889  0.466667  0.424242     30.0\n",
      "코다리조림      0.419355  0.433333  0.426230     30.0\n",
      "육개장        0.482759  0.466667  0.474576     30.0\n",
      "곱창전골       0.500000  0.466667  0.482759     30.0\n",
      "갈치조림       0.631579  0.400000  0.489796     30.0\n",
      "고추장진미채볶음   0.435897  0.566667  0.492754     30.0\n",
      "주꾸미볶음      0.439024  0.600000  0.507042     30.0\n",
      "오징어튀김      0.459459  0.566667  0.507463     30.0\n",
      "수제비        0.576923  0.500000  0.535714     30.0\n",
      "멍게         0.500000  0.600000  0.545455     30.0\n",
      "제육볶음       0.476190  0.666667  0.555556     30.0\n",
      "김치찜        0.476190  0.666667  0.555556     30.0\n",
      "회무침        0.592593  0.533333  0.561404     30.0\n",
      "홍어무침       0.615385  0.533333  0.571429     30.0\n",
      "불고기        0.615385  0.533333  0.571429     30.0\n",
      "수육         0.558824  0.633333  0.593750     30.0\n",
      "추어탕        0.823529  0.466667  0.595745     30.0\n",
      "김치찌개       0.629630  0.566667  0.596491     30.0\n",
      "가지볶음       0.575758  0.633333  0.603175     30.0\n",
      "떡볶이        0.695652  0.533333  0.603774     30.0\n",
      "새우튀김       0.653846  0.566667  0.607143     30.0\n",
      "황태구이       0.538462  0.700000  0.608696     30.0\n",
      "젓갈         0.523810  0.733333  0.611111     30.0\n",
      "훈제오리       0.593750  0.633333  0.612903     30.0\n",
      "닭계장        0.571429  0.666667  0.615385     30.0\n",
      "꽁치조림       0.727273  0.533333  0.615385     30.0\n",
      "감자전        0.727273  0.533333  0.615385     30.0\n",
      "도라지무침      0.680000  0.566667  0.618182     30.0\n",
      "해물찜        0.588235  0.666667  0.625000     30.0\n",
      "장어구이       0.761905  0.533333  0.627451     30.0\n",
      "두부조림       0.708333  0.566667  0.629630     30.0\n",
      "보쌈         0.633333  0.633333  0.633333     30.0\n",
      "떡국_만두국     0.606061  0.666667  0.634921     30.0\n",
      "콩나물국       0.692308  0.600000  0.642857     30.0\n",
      "비빔밥        0.600000  0.700000  0.646154     30.0\n",
      "순두부찌개      0.645161  0.666667  0.655738     30.0\n",
      "칼국수        0.617647  0.700000  0.656250     30.0\n",
      "감자탕        0.703704  0.633333  0.666667     30.0\n",
      "누룽지        0.782609  0.600000  0.679245     30.0\n",
      "양념치킨       0.621622  0.766667  0.686567     30.0\n"
     ]
    }
   ],
   "source": [
    "# F1-Score 기반 정렬\n",
    "low_f1_classes = report_df.sort_values(\"f1-score\").head(45)  # F1-Score 하위 10개 클래스\n",
    "print(\"Classes with the lowest F1-scores:\\n\", low_f1_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes with the lowest Recall:\n",
      "           precision    recall  f1-score  support\n",
      "오징어채볶음     0.333333  0.266667  0.296296     30.0\n",
      "매운탕        0.346154  0.300000  0.321429     30.0\n",
      "고등어조림      0.270270  0.333333  0.298507     30.0\n",
      "편육         0.458333  0.366667  0.407407     30.0\n",
      "갈비구이       0.400000  0.400000  0.400000     30.0\n",
      "갈치조림       0.631579  0.400000  0.489796     30.0\n",
      "코다리조림      0.419355  0.433333  0.426230     30.0\n",
      "육개장        0.482759  0.466667  0.474576     30.0\n",
      "동태찌개       0.388889  0.466667  0.424242     30.0\n",
      "곱창전골       0.500000  0.466667  0.482759     30.0\n",
      "추어탕        0.823529  0.466667  0.595745     30.0\n",
      "수제비        0.576923  0.500000  0.535714     30.0\n",
      "홍어무침       0.615385  0.533333  0.571429     30.0\n",
      "장어구이       0.761905  0.533333  0.627451     30.0\n",
      "감자전        0.727273  0.533333  0.615385     30.0\n",
      "불고기        0.615385  0.533333  0.571429     30.0\n",
      "꽁치조림       0.727273  0.533333  0.615385     30.0\n",
      "떡볶이        0.695652  0.533333  0.603774     30.0\n",
      "회무침        0.592593  0.533333  0.561404     30.0\n",
      "고추장진미채볶음   0.435897  0.566667  0.492754     30.0\n",
      "오징어튀김      0.459459  0.566667  0.507463     30.0\n",
      "김치찌개       0.629630  0.566667  0.596491     30.0\n",
      "두부조림       0.708333  0.566667  0.629630     30.0\n",
      "새우튀김       0.653846  0.566667  0.607143     30.0\n",
      "도라지무침      0.680000  0.566667  0.618182     30.0\n",
      "누룽지        0.782609  0.600000  0.679245     30.0\n",
      "주꾸미볶음      0.439024  0.600000  0.507042     30.0\n",
      "멍게         0.500000  0.600000  0.545455     30.0\n",
      "콩나물국       0.692308  0.600000  0.642857     30.0\n",
      "열무김치       0.950000  0.633333  0.760000     30.0\n",
      "순대         0.826087  0.633333  0.716981     30.0\n",
      "수육         0.558824  0.633333  0.593750     30.0\n",
      "가지볶음       0.575758  0.633333  0.603175     30.0\n",
      "보쌈         0.633333  0.633333  0.633333     30.0\n",
      "감자탕        0.703704  0.633333  0.666667     30.0\n",
      "훈제오리       0.593750  0.633333  0.612903     30.0\n",
      "순두부찌개      0.645161  0.666667  0.655738     30.0\n",
      "김치찜        0.476190  0.666667  0.555556     30.0\n",
      "닭계장        0.571429  0.666667  0.615385     30.0\n",
      "떡국_만두국     0.606061  0.666667  0.634921     30.0\n",
      "물회         0.740741  0.666667  0.701754     30.0\n",
      "곰탕_설렁탕     0.833333  0.666667  0.740741     30.0\n",
      "제육볶음       0.476190  0.666667  0.555556     30.0\n",
      "해물찜        0.588235  0.666667  0.625000     30.0\n",
      "삼겹살        0.750000  0.700000  0.724138     30.0\n"
     ]
    }
   ],
   "source": [
    "low_recall_classes = report_df.sort_values(by=\"recall\").head(45)  # Recall 하위 10개 클래스\n",
    "print(\"Classes with the lowest Recall:\\n\", low_recall_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most misclassified classes:\n",
      "       class  misclassified\n",
      "106  오징어채볶음             22\n",
      "60      매운탕             21\n",
      "19    고등어조림             20\n",
      "139      편육             19\n",
      "2      갈비구이             18\n",
      "6      갈치조림             18\n",
      "132   코다리조림             17\n",
      "47     동태찌개             16\n",
      "130     추어탕             16\n",
      "25     곱창전골             16\n",
      "110     육개장             16\n",
      "88      수제비             15\n",
      "55      떡볶이             14\n",
      "35     꽁치조림             14\n",
      "75      불고기             14\n",
      "7       감자전             14\n",
      "145    홍어무침             14\n",
      "147     회무침             14\n",
      "115    장어구이             14\n",
      "107   오징어튀김             13\n"
     ]
    }
   ],
   "source": [
    "# 각 클래스에서 잘못 예측된 횟수 계산\n",
    "misclass_counts = np.sum(conf_matrix, axis=1) - np.diag(conf_matrix)\n",
    "\n",
    "# 가장 많이 오분류된 클래스 상위 10개\n",
    "most_misclassified = pd.DataFrame({\n",
    "    \"class\": class_labels,\n",
    "    \"misclassified\": misclass_counts\n",
    "}).sort_values(by=\"misclassified\", ascending=False).head(20)\n",
    "\n",
    "print(\"Most misclassified classes:\\n\", most_misclassified)\n",
    "# 140장 증강 (20%) 총 840장 : 오징어채볶음, 매운탕, 고등어조림, 편육, 갈비구이, 갈치조림\n",
    "# 105장 증강 (15%) 총 805장 : 코다리조림, 동태찌개, 추어탕, 곱창전골, 육개장, 수제비\n",
    "# 70장 증강 (10%) 총 770장 : 떡볶이, 꽁치조림, 불고기, 감자전, 홍어무침, 회무침, 장어구이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis results saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# 분석 결과 저장\n",
    "report_df.to_csv(\"classification_report.csv\", index=True)\n",
    "most_misclassified.to_csv(\"misclassified_classes.csv\", index=False)\n",
    "\n",
    "print(\"Analysis results saved to CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일부러 불균형으로 만든 데이터 셋으로 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106960 images belonging to 150 classes.\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 21000 images belonging to 150 classes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 경로 설정\n",
    "train_dir = \"../../../K_food_for_colab(불균형으로 만듦)/train\"\n",
    "val_dir = \"../../../K_food_for_colab(불균형으로 만듦)/validation\"\n",
    "test_dir = \"../../../K_food_for_colab(불균형으로 만듦)/test\"\n",
    "\n",
    "# 데이터 전처리 (이미지 증강 없이)\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 경로\n",
    "model_path = r\"D:\\Work\\all_project\\3rd_final_project\\3rd_final_project\\Yul\\model\\best_model_with_rn101.keras\"\n",
    "\n",
    "# 모델 불러오기\n",
    "loaded_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 옵티마이저 변경\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "loaded_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = '../model/best_model_adam.keras'\n",
    "# 콜백 설정 함수\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "callbacks = [early_stopping, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# 모델 훈련\n",
    "histroy = model.fit(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // batch_size,\n",
    "                    epochs=70,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.samples // batch_size,\n",
    "                    callbacks=callbacks\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터로 성능 평가\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['accuracy'], label='train_accuracy', c='blue')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'], label='validation_accuracy', c='skyblue', marker='o')\n",
    "plt.plot(history.epoch, history.history['loss'], label='train_loss', c='orange')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='validation_loss', c='salmon', marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
