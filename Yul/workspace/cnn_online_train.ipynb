{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tf_keras\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "from tensorflow.keras.mixed_precision import set_global_policy, LossScaleOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 온라인 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계 함수\n",
    "def create_model(input_shape=(256, 256, 3), num_classes=150):\n",
    "    base_model = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Conv1 ~ Conv3 freeze, Conv4 ~ Conv5 학습\n",
    "    for layer in base_model.layers[:143]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in base_model.layers[143:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # 완전 연결층 추가\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)  # 150개의 클래스\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    optimizer = SGD(learning_rate=0.01, momentum=0.9, decay=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정 함수\n",
    "def get_callbacks(model_save_path='D:/Work/3rd_pj/k_food_datasets/model_best.keras'):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    return [early_stopping, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 제너레이터 함수\n",
    "def get_data_generators(dataset_dir, target_size=(256, 256), batch_size=16):\n",
    "    # ImageDataGenerator 설정\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/train\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/validation\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/test\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 및 평가 함수\n",
    "def train_and_evaluate_model(model, train_generator, val_generator, test_generator, \n",
    "                             callbacks, epochs=30, batch_size=16):\n",
    "    # 모델 훈련\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // batch_size,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # 테스트 데이터로 성능 평가\n",
    "    test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 학습 함수\n",
    "def run_training_on_datasets(base_dir, dataset_from, dataset_to, initial_model_path='../model/best_model_with_rn101.keras'):\n",
    "    # 모델이 주어지지 않으면 새로 생성, 또는 기존에 저장된 모델 불러오기\n",
    "    if os.path.exists(initial_model_path):\n",
    "        model = load_model(initial_model_path)  # 기존에 저장된 모델을 불러옴\n",
    "        print(f\"Loaded model from {initial_model_path}\")\n",
    "    else:\n",
    "        model = create_model()  # 처음부터 모델을 새로 생성\n",
    "        print(\"No existing model found, creating a new one.\")\n",
    "\n",
    "    # 지정한 범위 내 데이터셋만 학습\n",
    "    for i in range(dataset_from, dataset_to):\n",
    "        dataset_dir = f\"{base_dir}/dataset{i}\"\n",
    "        \n",
    "        # 모델 저장 경로 (최고 성능 모델을 이 파일에 저장)\n",
    "        model_save_path = initial_model_path  # 경로와 이름을 그대로 사용\n",
    "        \n",
    "        # 콜백 설정\n",
    "        callbacks = get_callbacks(model_save_path)\n",
    "        \n",
    "        # 데이터 제너레이터 생성\n",
    "        train_generator, val_generator, test_generator = get_data_generators(dataset_dir)\n",
    "        \n",
    "        # 모델 훈련 및 성능 평가\n",
    "        test_acc = train_and_evaluate_model(model, train_generator, val_generator, test_generator, callbacks)\n",
    "        \n",
    "        print(f\"Dataset {i} - Test accuracy: {test_acc}\")\n",
    "\n",
    "    return model  # 학습이 끝난 모델을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing model found, creating a new one.\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.0076 - loss: 5.6983\n",
      "Epoch 1: val_loss improved from inf to 4.83258, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6706s\u001b[0m 5s/step - accuracy: 0.0076 - loss: 5.6981 - val_accuracy: 0.0116 - val_loss: 4.8326 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:29\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 4.9045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 4.83258 to 4.83192, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 361ms/step - accuracy: 0.0000e+00 - loss: 4.9045 - val_accuracy: 0.0111 - val_loss: 4.8319 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0145 - loss: 4.8225\n",
      "Epoch 3: val_loss did not improve from 4.83192\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6209s\u001b[0m 5s/step - accuracy: 0.0145 - loss: 4.8224 - val_accuracy: 0.0309 - val_loss: 4.8342 - learning_rate: 0.0100\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:28\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.6935\n",
      "Epoch 4: val_loss did not improve from 4.83192\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 350ms/step - accuracy: 0.0000e+00 - loss: 4.6935 - val_accuracy: 0.0309 - val_loss: 4.8530 - learning_rate: 0.0100\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0260 - loss: 4.4706\n",
      "Epoch 5: val_loss improved from 4.83192 to 4.12353, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6237s\u001b[0m 5s/step - accuracy: 0.0260 - loss: 4.4705 - val_accuracy: 0.0830 - val_loss: 4.1235 - learning_rate: 0.0100\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:15\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.3030\n",
      "Epoch 6: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 350ms/step - accuracy: 0.0000e+00 - loss: 4.3030 - val_accuracy: 0.0810 - val_loss: 4.1308 - learning_rate: 0.0100\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0734 - loss: 4.0419\n",
      "Epoch 7: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6183s\u001b[0m 5s/step - accuracy: 0.0734 - loss: 4.0417 - val_accuracy: 0.1552 - val_loss: 36.2028 - learning_rate: 0.0100\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 4s/step - accuracy: 0.0625 - loss: 4.1591\n",
      "Epoch 8: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 355ms/step - accuracy: 0.0625 - loss: 4.1591 - val_accuracy: 0.1559 - val_loss: 35.8441 - learning_rate: 0.0100\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1770 - loss: 3.3432\n",
      "Epoch 9: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6180s\u001b[0m 5s/step - accuracy: 0.1770 - loss: 3.3432 - val_accuracy: 0.3263 - val_loss: 4.1579 - learning_rate: 0.0100\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:54\u001b[0m 4s/step - accuracy: 0.2500 - loss: 2.7067\n",
      "Epoch 10: val_loss improved from 4.12353 to 4.11211, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 355ms/step - accuracy: 0.2500 - loss: 2.7067 - val_accuracy: 0.3265 - val_loss: 4.1121 - learning_rate: 0.0100\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2465 - loss: 2.9563\n",
      "Epoch 11: val_loss did not improve from 4.11211\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6197s\u001b[0m 5s/step - accuracy: 0.2465 - loss: 2.9563 - val_accuracy: 0.0914 - val_loss: 288.3196 - learning_rate: 0.0100\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:35\u001b[0m 4s/step - accuracy: 0.4375 - loss: 2.5502\n",
      "Epoch 12: val_loss did not improve from 4.11211\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 356ms/step - accuracy: 0.4375 - loss: 2.5502 - val_accuracy: 0.0932 - val_loss: 282.4831 - learning_rate: 0.0100\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2928 - loss: 2.7582\n",
      "Epoch 13: val_loss improved from 4.11211 to 2.06562, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6189s\u001b[0m 5s/step - accuracy: 0.2928 - loss: 2.7582 - val_accuracy: 0.4444 - val_loss: 2.0656 - learning_rate: 0.0100\n",
      "Epoch 14/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:53\u001b[0m 4s/step - accuracy: 0.3125 - loss: 2.3432\n",
      "Epoch 14: val_loss did not improve from 2.06562\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 354ms/step - accuracy: 0.3125 - loss: 2.3432 - val_accuracy: 0.4437 - val_loss: 2.0665 - learning_rate: 0.0100\n",
      "Epoch 15/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3611 - loss: 2.4022\n",
      "Epoch 15: val_loss did not improve from 2.06562\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6192s\u001b[0m 5s/step - accuracy: 0.3611 - loss: 2.4021 - val_accuracy: 0.4824 - val_loss: 2.4574 - learning_rate: 0.0100\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 2s/step - accuracy: 0.4629 - loss: 2.0375\n",
      "Dataset 0 - Test accuracy: 0.4528469741344452\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.2875 - loss: 2.8132\n",
      "Epoch 1: val_loss improved from inf to 1.88420, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6410s\u001b[0m 5s/step - accuracy: 0.2875 - loss: 2.8131 - val_accuracy: 0.4996 - val_loss: 1.8842 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:10\u001b[0m 4s/step - accuracy: 0.2500 - loss: 2.7772\n",
      "Epoch 2: val_loss did not improve from 1.88420\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 362ms/step - accuracy: 0.2500 - loss: 2.7772 - val_accuracy: 0.4973 - val_loss: 1.8853 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001b[1m 779/1312\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m39:29\u001b[0m 4s/step - accuracy: 0.3884 - loss: 2.3034"
     ]
    }
   ],
   "source": [
    "# 첫날 학습\n",
    "best_model_day1 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets', \n",
    "    dataset_from=0, \n",
    "    dataset_to=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3753 - loss: 2.3215\n",
      "Epoch 1: val_loss improved from inf to 1.81550, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6226s\u001b[0m 5s/step - accuracy: 0.3753 - loss: 2.3215 - val_accuracy: 0.5122 - val_loss: 1.8155 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:31\u001b[0m 4s/step - accuracy: 0.5000 - loss: 2.3280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.81550 to 1.81311, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 354ms/step - accuracy: 0.5000 - loss: 2.3280 - val_accuracy: 0.5125 - val_loss: 1.8131 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4507 - loss: 2.0064\n",
      "Epoch 3: val_loss improved from 1.81311 to 1.62616, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.4507 - loss: 2.0064 - val_accuracy: 0.5614 - val_loss: 1.6262 - learning_rate: 0.0100\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:18\u001b[0m 4s/step - accuracy: 0.4375 - loss: 2.1665\n",
      "Epoch 4: val_loss did not improve from 1.62616\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 355ms/step - accuracy: 0.4375 - loss: 2.1665 - val_accuracy: 0.5616 - val_loss: 1.6288 - learning_rate: 0.0100\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5173 - loss: 1.7296\n",
      "Epoch 5: val_loss improved from 1.62616 to 1.62431, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6087s\u001b[0m 5s/step - accuracy: 0.5173 - loss: 1.7296 - val_accuracy: 0.5596 - val_loss: 1.6243 - learning_rate: 0.0100\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:22\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.6187\n",
      "Epoch 6: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 343ms/step - accuracy: 0.5000 - loss: 1.6187 - val_accuracy: 0.5596 - val_loss: 1.6287 - learning_rate: 0.0100\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5669 - loss: 1.4853\n",
      "Epoch 7: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6290s\u001b[0m 5s/step - accuracy: 0.5669 - loss: 1.4854 - val_accuracy: 0.5494 - val_loss: 1.7073 - learning_rate: 0.0100\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:02\u001b[0m 4s/step - accuracy: 0.6875 - loss: 1.2153\n",
      "Epoch 8: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 351ms/step - accuracy: 0.6875 - loss: 1.2153 - val_accuracy: 0.5463 - val_loss: 1.7165 - learning_rate: 0.0100\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6256 - loss: 1.2650\n",
      "Epoch 9: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6209s\u001b[0m 5s/step - accuracy: 0.6256 - loss: 1.2650 - val_accuracy: 0.5576 - val_loss: 1.7150 - learning_rate: 0.0100\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:51\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.3297\n",
      "Epoch 10: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 343ms/step - accuracy: 0.5000 - loss: 1.3297 - val_accuracy: 0.5565 - val_loss: 1.7180 - learning_rate: 0.0100\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7244 - loss: 0.9106\n",
      "Epoch 11: val_loss improved from 1.62431 to 1.61108, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6082s\u001b[0m 5s/step - accuracy: 0.7244 - loss: 0.9106 - val_accuracy: 0.6056 - val_loss: 1.6111 - learning_rate: 0.0050\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:51\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.6271\n",
      "Epoch 12: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.5000 - loss: 1.6271 - val_accuracy: 0.6039 - val_loss: 1.6131 - learning_rate: 0.0050\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7967 - loss: 0.6572\n",
      "Epoch 13: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.7967 - loss: 0.6573 - val_accuracy: 0.5979 - val_loss: 1.7200 - learning_rate: 0.0050\n",
      "Epoch 14/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:09\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.7110\n",
      "Epoch 14: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 343ms/step - accuracy: 0.8125 - loss: 0.7110 - val_accuracy: 0.5985 - val_loss: 1.7185 - learning_rate: 0.0050\n",
      "Epoch 15/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8278 - loss: 0.5445\n",
      "Epoch 15: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6088s\u001b[0m 5s/step - accuracy: 0.8278 - loss: 0.5445 - val_accuracy: 0.5876 - val_loss: 1.8881 - learning_rate: 0.0050\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 2s/step - accuracy: 0.5784 - loss: 1.6641\n",
      "Dataset 1 - Test accuracy: 0.5787366628646851\n"
     ]
    }
   ],
   "source": [
    "# 두번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day2 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=1,\n",
    "    dataset_to=2,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4479 - loss: 2.2937\n",
      "Epoch 1: val_loss improved from inf to 1.37227, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6286s\u001b[0m 5s/step - accuracy: 0.4479 - loss: 2.2935 - val_accuracy: 0.6259 - val_loss: 1.3723 - learning_rate: 0.0050\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:28\u001b[0m 4s/step - accuracy: 0.4375 - loss: 2.9725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 348ms/step - accuracy: 0.4375 - loss: 2.9725 - val_accuracy: 0.6252 - val_loss: 1.3727 - learning_rate: 0.0050\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5715 - loss: 1.5536\n",
      "Epoch 3: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6096s\u001b[0m 5s/step - accuracy: 0.5715 - loss: 1.5536 - val_accuracy: 0.6210 - val_loss: 1.3816 - learning_rate: 0.0050\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:50\u001b[0m 4s/step - accuracy: 0.3125 - loss: 2.3637\n",
      "Epoch 4: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 345ms/step - accuracy: 0.3125 - loss: 2.3637 - val_accuracy: 0.6208 - val_loss: 1.3805 - learning_rate: 0.0050\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6502 - loss: 1.2152\n",
      "Epoch 5: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6053s\u001b[0m 5s/step - accuracy: 0.6502 - loss: 1.2152 - val_accuracy: 0.6161 - val_loss: 1.4329 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:51\u001b[0m 4s/step - accuracy: 0.6250 - loss: 1.6757\n",
      "Epoch 6: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.6250 - loss: 1.6757 - val_accuracy: 0.6172 - val_loss: 1.4319 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7437 - loss: 0.8655\n",
      "Epoch 7: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6228s\u001b[0m 5s/step - accuracy: 0.7437 - loss: 0.8655 - val_accuracy: 0.6426 - val_loss: 1.3994 - learning_rate: 0.0025\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:17\u001b[0m 5s/step - accuracy: 0.6250 - loss: 0.7405\n",
      "Epoch 8: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 383ms/step - accuracy: 0.6250 - loss: 0.7405 - val_accuracy: 0.6430 - val_loss: 1.4002 - learning_rate: 0.0025\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 2s/step - accuracy: 0.6304 - loss: 1.3595\n",
      "Dataset 2 - Test accuracy: 0.6270017623901367\n"
     ]
    }
   ],
   "source": [
    "# 세번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day3 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=2,\n",
    "    dataset_to=3,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4838 - loss: 1.9577\n",
      "Epoch 1: val_loss improved from inf to 1.32763, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6549s\u001b[0m 5s/step - accuracy: 0.4838 - loss: 1.9577 - val_accuracy: 0.6312 - val_loss: 1.3276 - learning_rate: 0.0050\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:18\u001b[0m 4s/step - accuracy: 0.4375 - loss: 1.7730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.32763 to 1.32750, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 354ms/step - accuracy: 0.4375 - loss: 1.7730 - val_accuracy: 0.6306 - val_loss: 1.3275 - learning_rate: 0.0050\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5628 - loss: 1.5639\n",
      "Epoch 3: val_loss improved from 1.32750 to 1.31480, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6692s\u001b[0m 5s/step - accuracy: 0.5628 - loss: 1.5640 - val_accuracy: 0.6346 - val_loss: 1.3148 - learning_rate: 0.0050\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:32\u001b[0m 5s/step - accuracy: 0.5625 - loss: 1.8617\n",
      "Epoch 4: val_loss improved from 1.31480 to 1.31355, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 382ms/step - accuracy: 0.5625 - loss: 1.8617 - val_accuracy: 0.6352 - val_loss: 1.3135 - learning_rate: 0.0050\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6373 - loss: 1.2348\n",
      "Epoch 5: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6413s\u001b[0m 5s/step - accuracy: 0.6373 - loss: 1.2348 - val_accuracy: 0.6123 - val_loss: 1.4146 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:31\u001b[0m 5s/step - accuracy: 0.6250 - loss: 0.9826\n",
      "Epoch 6: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 368ms/step - accuracy: 0.6250 - loss: 0.9826 - val_accuracy: 0.6137 - val_loss: 1.4145 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7008 - loss: 0.9985\n",
      "Epoch 7: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6349s\u001b[0m 5s/step - accuracy: 0.7008 - loss: 0.9985 - val_accuracy: 0.6137 - val_loss: 1.4485 - learning_rate: 0.0050\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:23\u001b[0m 5s/step - accuracy: 0.6875 - loss: 0.8997\n",
      "Epoch 8: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 344ms/step - accuracy: 0.6875 - loss: 0.8997 - val_accuracy: 0.6099 - val_loss: 1.4507 - learning_rate: 0.0050\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7658 - loss: 0.7708\n",
      "Epoch 9: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6076s\u001b[0m 5s/step - accuracy: 0.7658 - loss: 0.7708 - val_accuracy: 0.6008 - val_loss: 1.5466 - learning_rate: 0.0050\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:15\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.7469\n",
      "Epoch 10: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 347ms/step - accuracy: 0.7500 - loss: 0.7469 - val_accuracy: 0.6012 - val_loss: 1.5488 - learning_rate: 0.0025\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8252 - loss: 0.5677\n",
      "Epoch 11: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6070s\u001b[0m 5s/step - accuracy: 0.8252 - loss: 0.5677 - val_accuracy: 0.6383 - val_loss: 1.4237 - learning_rate: 0.0025\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 2s/step - accuracy: 0.6355 - loss: 1.3219\n",
      "Dataset 3 - Test accuracy: 0.6323398351669312\n"
     ]
    }
   ],
   "source": [
    "# 4번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day4 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=3,\n",
    "    dataset_to=4,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5190 - loss: 1.8278\n",
      "Epoch 1: val_loss improved from inf to 1.24370, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6180s\u001b[0m 5s/step - accuracy: 0.5190 - loss: 1.8278 - val_accuracy: 0.6615 - val_loss: 1.2437 - learning_rate: 0.0050\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:34\u001b[0m 4s/step - accuracy: 0.4375 - loss: 1.9475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 1.24370\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.4375 - loss: 1.9475 - val_accuracy: 0.6613 - val_loss: 1.2448 - learning_rate: 0.0050\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5989 - loss: 1.4193\n",
      "Epoch 3: val_loss improved from 1.24370 to 1.22720, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6134s\u001b[0m 5s/step - accuracy: 0.5989 - loss: 1.4193 - val_accuracy: 0.6581 - val_loss: 1.2272 - learning_rate: 0.0050\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:22\u001b[0m 4s/step - accuracy: 0.6250 - loss: 0.9612\n",
      "Epoch 4: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 350ms/step - accuracy: 0.6250 - loss: 0.9612 - val_accuracy: 0.6581 - val_loss: 1.2286 - learning_rate: 0.0050\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6751 - loss: 1.1224\n",
      "Epoch 5: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6122s\u001b[0m 5s/step - accuracy: 0.6751 - loss: 1.1224 - val_accuracy: 0.6446 - val_loss: 1.2865 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:31\u001b[0m 4s/step - accuracy: 0.6250 - loss: 1.4102\n",
      "Epoch 6: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.6250 - loss: 1.4102 - val_accuracy: 0.6435 - val_loss: 1.2889 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7458 - loss: 0.8687\n",
      "Epoch 7: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6123s\u001b[0m 5s/step - accuracy: 0.7458 - loss: 0.8687 - val_accuracy: 0.6479 - val_loss: 1.4055 - learning_rate: 0.0050\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:44\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.5852\n",
      "Epoch 8: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 345ms/step - accuracy: 0.7500 - loss: 0.5852 - val_accuracy: 0.6472 - val_loss: 1.3998 - learning_rate: 0.0050\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8185 - loss: 0.5974\n",
      "Epoch 9: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6110s\u001b[0m 5s/step - accuracy: 0.8185 - loss: 0.5973 - val_accuracy: 0.6628 - val_loss: 1.3402 - learning_rate: 0.0025\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:24\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.2563\n",
      "Epoch 10: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.9375 - loss: 0.2563 - val_accuracy: 0.6630 - val_loss: 1.3408 - learning_rate: 0.0025\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 2s/step - accuracy: 0.6532 - loss: 1.2287\n",
      "Dataset 4 - Test accuracy: 0.6499110460281372\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5582 - loss: 1.6624\n",
      "Epoch 1: val_loss improved from inf to 1.06614, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6180s\u001b[0m 5s/step - accuracy: 0.5582 - loss: 1.6623 - val_accuracy: 0.7046 - val_loss: 1.0661 - learning_rate: 0.0025\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:12\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.6704\n",
      "Epoch 2: val_loss did not improve from 1.06614\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 351ms/step - accuracy: 0.5625 - loss: 1.6704 - val_accuracy: 0.7035 - val_loss: 1.0664 - learning_rate: 0.0025\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6304 - loss: 1.3113\n",
      "Epoch 3: val_loss improved from 1.06614 to 1.02690, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6133s\u001b[0m 5s/step - accuracy: 0.6304 - loss: 1.3113 - val_accuracy: 0.7151 - val_loss: 1.0269 - learning_rate: 0.0025\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:07\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.9041\n",
      "Epoch 4: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.7500 - loss: 0.9041 - val_accuracy: 0.7153 - val_loss: 1.0271 - learning_rate: 0.0025\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6952 - loss: 1.0673\n",
      "Epoch 5: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6170s\u001b[0m 5s/step - accuracy: 0.6952 - loss: 1.0673 - val_accuracy: 0.7113 - val_loss: 1.0454 - learning_rate: 0.0025\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:51\u001b[0m 5s/step - accuracy: 0.6250 - loss: 1.0419\n",
      "Epoch 6: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 347ms/step - accuracy: 0.6250 - loss: 1.0419 - val_accuracy: 0.7106 - val_loss: 1.0464 - learning_rate: 0.0025\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7456 - loss: 0.8663\n",
      "Epoch 7: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6102s\u001b[0m 5s/step - accuracy: 0.7456 - loss: 0.8663 - val_accuracy: 0.7066 - val_loss: 1.0963 - learning_rate: 0.0025\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:46\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6310\n",
      "Epoch 8: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 343ms/step - accuracy: 0.7500 - loss: 0.6310 - val_accuracy: 0.7073 - val_loss: 1.0971 - learning_rate: 0.0025\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8144 - loss: 0.6240\n",
      "Epoch 9: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6109s\u001b[0m 5s/step - accuracy: 0.8144 - loss: 0.6240 - val_accuracy: 0.7117 - val_loss: 1.0786 - learning_rate: 0.0012\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:25\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.7847\n",
      "Epoch 10: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 353ms/step - accuracy: 0.5625 - loss: 1.7847 - val_accuracy: 0.7124 - val_loss: 1.0785 - learning_rate: 0.0012\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 2s/step - accuracy: 0.7040 - loss: 1.0268\n",
      "Dataset 5 - Test accuracy: 0.6977313160896301\n"
     ]
    }
   ],
   "source": [
    "# 5번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day5 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=4,\n",
    "    dataset_to=6,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5965 - loss: 1.5135\n",
      "Epoch 1: val_loss improved from inf to 0.96269, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6129s\u001b[0m 5s/step - accuracy: 0.5965 - loss: 1.5135 - val_accuracy: 0.7260 - val_loss: 0.9627 - learning_rate: 0.0025\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:17\u001b[0m 4s/step - accuracy: 0.5000 - loss: 2.2539\n",
      "Epoch 2: val_loss did not improve from 0.96269\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.5000 - loss: 2.2539 - val_accuracy: 0.7260 - val_loss: 0.9629 - learning_rate: 0.0025\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6685 - loss: 1.1742\n",
      "Epoch 3: val_loss improved from 0.96269 to 0.95593, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6017s\u001b[0m 5s/step - accuracy: 0.6685 - loss: 1.1742 - val_accuracy: 0.7320 - val_loss: 0.9559 - learning_rate: 0.0025\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 4s/step - accuracy: 0.6875 - loss: 0.8449\n",
      "Epoch 4: val_loss improved from 0.95593 to 0.95541, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 347ms/step - accuracy: 0.6875 - loss: 0.8449 - val_accuracy: 0.7322 - val_loss: 0.9554 - learning_rate: 0.0025\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7258 - loss: 0.9246\n",
      "Epoch 5: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6021s\u001b[0m 5s/step - accuracy: 0.7258 - loss: 0.9246 - val_accuracy: 0.7240 - val_loss: 0.9961 - learning_rate: 0.0025\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:40\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4129\n",
      "Epoch 6: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 347ms/step - accuracy: 0.8750 - loss: 0.4129 - val_accuracy: 0.7240 - val_loss: 0.9967 - learning_rate: 0.0025\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7788 - loss: 0.7477\n",
      "Epoch 7: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6015s\u001b[0m 5s/step - accuracy: 0.7788 - loss: 0.7477 - val_accuracy: 0.7293 - val_loss: 1.0039 - learning_rate: 0.0025\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:28\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.5739\n",
      "Epoch 8: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.8125 - loss: 0.5739 - val_accuracy: 0.7293 - val_loss: 1.0043 - learning_rate: 0.0025\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8219 - loss: 0.5659\n",
      "Epoch 9: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6015s\u001b[0m 5s/step - accuracy: 0.8219 - loss: 0.5659 - val_accuracy: 0.7166 - val_loss: 1.0863 - learning_rate: 0.0025\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:55\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4695\n",
      "Epoch 10: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 341ms/step - accuracy: 0.8750 - loss: 0.4695 - val_accuracy: 0.7146 - val_loss: 1.0895 - learning_rate: 0.0012\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8743 - loss: 0.4157\n",
      "Epoch 11: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6035s\u001b[0m 5s/step - accuracy: 0.8743 - loss: 0.4157 - val_accuracy: 0.7233 - val_loss: 1.0669 - learning_rate: 0.0012\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 2s/step - accuracy: 0.7364 - loss: 0.9066\n",
      "Dataset 6 - Test accuracy: 0.7364323735237122\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5870 - loss: 1.5514\n",
      "Epoch 1: val_loss improved from inf to 0.98256, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6094s\u001b[0m 5s/step - accuracy: 0.5870 - loss: 1.5514 - val_accuracy: 0.7260 - val_loss: 0.9826 - learning_rate: 0.0012\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:35\u001b[0m 5s/step - accuracy: 0.6250 - loss: 2.2156\n",
      "Epoch 2: val_loss did not improve from 0.98256\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 340ms/step - accuracy: 0.6250 - loss: 2.2156 - val_accuracy: 0.7246 - val_loss: 0.9827 - learning_rate: 0.0012\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6502 - loss: 1.2657\n",
      "Epoch 3: val_loss improved from 0.98256 to 0.96856, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6032s\u001b[0m 5s/step - accuracy: 0.6502 - loss: 1.2657 - val_accuracy: 0.7273 - val_loss: 0.9686 - learning_rate: 0.0012\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.7102\n",
      "Epoch 4: val_loss improved from 0.96856 to 0.96816, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.5625 - loss: 1.7102 - val_accuracy: 0.7275 - val_loss: 0.9682 - learning_rate: 0.0012\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6938 - loss: 1.0840\n",
      "Epoch 5: val_loss improved from 0.96816 to 0.95314, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6039s\u001b[0m 5s/step - accuracy: 0.6938 - loss: 1.0840 - val_accuracy: 0.7324 - val_loss: 0.9531 - learning_rate: 0.0012\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:46\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.2286\n",
      "Epoch 6: val_loss improved from 0.95314 to 0.95232, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 342ms/step - accuracy: 0.5000 - loss: 1.2286 - val_accuracy: 0.7318 - val_loss: 0.9523 - learning_rate: 0.0012\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7381 - loss: 0.9098\n",
      "Epoch 7: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6008s\u001b[0m 5s/step - accuracy: 0.7381 - loss: 0.9098 - val_accuracy: 0.7351 - val_loss: 0.9675 - learning_rate: 0.0012\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:15\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.9006\n",
      "Epoch 8: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 339ms/step - accuracy: 0.8125 - loss: 0.9006 - val_accuracy: 0.7358 - val_loss: 0.9660 - learning_rate: 0.0012\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7795 - loss: 0.7446\n",
      "Epoch 9: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6004s\u001b[0m 5s/step - accuracy: 0.7795 - loss: 0.7446 - val_accuracy: 0.7200 - val_loss: 1.0399 - learning_rate: 0.0012\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:07\u001b[0m 4s/step - accuracy: 0.6875 - loss: 0.7904\n",
      "Epoch 10: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.6875 - loss: 0.7904 - val_accuracy: 0.7211 - val_loss: 1.0399 - learning_rate: 0.0012\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8224 - loss: 0.5913\n",
      "Epoch 11: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6001s\u001b[0m 5s/step - accuracy: 0.8224 - loss: 0.5914 - val_accuracy: 0.7102 - val_loss: 1.0788 - learning_rate: 0.0012\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:12\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6758\n",
      "Epoch 12: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.7500 - loss: 0.6758 - val_accuracy: 0.7089 - val_loss: 1.0828 - learning_rate: 6.2500e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8698 - loss: 0.4491\n",
      "Epoch 13: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5915s\u001b[0m 5s/step - accuracy: 0.8698 - loss: 0.4491 - val_accuracy: 0.7280 - val_loss: 1.0448 - learning_rate: 6.2500e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 2s/step - accuracy: 0.7303 - loss: 0.9197\n",
      "Dataset 7 - Test accuracy: 0.7333185076713562\n"
     ]
    }
   ],
   "source": [
    "# 6번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day6 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=6,\n",
    "    dataset_to=8,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6155 - loss: 1.4214\n",
      "Epoch 1: val_loss improved from inf to 0.91524, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6065s\u001b[0m 5s/step - accuracy: 0.6155 - loss: 1.4214 - val_accuracy: 0.7335 - val_loss: 0.9152 - learning_rate: 0.0012\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:12\u001b[0m 4s/step - accuracy: 0.5625 - loss: 0.9799\n",
      "Epoch 2: val_loss improved from 0.91524 to 0.91380, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 337ms/step - accuracy: 0.5625 - loss: 0.9799 - val_accuracy: 0.7342 - val_loss: 0.9138 - learning_rate: 0.0012\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6678 - loss: 1.1860\n",
      "Epoch 3: val_loss improved from 0.91380 to 0.90831, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5951s\u001b[0m 5s/step - accuracy: 0.6678 - loss: 1.1860 - val_accuracy: 0.7344 - val_loss: 0.9083 - learning_rate: 0.0012\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:35\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.7118\n",
      "Epoch 4: val_loss improved from 0.90831 to 0.90796, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.5625 - loss: 1.7118 - val_accuracy: 0.7353 - val_loss: 0.9080 - learning_rate: 0.0012\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7236 - loss: 0.9656\n",
      "Epoch 5: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6030s\u001b[0m 5s/step - accuracy: 0.7236 - loss: 0.9656 - val_accuracy: 0.7375 - val_loss: 0.9112 - learning_rate: 0.0012\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:55\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.7175\n",
      "Epoch 6: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 340ms/step - accuracy: 0.8750 - loss: 0.7175 - val_accuracy: 0.7391 - val_loss: 0.9107 - learning_rate: 0.0012\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7694 - loss: 0.7893\n",
      "Epoch 7: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6036s\u001b[0m 5s/step - accuracy: 0.7694 - loss: 0.7894 - val_accuracy: 0.7375 - val_loss: 0.9247 - learning_rate: 0.0012\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:03\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.6214\n",
      "Epoch 8: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.8750 - loss: 0.6214 - val_accuracy: 0.7387 - val_loss: 0.9252 - learning_rate: 0.0012\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8145 - loss: 0.6265\n",
      "Epoch 9: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5936s\u001b[0m 5s/step - accuracy: 0.8145 - loss: 0.6265 - val_accuracy: 0.7320 - val_loss: 0.9747 - learning_rate: 0.0012\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:14\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.3501\n",
      "Epoch 10: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 333ms/step - accuracy: 0.8750 - loss: 0.3501 - val_accuracy: 0.7322 - val_loss: 0.9750 - learning_rate: 6.2500e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8634 - loss: 0.4749\n",
      "Epoch 11: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5900s\u001b[0m 4s/step - accuracy: 0.8634 - loss: 0.4749 - val_accuracy: 0.7398 - val_loss: 0.9673 - learning_rate: 6.2500e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 2s/step - accuracy: 0.7547 - loss: 0.8819\n",
      "Dataset 8 - Test accuracy: 0.7473309636116028\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6499 - loss: 1.2749\n",
      "Epoch 1: val_loss improved from inf to 0.78872, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5989s\u001b[0m 5s/step - accuracy: 0.6499 - loss: 1.2749 - val_accuracy: 0.7680 - val_loss: 0.7887 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:28\u001b[0m 4s/step - accuracy: 0.6875 - loss: 1.5735\n",
      "Epoch 2: val_loss improved from 0.78872 to 0.78713, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 340ms/step - accuracy: 0.6875 - loss: 1.5735 - val_accuracy: 0.7685 - val_loss: 0.7871 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6875 - loss: 1.1323\n",
      "Epoch 3: val_loss improved from 0.78713 to 0.77820, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5957s\u001b[0m 5s/step - accuracy: 0.6875 - loss: 1.1323 - val_accuracy: 0.7700 - val_loss: 0.7782 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:11\u001b[0m 4s/step - accuracy: 0.7500 - loss: 1.2073\n",
      "Epoch 4: val_loss did not improve from 0.77820\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 334ms/step - accuracy: 0.7500 - loss: 1.2073 - val_accuracy: 0.7702 - val_loss: 0.7788 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7158 - loss: 0.9906\n",
      "Epoch 5: val_loss improved from 0.77820 to 0.76484, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5923s\u001b[0m 5s/step - accuracy: 0.7158 - loss: 0.9906 - val_accuracy: 0.7729 - val_loss: 0.7648 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:50\u001b[0m 4s/step - accuracy: 0.6875 - loss: 0.9255\n",
      "Epoch 6: val_loss improved from 0.76484 to 0.76300, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 343ms/step - accuracy: 0.6875 - loss: 0.9255 - val_accuracy: 0.7734 - val_loss: 0.7630 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7487 - loss: 0.8777\n",
      "Epoch 7: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6424s\u001b[0m 5s/step - accuracy: 0.7487 - loss: 0.8777 - val_accuracy: 0.7705 - val_loss: 0.7730 - learning_rate: 6.2500e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:26\u001b[0m 4s/step - accuracy: 0.4375 - loss: 1.2839\n",
      "Epoch 8: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 353ms/step - accuracy: 0.4375 - loss: 1.2839 - val_accuracy: 0.7702 - val_loss: 0.7721 - learning_rate: 6.2500e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7802 - loss: 0.7496\n",
      "Epoch 9: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6560s\u001b[0m 5s/step - accuracy: 0.7802 - loss: 0.7496 - val_accuracy: 0.7682 - val_loss: 0.7893 - learning_rate: 6.2500e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:00\u001b[0m 5s/step - accuracy: 0.7500 - loss: 0.6175\n",
      "Epoch 10: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 382ms/step - accuracy: 0.7500 - loss: 0.6175 - val_accuracy: 0.7685 - val_loss: 0.7898 - learning_rate: 6.2500e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8052 - loss: 0.6558\n",
      "Epoch 11: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6187s\u001b[0m 5s/step - accuracy: 0.8052 - loss: 0.6558 - val_accuracy: 0.7700 - val_loss: 0.7995 - learning_rate: 6.2500e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:04\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.3186\n",
      "Epoch 12: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 361ms/step - accuracy: 0.8750 - loss: 0.3186 - val_accuracy: 0.7707 - val_loss: 0.8001 - learning_rate: 3.1250e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8437 - loss: 0.5482\n",
      "Epoch 13: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6418s\u001b[0m 5s/step - accuracy: 0.8437 - loss: 0.5482 - val_accuracy: 0.7669 - val_loss: 0.8014 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 2s/step - accuracy: 0.7690 - loss: 0.7846\n",
      "Dataset 9 - Test accuracy: 0.7702401876449585\n"
     ]
    }
   ],
   "source": [
    "# 7번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=8,\n",
    "    dataset_to=10,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6224 - loss: 1.3886\n",
      "Epoch 1: val_loss improved from inf to 0.92480, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6415s\u001b[0m 5s/step - accuracy: 0.6224 - loss: 1.3886 - val_accuracy: 0.7411 - val_loss: 0.9248 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:53\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.9614\n",
      "Epoch 2: val_loss improved from 0.92480 to 0.92296, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 353ms/step - accuracy: 0.5625 - loss: 1.9614 - val_accuracy: 0.7418 - val_loss: 0.9230 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6733 - loss: 1.1813\n",
      "Epoch 3: val_loss improved from 0.92296 to 0.91048, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6089s\u001b[0m 5s/step - accuracy: 0.6733 - loss: 1.1813 - val_accuracy: 0.7418 - val_loss: 0.9105 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:38\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.8616\n",
      "Epoch 4: val_loss improved from 0.91048 to 0.90927, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 348ms/step - accuracy: 0.8125 - loss: 0.8616 - val_accuracy: 0.7418 - val_loss: 0.9093 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7124 - loss: 1.0065\n",
      "Epoch 5: val_loss improved from 0.90927 to 0.90107, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6098s\u001b[0m 5s/step - accuracy: 0.7124 - loss: 1.0065 - val_accuracy: 0.7476 - val_loss: 0.9011 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:01\u001b[0m 5s/step - accuracy: 0.6250 - loss: 0.8521\n",
      "Epoch 6: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.6250 - loss: 0.8521 - val_accuracy: 0.7469 - val_loss: 0.9016 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7420 - loss: 0.8837\n",
      "Epoch 7: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6096s\u001b[0m 5s/step - accuracy: 0.7420 - loss: 0.8837 - val_accuracy: 0.7400 - val_loss: 0.9204 - learning_rate: 6.2500e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:20\u001b[0m 5s/step - accuracy: 0.8750 - loss: 0.4177\n",
      "Epoch 8: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 348ms/step - accuracy: 0.8750 - loss: 0.4177 - val_accuracy: 0.7409 - val_loss: 0.9195 - learning_rate: 6.2500e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7808 - loss: 0.7525\n",
      "Epoch 9: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6102s\u001b[0m 5s/step - accuracy: 0.7808 - loss: 0.7525 - val_accuracy: 0.7364 - val_loss: 0.9273 - learning_rate: 6.2500e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:38\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.8019\n",
      "Epoch 10: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 351ms/step - accuracy: 0.7500 - loss: 0.8019 - val_accuracy: 0.7369 - val_loss: 0.9288 - learning_rate: 6.2500e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8163 - loss: 0.6151\n",
      "Epoch 11: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6110s\u001b[0m 5s/step - accuracy: 0.8163 - loss: 0.6151 - val_accuracy: 0.7373 - val_loss: 0.9304 - learning_rate: 3.1250e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:47\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.3962\n",
      "Epoch 12: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.9375 - loss: 0.3962 - val_accuracy: 0.7375 - val_loss: 0.9291 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 2s/step - accuracy: 0.7316 - loss: 0.9292\n",
      "Dataset 0 - Test accuracy: 0.7388790249824524\n"
     ]
    }
   ],
   "source": [
    "# 8번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=0,\n",
    "    dataset_to=1,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7498 - loss: 0.8574\n",
      "Epoch 1: val_loss improved from inf to 0.94312, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6263s\u001b[0m 5s/step - accuracy: 0.7498 - loss: 0.8573 - val_accuracy: 0.7411 - val_loss: 0.9431 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:55\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.9336\n",
      "Epoch 2: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.7500 - loss: 0.9336 - val_accuracy: 0.7413 - val_loss: 0.9433 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8081 - loss: 0.6584\n",
      "Epoch 3: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6127s\u001b[0m 5s/step - accuracy: 0.8081 - loss: 0.6584 - val_accuracy: 0.7329 - val_loss: 0.9729 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:50\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.4767\n",
      "Epoch 4: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 347ms/step - accuracy: 0.9375 - loss: 0.4767 - val_accuracy: 0.7331 - val_loss: 0.9721 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8349 - loss: 0.5611\n",
      "Epoch 5: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6099s\u001b[0m 5s/step - accuracy: 0.8349 - loss: 0.5611 - val_accuracy: 0.7322 - val_loss: 0.9981 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:52\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.8940\n",
      "Epoch 6: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 344ms/step - accuracy: 0.7500 - loss: 0.8940 - val_accuracy: 0.7329 - val_loss: 0.9985 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8607 - loss: 0.4789\n",
      "Epoch 7: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6093s\u001b[0m 5s/step - accuracy: 0.8607 - loss: 0.4788 - val_accuracy: 0.7338 - val_loss: 1.0056 - learning_rate: 3.1250e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:19\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.3969\n",
      "Epoch 8: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.9375 - loss: 0.3969 - val_accuracy: 0.7344 - val_loss: 1.0044 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 2s/step - accuracy: 0.7391 - loss: 0.9222\n",
      "Dataset 1 - Test accuracy: 0.7315391302108765\n"
     ]
    }
   ],
   "source": [
    "# 9번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=1,\n",
    "    dataset_to=2,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6545 - loss: 1.2665\n",
      "Epoch 1: val_loss improved from inf to 0.93930, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6228s\u001b[0m 5s/step - accuracy: 0.6545 - loss: 1.2665 - val_accuracy: 0.7369 - val_loss: 0.9393 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:32\u001b[0m 5s/step - accuracy: 0.6250 - loss: 1.1542\n",
      "Epoch 2: val_loss did not improve from 0.93930\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.6250 - loss: 1.1542 - val_accuracy: 0.7362 - val_loss: 0.9401 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7007 - loss: 1.0596\n",
      "Epoch 3: val_loss improved from 0.93930 to 0.93840, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6153s\u001b[0m 5s/step - accuracy: 0.7007 - loss: 1.0596 - val_accuracy: 0.7391 - val_loss: 0.9384 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:09\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.1254\n",
      "Epoch 4: val_loss improved from 0.93840 to 0.93696, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 351ms/step - accuracy: 0.5625 - loss: 1.1254 - val_accuracy: 0.7389 - val_loss: 0.9370 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7387 - loss: 0.8996\n",
      "Epoch 5: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6080s\u001b[0m 5s/step - accuracy: 0.7387 - loss: 0.8996 - val_accuracy: 0.7371 - val_loss: 0.9477 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:30\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6344\n",
      "Epoch 6: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.7500 - loss: 0.6344 - val_accuracy: 0.7378 - val_loss: 0.9472 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7773 - loss: 0.7678\n",
      "Epoch 7: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6115s\u001b[0m 5s/step - accuracy: 0.7773 - loss: 0.7679 - val_accuracy: 0.7329 - val_loss: 0.9686 - learning_rate: 6.2500e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:51\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.3235\n",
      "Epoch 8: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.9375 - loss: 0.3235 - val_accuracy: 0.7335 - val_loss: 0.9697 - learning_rate: 6.2500e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8029 - loss: 0.6517\n",
      "Epoch 9: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6098s\u001b[0m 5s/step - accuracy: 0.8029 - loss: 0.6517 - val_accuracy: 0.7226 - val_loss: 0.9975 - learning_rate: 6.2500e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:24\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4287\n",
      "Epoch 10: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 344ms/step - accuracy: 0.8750 - loss: 0.4287 - val_accuracy: 0.7222 - val_loss: 0.9967 - learning_rate: 3.1250e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8430 - loss: 0.5202\n",
      "Epoch 11: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6074s\u001b[0m 5s/step - accuracy: 0.8430 - loss: 0.5202 - val_accuracy: 0.7226 - val_loss: 1.0159 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 2s/step - accuracy: 0.7459 - loss: 0.8915\n",
      "Dataset 2 - Test accuracy: 0.7404359579086304\n"
     ]
    }
   ],
   "source": [
    "# 10번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=2,\n",
    "    dataset_to=3,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7710 - loss: 0.7729\n",
      "Epoch 1: val_loss improved from inf to 0.89490, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6454s\u001b[0m 5s/step - accuracy: 0.7710 - loss: 0.7729 - val_accuracy: 0.7424 - val_loss: 0.8949 - learning_rate: 3.9062e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:29\u001b[0m 5s/step - accuracy: 0.8750 - loss: 0.4717"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 0.89490 to 0.89433, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 357ms/step - accuracy: 0.8750 - loss: 0.4717 - val_accuracy: 0.7438 - val_loss: 0.8943 - learning_rate: 3.9062e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7884 - loss: 0.7217\n",
      "Epoch 3: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6386s\u001b[0m 5s/step - accuracy: 0.7884 - loss: 0.7217 - val_accuracy: 0.7444 - val_loss: 0.8967 - learning_rate: 3.9062e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:23\u001b[0m 5s/step - accuracy: 0.8125 - loss: 0.5526\n",
      "Epoch 4: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 372ms/step - accuracy: 0.8125 - loss: 0.5526 - val_accuracy: 0.7447 - val_loss: 0.8952 - learning_rate: 3.9062e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7840 - loss: 0.7209\n",
      "Epoch 5: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6468s\u001b[0m 5s/step - accuracy: 0.7840 - loss: 0.7209 - val_accuracy: 0.7473 - val_loss: 0.9015 - learning_rate: 3.9062e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:40:28\u001b[0m 5s/step - accuracy: 0.8750 - loss: 0.5420\n",
      "Epoch 6: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m480s\u001b[0m 363ms/step - accuracy: 0.8750 - loss: 0.5420 - val_accuracy: 0.7469 - val_loss: 0.9013 - learning_rate: 3.9062e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7961 - loss: 0.6960\n",
      "Epoch 7: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6403s\u001b[0m 5s/step - accuracy: 0.7961 - loss: 0.6960 - val_accuracy: 0.7433 - val_loss: 0.9048 - learning_rate: 3.9062e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:58\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.9318\n",
      "Epoch 8: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m531s\u001b[0m 402ms/step - accuracy: 0.8125 - loss: 0.9318 - val_accuracy: 0.7438 - val_loss: 0.9042 - learning_rate: 1.9531e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8051 - loss: 0.6576\n",
      "Epoch 9: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7666s\u001b[0m 6s/step - accuracy: 0.8051 - loss: 0.6576 - val_accuracy: 0.7411 - val_loss: 0.9044 - learning_rate: 1.9531e-05\n",
      "Epoch 10/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:59:35\u001b[0m 5s/step - accuracy: 0.6875 - loss: 0.5889\n",
      "Epoch 10: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 422ms/step - accuracy: 0.6875 - loss: 0.5889 - val_accuracy: 0.7420 - val_loss: 0.9044 - learning_rate: 1.9531e-05\n",
      "Epoch 11/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8102 - loss: 0.6513\n",
      "Epoch 11: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7146s\u001b[0m 5s/step - accuracy: 0.8102 - loss: 0.6513 - val_accuracy: 0.7442 - val_loss: 0.9007 - learning_rate: 1.9531e-05\n",
      "Epoch 12/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:43:06\u001b[0m 5s/step - accuracy: 0.7500 - loss: 0.7896\n",
      "Epoch 12: val_loss did not improve from 0.89433\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 375ms/step - accuracy: 0.7500 - loss: 0.7896 - val_accuracy: 0.7440 - val_loss: 0.9008 - learning_rate: 1.9531e-05\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 2s/step - accuracy: 0.7552 - loss: 0.8923\n",
      "Dataset 0 - Test accuracy: 0.7415480613708496\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8095 - loss: 0.6410\n",
      "Epoch 1: val_loss improved from inf to 0.95901, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6927s\u001b[0m 5s/step - accuracy: 0.8095 - loss: 0.6409 - val_accuracy: 0.7353 - val_loss: 0.9590 - learning_rate: 9.7656e-06\n",
      "Epoch 2/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:45\u001b[0m 5s/step - accuracy: 0.9375 - loss: 0.1869\n",
      "Epoch 2: val_loss improved from 0.95901 to 0.95867, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m530s\u001b[0m 400ms/step - accuracy: 0.9375 - loss: 0.1869 - val_accuracy: 0.7355 - val_loss: 0.9587 - learning_rate: 9.7656e-06\n",
      "Epoch 3/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8204 - loss: 0.6135\n",
      "Epoch 3: val_loss did not improve from 0.95867\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6870s\u001b[0m 5s/step - accuracy: 0.8204 - loss: 0.6135 - val_accuracy: 0.7347 - val_loss: 0.9619 - learning_rate: 9.7656e-06\n",
      "Epoch 4/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:09\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6150\n",
      "Epoch 4: val_loss did not improve from 0.95867\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 355ms/step - accuracy: 0.7500 - loss: 0.6150 - val_accuracy: 0.7360 - val_loss: 0.9608 - learning_rate: 9.7656e-06\n",
      "Epoch 5/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8184 - loss: 0.6110\n",
      "Epoch 5: val_loss improved from 0.95867 to 0.95648, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6190s\u001b[0m 5s/step - accuracy: 0.8184 - loss: 0.6110 - val_accuracy: 0.7369 - val_loss: 0.9565 - learning_rate: 9.7656e-06\n",
      "Epoch 6/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:22\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.6789\n",
      "Epoch 6: val_loss did not improve from 0.95648\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.8125 - loss: 0.6789 - val_accuracy: 0.7371 - val_loss: 0.9570 - learning_rate: 9.7656e-06\n",
      "Epoch 7/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8220 - loss: 0.6012\n",
      "Epoch 7: val_loss did not improve from 0.95648\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6117s\u001b[0m 5s/step - accuracy: 0.8220 - loss: 0.6012 - val_accuracy: 0.7329 - val_loss: 0.9593 - learning_rate: 9.7656e-06\n",
      "Epoch 8/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:46\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.9156\n",
      "Epoch 8: val_loss did not improve from 0.95648\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 343ms/step - accuracy: 0.7500 - loss: 0.9156 - val_accuracy: 0.7342 - val_loss: 0.9573 - learning_rate: 9.7656e-06\n",
      "Epoch 9/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8254 - loss: 0.5902\n",
      "Epoch 9: val_loss improved from 0.95648 to 0.95436, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6112s\u001b[0m 5s/step - accuracy: 0.8254 - loss: 0.5902 - val_accuracy: 0.7349 - val_loss: 0.9544 - learning_rate: 9.7656e-06\n",
      "Epoch 10/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:30\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.6295\n",
      "Epoch 10: val_loss improved from 0.95436 to 0.95376, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.8125 - loss: 0.6295 - val_accuracy: 0.7349 - val_loss: 0.9538 - learning_rate: 9.7656e-06\n",
      "Epoch 11/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8216 - loss: 0.5940\n",
      "Epoch 11: val_loss did not improve from 0.95376\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.8216 - loss: 0.5940 - val_accuracy: 0.7369 - val_loss: 0.9549 - learning_rate: 9.7656e-06\n",
      "Epoch 12/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:09\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4559\n",
      "Epoch 12: val_loss did not improve from 0.95376\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.8750 - loss: 0.4559 - val_accuracy: 0.7367 - val_loss: 0.9565 - learning_rate: 9.7656e-06\n",
      "Epoch 13/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8239 - loss: 0.5875\n",
      "Epoch 13: val_loss improved from 0.95376 to 0.95259, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.8239 - loss: 0.5875 - val_accuracy: 0.7395 - val_loss: 0.9526 - learning_rate: 9.7656e-06\n",
      "Epoch 14/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:26\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.5394\n",
      "Epoch 14: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.8125 - loss: 0.5394 - val_accuracy: 0.7387 - val_loss: 0.9551 - learning_rate: 9.7656e-06\n",
      "Epoch 15/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8264 - loss: 0.5778\n",
      "Epoch 15: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6112s\u001b[0m 5s/step - accuracy: 0.8264 - loss: 0.5778 - val_accuracy: 0.7398 - val_loss: 0.9546 - learning_rate: 9.7656e-06\n",
      "Epoch 16/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:12\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.4422\n",
      "Epoch 16: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.7500 - loss: 0.4422 - val_accuracy: 0.7400 - val_loss: 0.9554 - learning_rate: 9.7656e-06\n",
      "Epoch 17/30\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8254 - loss: 0.5818\n",
      "Epoch 17: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6111s\u001b[0m 5s/step - accuracy: 0.8254 - loss: 0.5818 - val_accuracy: 0.7369 - val_loss: 0.9565 - learning_rate: 9.7656e-06\n",
      "Epoch 18/30\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:46\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.5332\n",
      "Epoch 18: val_loss did not improve from 0.95259\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.8125 - loss: 0.5332 - val_accuracy: 0.7369 - val_loss: 0.9578 - learning_rate: 9.7656e-06\n",
      "Epoch 19/30\n",
      "\u001b[1m1006/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m22:14\u001b[0m 4s/step - accuracy: 0.8276 - loss: 0.5753"
     ]
    }
   ],
   "source": [
    "# 11번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day11 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=0,\n",
    "    dataset_to=10,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분류를 잘 못하는 클래스 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 약식을 위한 dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# 원본 데이터 경로와 생성할 데이터 경로 설정\n",
    "original_dataset_dir = r\"D:\\Work\\all_project\\3rd_final_project\\k_food_for_colab\"    # test: class별 140장\n",
    "test_dataset_dir = r\"D:\\Work\\all_project\\3rd_final_project\\k_food_datasets\\dataset_test\"\n",
    "\n",
    "# 폴더 생성 함수\n",
    "def create_directory_structure(base_dir, class_names):\n",
    "    for split in [\"test\"]:\n",
    "        split_dir = os.path.join(base_dir, split)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        for class_name in class_names:\n",
    "            os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n",
    "\n",
    "# 샘플링 및 파일 복사 함수\n",
    "def sample_and_copy_files(original_dir, target_dir, class_names, sampling_ratios):\n",
    "    for split, ratio in sampling_ratios.items():\n",
    "        for class_name in class_names:\n",
    "            original_class_dir = os.path.join(original_dir, split, class_name)\n",
    "            target_class_dir = os.path.join(target_dir, split, class_name)\n",
    "\n",
    "            # 원본 이미지 리스트 가져오기\n",
    "            all_files = os.listdir(original_class_dir)\n",
    "            sampled_files = random.sample(all_files, int(len(all_files) * ratio))\n",
    "\n",
    "            # 파일 복사\n",
    "            for file_name in sampled_files:\n",
    "                src = os.path.join(original_class_dir, file_name)\n",
    "                dst = os.path.join(target_class_dir, file_name)\n",
    "                shutil.copy(src, dst)\n",
    "\n",
    "# 메인 함수\n",
    "def create_mini_dataset(original_dir, mini_dir, sampling_ratio=0.4):\n",
    "    # 10% : 14, 20% : 28, 30% : 42, 40% : 56, 50% : 70, 60% : 84, 70% : 98, 80% : 112, 90% : 126\n",
    "\n",
    "    # 클래스 이름 추출 (test 폴더 기준)\n",
    "    class_names = os.listdir(os.path.join(original_dir, \"test\"))\n",
    "\n",
    "    # 새로운 데이터셋 폴더 구조 생성\n",
    "    create_directory_structure(mini_dir, class_names)\n",
    "\n",
    "    # 샘플링 비율 설정 (train, test, validation 각각 10%)\n",
    "    sampling_ratios = {\"test\": sampling_ratio}\n",
    "\n",
    "    # 데이터 복사 및 샘플링\n",
    "    sample_and_copy_files(original_dir, mini_dir, class_names, sampling_ratios)\n",
    "    print(f\"Mini dataset created at {mini_dir}\")\n",
    "\n",
    "# 실행\n",
    "create_mini_dataset(original_dataset_dir, test_dataset_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 경로\n",
    "model_path = r\"D:\\Work\\all_project\\3rd_final_project\\3rd_final_project\\Yul\\model\\best_model_with_rn101.keras\"\n",
    "\n",
    "# 모델 불러오기\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4500 images belonging to 150 classes.\n",
      "Test generator prepared!!\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "\n",
    "# 미니 데이터셋 경로\n",
    "test_dataset_dir = \"D:/Work/all_project/3rd_final_project/k_food_datasets/dataset0\"\n",
    "\n",
    "# 데이터 제너레이터 설정\n",
    "def get_test_generator(dataset_dir, target_size=(256, 256), batch_size=16):\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/test\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False  # 순서를 고정하여 클래스별 매핑이 유지되도록 설정\n",
    "    )\n",
    "    return test_generator\n",
    "\n",
    "# Test 데이터 로드\n",
    "test_generator = get_test_generator(test_dataset_dir)\n",
    "print(\"Test generator prepared!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m282/282\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        가지볶음     0.5758    0.6333    0.6032        30\n",
      "        간장게장     0.7419    0.7667    0.7541        30\n",
      "        갈비구이     0.4000    0.4000    0.4000        30\n",
      "         갈비찜     0.7500    0.7000    0.7241        30\n",
      "         갈비탕     0.6970    0.7667    0.7302        30\n",
      "        갈치구이     0.8750    0.7000    0.7778        30\n",
      "        갈치조림     0.6316    0.4000    0.4898        30\n",
      "         감자전     0.7273    0.5333    0.6154        30\n",
      "        감자조림     0.7857    0.7333    0.7586        30\n",
      "       감자채볶음     0.9355    0.9667    0.9508        30\n",
      "         감자탕     0.7037    0.6333    0.6667        30\n",
      "         갓김치     0.8077    0.7000    0.7500        30\n",
      "       건새우볶음     0.8621    0.8333    0.8475        30\n",
      "          경단     0.9259    0.8333    0.8772        30\n",
      "         계란국     0.7500    0.7000    0.7241        30\n",
      "        계란말이     0.7857    0.7333    0.7586        30\n",
      "         계란찜     0.8438    0.9000    0.8710        30\n",
      "       계란후라이     0.9062    0.9667    0.9355        30\n",
      "       고등어구이     0.6341    0.8667    0.7324        30\n",
      "       고등어조림     0.2703    0.3333    0.2985        30\n",
      "       고사리나물     0.8286    0.9667    0.8923        30\n",
      "    고추장진미채볶음     0.4359    0.5667    0.4928        30\n",
      "        고추튀김     0.7931    0.7667    0.7797        30\n",
      "      곰탕_설렁탕     0.8333    0.6667    0.7407        30\n",
      "        곱창구이     0.8065    0.8333    0.8197        30\n",
      "        곱창전골     0.5000    0.4667    0.4828        30\n",
      "         과메기     0.9355    0.9667    0.9508        30\n",
      "          김밥     0.9375    1.0000    0.9677        30\n",
      "       김치볶음밥     0.7742    0.8000    0.7869        30\n",
      "         김치전     0.7097    0.7333    0.7213        30\n",
      "        김치찌개     0.6296    0.5667    0.5965        30\n",
      "         김치찜     0.4762    0.6667    0.5556        30\n",
      "         깍두기     0.8333    0.8333    0.8333        30\n",
      "       깻잎장아찌     0.9200    0.7667    0.8364        30\n",
      "         꼬막찜     1.0000    0.8333    0.9091        30\n",
      "        꽁치조림     0.7273    0.5333    0.6154        30\n",
      "      꽈리고추무침     0.8929    0.8333    0.8621        30\n",
      "          꿀떡     0.8621    0.8333    0.8475        30\n",
      "        나박김치     0.8667    0.8667    0.8667        30\n",
      "         누룽지     0.7826    0.6000    0.6792        30\n",
      "         닭갈비     0.6471    0.7333    0.6875        30\n",
      "         닭계장     0.5714    0.6667    0.6154        30\n",
      "        닭볶음탕     0.7647    0.8667    0.8125        30\n",
      "        더덕구이     0.8750    0.7000    0.7778        30\n",
      "       도라지무침     0.6800    0.5667    0.6182        30\n",
      "        도토리묵     0.7500    0.7000    0.7241        30\n",
      "        동그랑땡     0.8462    0.7333    0.7857        30\n",
      "        동태찌개     0.3889    0.4667    0.4242        30\n",
      "        된장찌개     0.7500    0.7000    0.7241        30\n",
      "        두부김치     0.8750    0.9333    0.9032        30\n",
      "        두부조림     0.7083    0.5667    0.6296        30\n",
      "        땅콩조림     0.8750    0.9333    0.9032        30\n",
      "         떡갈비     0.8000    0.8000    0.8000        30\n",
      "      떡국_만두국     0.6061    0.6667    0.6349        30\n",
      "         떡꼬치     0.7812    0.8333    0.8065        30\n",
      "         떡볶이     0.6957    0.5333    0.6038        30\n",
      "          라면     0.8077    0.7000    0.7500        30\n",
      "         라볶이     0.7742    0.8000    0.7869        30\n",
      "         막국수     0.8400    0.7000    0.7636        30\n",
      "          만두     0.8462    0.7333    0.7857        30\n",
      "         매운탕     0.3462    0.3000    0.3214        30\n",
      "          멍게     0.5000    0.6000    0.5455        30\n",
      "     메추리알장조림     0.8077    0.7000    0.7500        30\n",
      "        멸치볶음     0.8400    0.7000    0.7636        30\n",
      "          무국     0.6857    0.8000    0.7385        30\n",
      "         무생채     0.7419    0.7667    0.7541        30\n",
      "         물냉면     0.8065    0.8333    0.8197        30\n",
      "          물회     0.7407    0.6667    0.7018        30\n",
      "         미역국     0.9000    0.9000    0.9000        30\n",
      "      미역줄기볶음     1.0000    0.9333    0.9655        30\n",
      "        배추김치     0.8077    0.7000    0.7500        30\n",
      "         백김치     0.8710    0.9000    0.8852        30\n",
      "          보쌈     0.6333    0.6333    0.6333        30\n",
      "        부추김치     0.6842    0.8667    0.7647        30\n",
      "         북엇국     0.7742    0.8000    0.7869        30\n",
      "         불고기     0.6154    0.5333    0.5714        30\n",
      "        비빔냉면     0.8387    0.8667    0.8525        30\n",
      "         비빔밥     0.6000    0.7000    0.6462        30\n",
      "         산낙지     0.7742    0.8000    0.7869        30\n",
      "         삼겹살     0.7500    0.7000    0.7241        30\n",
      "         삼계탕     0.7778    0.7000    0.7368        30\n",
      "       새우볶음밥     0.8333    1.0000    0.9091        30\n",
      "        새우튀김     0.6538    0.5667    0.6071        30\n",
      "         생선전     0.6970    0.7667    0.7302        30\n",
      "       소세지볶음     0.6944    0.8333    0.7576        30\n",
      "          송편     0.7576    0.8333    0.7937        30\n",
      "          수육     0.5588    0.6333    0.5938        30\n",
      "         수정과     0.9655    0.9333    0.9492        30\n",
      "         수제비     0.5769    0.5000    0.5357        30\n",
      "        숙주나물     0.8333    0.8333    0.8333        30\n",
      "          순대     0.8261    0.6333    0.7170        30\n",
      "       순두부찌개     0.6452    0.6667    0.6557        30\n",
      "       시금치나물     0.9091    1.0000    0.9524        30\n",
      "        시래기국     0.7188    0.7667    0.7419        30\n",
      "          식혜     0.8529    0.9667    0.9062        30\n",
      "          알밥     0.9583    0.7667    0.8519        30\n",
      "       애호박볶음     0.9667    0.9667    0.9667        30\n",
      "          약과     0.7429    0.8667    0.8000        30\n",
      "          약식     0.8571    0.8000    0.8276        30\n",
      "        양념게장     0.7586    0.7333    0.7458        30\n",
      "        양념치킨     0.6216    0.7667    0.6866        30\n",
      "        어묵볶음     0.6875    0.7333    0.7097        30\n",
      "        연근조림     1.0000    0.9667    0.9831        30\n",
      "        열무국수     0.8065    0.8333    0.8197        30\n",
      "        열무김치     0.9500    0.6333    0.7600        30\n",
      "       오이소박이     0.9091    1.0000    0.9524        30\n",
      "      오징어채볶음     0.3333    0.2667    0.2963        30\n",
      "       오징어튀김     0.4595    0.5667    0.5075        30\n",
      "        우엉조림     0.9130    0.7000    0.7925        30\n",
      "        유부초밥     0.8387    0.8667    0.8525        30\n",
      "         육개장     0.4828    0.4667    0.4746        30\n",
      "          육회     0.7879    0.8667    0.8254        30\n",
      "        잔치국수     0.7931    0.7667    0.7797        30\n",
      "         잡곡밥     0.8788    0.9667    0.9206        30\n",
      "          잡채     0.8125    0.8667    0.8387        30\n",
      "        장어구이     0.7619    0.5333    0.6275        30\n",
      "         장조림     0.7667    0.7667    0.7667        30\n",
      "         전복죽     0.8750    0.9333    0.9032        30\n",
      "          젓갈     0.5238    0.7333    0.6111        30\n",
      "        제육볶음     0.4762    0.6667    0.5556        30\n",
      "        조개구이     0.8529    0.9667    0.9062        30\n",
      "        조기구이     0.9615    0.8333    0.8929        30\n",
      "          족발     0.7419    0.7667    0.7541        30\n",
      "       주꾸미볶음     0.4390    0.6000    0.5070        30\n",
      "         주먹밥     0.8621    0.8333    0.8475        30\n",
      "         짜장면     0.9200    0.7667    0.8364        30\n",
      "          짬뽕     0.9259    0.8333    0.8772        30\n",
      "          쫄면     0.7667    0.7667    0.7667        30\n",
      "          찜닭     0.8276    0.8000    0.8136        30\n",
      "        총각김치     0.8235    0.9333    0.8750        30\n",
      "         추어탕     0.8235    0.4667    0.5957        30\n",
      "         칼국수     0.6176    0.7000    0.6562        30\n",
      "       코다리조림     0.4194    0.4333    0.4262        30\n",
      "         콩국수     0.8966    0.8667    0.8814        30\n",
      "        콩나물국     0.6923    0.6000    0.6429        30\n",
      "       콩나물무침     0.9231    0.8000    0.8571        30\n",
      "         콩자반     0.9310    0.9000    0.9153        30\n",
      "         파김치     0.7812    0.8333    0.8065        30\n",
      "          파전     0.8387    0.8667    0.8525        30\n",
      "          편육     0.4583    0.3667    0.4074        30\n",
      "          피자     0.7632    0.9667    0.8529        30\n",
      "          한과     0.9677    1.0000    0.9836        30\n",
      "         해물찜     0.5882    0.6667    0.6250        30\n",
      "         호박전     0.6857    0.8000    0.7385        30\n",
      "         호박죽     0.9655    0.9333    0.9492        30\n",
      "        홍어무침     0.6154    0.5333    0.5714        30\n",
      "        황태구이     0.5385    0.7000    0.6087        30\n",
      "         회무침     0.5926    0.5333    0.5614        30\n",
      "      후라이드치킨     0.9355    0.9667    0.9508        30\n",
      "        훈제오리     0.5938    0.6333    0.6129        30\n",
      "\n",
      "    accuracy                         0.7438      4500\n",
      "   macro avg     0.7518    0.7438    0.7436      4500\n",
      "weighted avg     0.7518    0.7438    0.7436      4500\n",
      "\n",
      "Confusion Matrix:\n",
      " [[19  1  0 ...  0  0  0]\n",
      " [ 1 23  0 ...  0  0  0]\n",
      " [ 1  0 12 ...  0  0  3]\n",
      " ...\n",
      " [ 0  0  0 ... 16  0  0]\n",
      " [ 0  0  0 ...  0 29  0]\n",
      " [ 0  0  0 ...  0  0 19]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# 모델로 예측 수행\n",
    "y_pred = model.predict(test_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 예측 클래스\n",
    "y_true = test_generator.classes             # 실제 클래스\n",
    "\n",
    "# 클래스 이름 가져오기\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# 분류 보고서 생성\n",
    "report = classification_report(y_true, y_pred_classes, target_names=class_labels, digits=4)\n",
    "print(report)\n",
    "\n",
    "# 혼동 행렬 생성\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report 분석\n",
    "import pandas as pd\n",
    "\n",
    "# Report 문자열을 DataFrame으로 변환\n",
    "report_dict = classification_report(y_true, y_pred_classes, target_names=class_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes with the lowest F1-scores:\n",
      "           precision    recall  f1-score  support\n",
      "오징어채볶음     0.333333  0.266667  0.296296     30.0\n",
      "고등어조림      0.270270  0.333333  0.298507     30.0\n",
      "매운탕        0.346154  0.300000  0.321429     30.0\n",
      "갈비구이       0.400000  0.400000  0.400000     30.0\n",
      "편육         0.458333  0.366667  0.407407     30.0\n",
      "동태찌개       0.388889  0.466667  0.424242     30.0\n",
      "코다리조림      0.419355  0.433333  0.426230     30.0\n",
      "육개장        0.482759  0.466667  0.474576     30.0\n",
      "곱창전골       0.500000  0.466667  0.482759     30.0\n",
      "갈치조림       0.631579  0.400000  0.489796     30.0\n",
      "고추장진미채볶음   0.435897  0.566667  0.492754     30.0\n",
      "주꾸미볶음      0.439024  0.600000  0.507042     30.0\n",
      "오징어튀김      0.459459  0.566667  0.507463     30.0\n",
      "수제비        0.576923  0.500000  0.535714     30.0\n",
      "멍게         0.500000  0.600000  0.545455     30.0\n",
      "제육볶음       0.476190  0.666667  0.555556     30.0\n",
      "김치찜        0.476190  0.666667  0.555556     30.0\n",
      "회무침        0.592593  0.533333  0.561404     30.0\n",
      "홍어무침       0.615385  0.533333  0.571429     30.0\n",
      "불고기        0.615385  0.533333  0.571429     30.0\n",
      "수육         0.558824  0.633333  0.593750     30.0\n",
      "추어탕        0.823529  0.466667  0.595745     30.0\n",
      "김치찌개       0.629630  0.566667  0.596491     30.0\n",
      "가지볶음       0.575758  0.633333  0.603175     30.0\n",
      "떡볶이        0.695652  0.533333  0.603774     30.0\n",
      "새우튀김       0.653846  0.566667  0.607143     30.0\n",
      "황태구이       0.538462  0.700000  0.608696     30.0\n",
      "젓갈         0.523810  0.733333  0.611111     30.0\n",
      "훈제오리       0.593750  0.633333  0.612903     30.0\n",
      "닭계장        0.571429  0.666667  0.615385     30.0\n",
      "꽁치조림       0.727273  0.533333  0.615385     30.0\n",
      "감자전        0.727273  0.533333  0.615385     30.0\n",
      "도라지무침      0.680000  0.566667  0.618182     30.0\n",
      "해물찜        0.588235  0.666667  0.625000     30.0\n",
      "장어구이       0.761905  0.533333  0.627451     30.0\n",
      "두부조림       0.708333  0.566667  0.629630     30.0\n",
      "보쌈         0.633333  0.633333  0.633333     30.0\n",
      "떡국_만두국     0.606061  0.666667  0.634921     30.0\n",
      "콩나물국       0.692308  0.600000  0.642857     30.0\n",
      "비빔밥        0.600000  0.700000  0.646154     30.0\n",
      "순두부찌개      0.645161  0.666667  0.655738     30.0\n",
      "칼국수        0.617647  0.700000  0.656250     30.0\n",
      "감자탕        0.703704  0.633333  0.666667     30.0\n",
      "누룽지        0.782609  0.600000  0.679245     30.0\n",
      "양념치킨       0.621622  0.766667  0.686567     30.0\n"
     ]
    }
   ],
   "source": [
    "# F1-Score 기반 정렬\n",
    "low_f1_classes = report_df.sort_values(\"f1-score\").head(45)  # F1-Score 하위 10개 클래스\n",
    "print(\"Classes with the lowest F1-scores:\\n\", low_f1_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes with the lowest Recall:\n",
      "           precision    recall  f1-score  support\n",
      "오징어채볶음     0.333333  0.266667  0.296296     30.0\n",
      "매운탕        0.346154  0.300000  0.321429     30.0\n",
      "고등어조림      0.270270  0.333333  0.298507     30.0\n",
      "편육         0.458333  0.366667  0.407407     30.0\n",
      "갈비구이       0.400000  0.400000  0.400000     30.0\n",
      "갈치조림       0.631579  0.400000  0.489796     30.0\n",
      "코다리조림      0.419355  0.433333  0.426230     30.0\n",
      "육개장        0.482759  0.466667  0.474576     30.0\n",
      "동태찌개       0.388889  0.466667  0.424242     30.0\n",
      "곱창전골       0.500000  0.466667  0.482759     30.0\n",
      "추어탕        0.823529  0.466667  0.595745     30.0\n",
      "수제비        0.576923  0.500000  0.535714     30.0\n",
      "홍어무침       0.615385  0.533333  0.571429     30.0\n",
      "장어구이       0.761905  0.533333  0.627451     30.0\n",
      "감자전        0.727273  0.533333  0.615385     30.0\n",
      "불고기        0.615385  0.533333  0.571429     30.0\n",
      "꽁치조림       0.727273  0.533333  0.615385     30.0\n",
      "떡볶이        0.695652  0.533333  0.603774     30.0\n",
      "회무침        0.592593  0.533333  0.561404     30.0\n",
      "고추장진미채볶음   0.435897  0.566667  0.492754     30.0\n",
      "오징어튀김      0.459459  0.566667  0.507463     30.0\n",
      "김치찌개       0.629630  0.566667  0.596491     30.0\n",
      "두부조림       0.708333  0.566667  0.629630     30.0\n",
      "새우튀김       0.653846  0.566667  0.607143     30.0\n",
      "도라지무침      0.680000  0.566667  0.618182     30.0\n",
      "누룽지        0.782609  0.600000  0.679245     30.0\n",
      "주꾸미볶음      0.439024  0.600000  0.507042     30.0\n",
      "멍게         0.500000  0.600000  0.545455     30.0\n",
      "콩나물국       0.692308  0.600000  0.642857     30.0\n",
      "열무김치       0.950000  0.633333  0.760000     30.0\n",
      "순대         0.826087  0.633333  0.716981     30.0\n",
      "수육         0.558824  0.633333  0.593750     30.0\n",
      "가지볶음       0.575758  0.633333  0.603175     30.0\n",
      "보쌈         0.633333  0.633333  0.633333     30.0\n",
      "감자탕        0.703704  0.633333  0.666667     30.0\n",
      "훈제오리       0.593750  0.633333  0.612903     30.0\n",
      "순두부찌개      0.645161  0.666667  0.655738     30.0\n",
      "김치찜        0.476190  0.666667  0.555556     30.0\n",
      "닭계장        0.571429  0.666667  0.615385     30.0\n",
      "떡국_만두국     0.606061  0.666667  0.634921     30.0\n",
      "물회         0.740741  0.666667  0.701754     30.0\n",
      "곰탕_설렁탕     0.833333  0.666667  0.740741     30.0\n",
      "제육볶음       0.476190  0.666667  0.555556     30.0\n",
      "해물찜        0.588235  0.666667  0.625000     30.0\n",
      "삼겹살        0.750000  0.700000  0.724138     30.0\n"
     ]
    }
   ],
   "source": [
    "low_recall_classes = report_df.sort_values(by=\"recall\").head(45)  # Recall 하위 10개 클래스\n",
    "print(\"Classes with the lowest Recall:\\n\", low_recall_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most misclassified classes:\n",
      "       class  misclassified\n",
      "106  오징어채볶음             22\n",
      "60      매운탕             21\n",
      "19    고등어조림             20\n",
      "139      편육             19\n",
      "2      갈비구이             18\n",
      "6      갈치조림             18\n",
      "132   코다리조림             17\n",
      "47     동태찌개             16\n",
      "130     추어탕             16\n",
      "25     곱창전골             16\n",
      "110     육개장             16\n",
      "88      수제비             15\n",
      "55      떡볶이             14\n",
      "35     꽁치조림             14\n",
      "75      불고기             14\n",
      "7       감자전             14\n",
      "145    홍어무침             14\n",
      "147     회무침             14\n",
      "115    장어구이             14\n",
      "107   오징어튀김             13\n"
     ]
    }
   ],
   "source": [
    "# 각 클래스에서 잘못 예측된 횟수 계산\n",
    "misclass_counts = np.sum(conf_matrix, axis=1) - np.diag(conf_matrix)\n",
    "\n",
    "# 가장 많이 오분류된 클래스 상위 10개\n",
    "most_misclassified = pd.DataFrame({\n",
    "    \"class\": class_labels,\n",
    "    \"misclassified\": misclass_counts\n",
    "}).sort_values(by=\"misclassified\", ascending=False).head(20)\n",
    "\n",
    "print(\"Most misclassified classes:\\n\", most_misclassified)\n",
    "# 140장 증강 (20%) 총 840장 : 오징어채볶음, 매운탕, 고등어조림, 편육, 갈비구이, 갈치조림\n",
    "# 105장 증강 (15%) 총 805장 : 코다리조림, 동태찌개, 추어탕, 곱창전골, 육개장, 수제비\n",
    "# 70장 증강 (10%) 총 770장 : 떡볶이, 꽁치조림, 불고기, 감자전, 홍어무침, 회무침, 장어구이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis results saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "# 분석 결과 저장\n",
    "report_df.to_csv(\"classification_report.csv\", index=True)\n",
    "most_misclassified.to_csv(\"misclassified_classes.csv\", index=False)\n",
    "\n",
    "print(\"Analysis results saved to CSV files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 일부러 불균형으로 만든 데이터 셋으로 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106960 images belonging to 150 classes.\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 21000 images belonging to 150 classes.\n"
     ]
    }
   ],
   "source": [
    "# 데이터 경로 설정\n",
    "train_dir = \"../../../K_food_for_colab(불균형으로 만듦)/train\"\n",
    "val_dir = \"../../../K_food_for_colab(불균형으로 만듦)/validation\"\n",
    "test_dir = \"../../../K_food_for_colab(불균형으로 만듦)/test\"\n",
    "\n",
    "# 데이터 전처리 (이미지 증강 없이)\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 모델 경로\n",
    "model_path = r\"D:\\Work\\all_project\\3rd_final_project\\3rd_final_project\\Yul\\model\\best_model_with_rn101.keras\"\n",
    "\n",
    "# 모델 불러오기\n",
    "loaded_model = load_model(model_path)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 옵티마이저 변경\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "loaded_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = '../model/best_model_adam.keras'\n",
    "# 콜백 설정 함수\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "callbacks = [early_stopping, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7301 - loss: 0.9369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.62499, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15744s\u001b[0m 9s/step - accuracy: 0.7301 - loss: 0.9369 - val_accuracy: 0.8170 - val_loss: 0.6250 - learning_rate: 9.7656e-06\n",
      "Epoch 2/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7354 - loss: 0.9271\n",
      "Epoch 2: val_loss improved from 0.62499 to 0.61511, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15684s\u001b[0m 9s/step - accuracy: 0.7354 - loss: 0.9271 - val_accuracy: 0.8202 - val_loss: 0.6151 - learning_rate: 9.7656e-06\n",
      "Epoch 3/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:05:06\u001b[0m 9s/step - accuracy: 0.6875 - loss: 1.1090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3: val_loss improved from 0.61511 to 0.60803, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1069s\u001b[0m 635ms/step - accuracy: 0.6875 - loss: 1.1090 - val_accuracy: 0.8207 - val_loss: 0.6080 - learning_rate: 9.7656e-06\n",
      "Epoch 4/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7379 - loss: 0.9303\n",
      "Epoch 4: val_loss did not improve from 0.60803\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15584s\u001b[0m 9s/step - accuracy: 0.7379 - loss: 0.9303 - val_accuracy: 0.8178 - val_loss: 0.6218 - learning_rate: 9.7656e-06\n",
      "Epoch 5/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7373 - loss: 0.9168\n",
      "Epoch 5: val_loss did not improve from 0.60803\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15559s\u001b[0m 9s/step - accuracy: 0.7373 - loss: 0.9168 - val_accuracy: 0.8205 - val_loss: 0.6208 - learning_rate: 9.7656e-06\n",
      "Epoch 6/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:05:59\u001b[0m 9s/step - accuracy: 0.7812 - loss: 0.8863\n",
      "Epoch 6: val_loss improved from 0.60803 to 0.60300, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1074s\u001b[0m 638ms/step - accuracy: 0.7812 - loss: 0.8863 - val_accuracy: 0.8237 - val_loss: 0.6030 - learning_rate: 9.7656e-06\n",
      "Epoch 7/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7383 - loss: 0.9232\n",
      "Epoch 7: val_loss did not improve from 0.60300\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15568s\u001b[0m 9s/step - accuracy: 0.7383 - loss: 0.9232 - val_accuracy: 0.8217 - val_loss: 0.6147 - learning_rate: 9.7656e-06\n",
      "Epoch 8/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7371 - loss: 0.9200\n",
      "Epoch 8: val_loss did not improve from 0.60300\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15597s\u001b[0m 9s/step - accuracy: 0.7371 - loss: 0.9200 - val_accuracy: 0.8218 - val_loss: 0.6118 - learning_rate: 9.7656e-06\n",
      "Epoch 9/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:05:09\u001b[0m 9s/step - accuracy: 0.6875 - loss: 1.1233\n",
      "Epoch 9: val_loss improved from 0.60300 to 0.59970, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1077s\u001b[0m 639ms/step - accuracy: 0.6875 - loss: 1.1233 - val_accuracy: 0.8256 - val_loss: 0.5997 - learning_rate: 9.7656e-06\n",
      "Epoch 10/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7421 - loss: 0.9020\n",
      "Epoch 10: val_loss did not improve from 0.59970\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15715s\u001b[0m 9s/step - accuracy: 0.7421 - loss: 0.9020 - val_accuracy: 0.8208 - val_loss: 0.6101 - learning_rate: 9.7656e-06\n",
      "Epoch 11/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7399 - loss: 0.9140\n",
      "Epoch 11: val_loss did not improve from 0.59970\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15726s\u001b[0m 9s/step - accuracy: 0.7399 - loss: 0.9140 - val_accuracy: 0.8236 - val_loss: 0.6074 - learning_rate: 9.7656e-06\n",
      "Epoch 12/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:05:26\u001b[0m 9s/step - accuracy: 0.8125 - loss: 0.5983\n",
      "Epoch 12: val_loss did not improve from 0.59970\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1074s\u001b[0m 638ms/step - accuracy: 0.8125 - loss: 0.5983 - val_accuracy: 0.8195 - val_loss: 0.6175 - learning_rate: 9.7656e-06\n",
      "Epoch 13/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7447 - loss: 0.8936\n",
      "Epoch 13: val_loss did not improve from 0.59970\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15658s\u001b[0m 9s/step - accuracy: 0.7447 - loss: 0.8936 - val_accuracy: 0.8221 - val_loss: 0.6154 - learning_rate: 9.7656e-06\n",
      "Epoch 14/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7431 - loss: 0.9049\n",
      "Epoch 14: val_loss improved from 0.59970 to 0.59541, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15639s\u001b[0m 9s/step - accuracy: 0.7431 - loss: 0.9049 - val_accuracy: 0.8261 - val_loss: 0.5954 - learning_rate: 9.7656e-06\n",
      "Epoch 15/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:06:37\u001b[0m 9s/step - accuracy: 0.6875 - loss: 0.6475\n",
      "Epoch 15: val_loss did not improve from 0.59541\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1066s\u001b[0m 633ms/step - accuracy: 0.6875 - loss: 0.6475 - val_accuracy: 0.8215 - val_loss: 0.6109 - learning_rate: 9.7656e-06\n",
      "Epoch 16/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7456 - loss: 0.8908\n",
      "Epoch 16: val_loss did not improve from 0.59541\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15724s\u001b[0m 9s/step - accuracy: 0.7456 - loss: 0.8908 - val_accuracy: 0.8239 - val_loss: 0.6128 - learning_rate: 9.7656e-06\n",
      "Epoch 17/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7399 - loss: 0.9026\n",
      "Epoch 17: val_loss did not improve from 0.59541\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15706s\u001b[0m 9s/step - accuracy: 0.7399 - loss: 0.9026 - val_accuracy: 0.8234 - val_loss: 0.6089 - learning_rate: 9.7656e-06\n",
      "Epoch 18/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:04:02\u001b[0m 9s/step - accuracy: 0.6875 - loss: 0.9131\n",
      "Epoch 18: val_loss did not improve from 0.59541\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1074s\u001b[0m 638ms/step - accuracy: 0.6875 - loss: 0.9131 - val_accuracy: 0.8253 - val_loss: 0.5962 - learning_rate: 9.7656e-06\n",
      "Epoch 19/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7396 - loss: 0.8996\n",
      "Epoch 19: val_loss did not improve from 0.59541\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15717s\u001b[0m 9s/step - accuracy: 0.7396 - loss: 0.8996 - val_accuracy: 0.8164 - val_loss: 0.6400 - learning_rate: 9.7656e-06\n",
      "Epoch 20/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7453 - loss: 0.8966\n",
      "Epoch 20: val_loss improved from 0.59541 to 0.59372, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15683s\u001b[0m 9s/step - accuracy: 0.7453 - loss: 0.8966 - val_accuracy: 0.8256 - val_loss: 0.5937 - learning_rate: 4.8828e-06\n",
      "Epoch 21/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:08:43\u001b[0m 9s/step - accuracy: 0.6562 - loss: 1.2065\n",
      "Epoch 21: val_loss did not improve from 0.59372\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1072s\u001b[0m 637ms/step - accuracy: 0.6562 - loss: 1.2065 - val_accuracy: 0.8253 - val_loss: 0.5999 - learning_rate: 4.8828e-06\n",
      "Epoch 22/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7429 - loss: 0.8924\n",
      "Epoch 22: val_loss improved from 0.59372 to 0.59117, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15681s\u001b[0m 9s/step - accuracy: 0.7429 - loss: 0.8924 - val_accuracy: 0.8283 - val_loss: 0.5912 - learning_rate: 4.8828e-06\n",
      "Epoch 23/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7471 - loss: 0.8950\n",
      "Epoch 23: val_loss did not improve from 0.59117\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15708s\u001b[0m 9s/step - accuracy: 0.7471 - loss: 0.8950 - val_accuracy: 0.8212 - val_loss: 0.6057 - learning_rate: 4.8828e-06\n",
      "Epoch 24/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:06:25\u001b[0m 9s/step - accuracy: 0.6875 - loss: 1.1630\n",
      "Epoch 24: val_loss did not improve from 0.59117\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1075s\u001b[0m 639ms/step - accuracy: 0.6875 - loss: 1.1630 - val_accuracy: 0.8233 - val_loss: 0.6088 - learning_rate: 4.8828e-06\n",
      "Epoch 25/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7464 - loss: 0.8794\n",
      "Epoch 25: val_loss did not improve from 0.59117\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15691s\u001b[0m 9s/step - accuracy: 0.7464 - loss: 0.8794 - val_accuracy: 0.8248 - val_loss: 0.5983 - learning_rate: 4.8828e-06\n",
      "Epoch 26/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7460 - loss: 0.8915\n",
      "Epoch 26: val_loss did not improve from 0.59117\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15661s\u001b[0m 9s/step - accuracy: 0.7460 - loss: 0.8915 - val_accuracy: 0.8242 - val_loss: 0.5946 - learning_rate: 4.8828e-06\n",
      "Epoch 27/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:10:41\u001b[0m 9s/step - accuracy: 0.6562 - loss: 1.2772\n",
      "Epoch 27: val_loss did not improve from 0.59117\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1082s\u001b[0m 643ms/step - accuracy: 0.6562 - loss: 1.2772 - val_accuracy: 0.8211 - val_loss: 0.6144 - learning_rate: 4.8828e-06\n",
      "Epoch 28/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7455 - loss: 0.8944\n",
      "Epoch 28: val_loss did not improve from 0.59117\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15729s\u001b[0m 9s/step - accuracy: 0.7455 - loss: 0.8944 - val_accuracy: 0.8258 - val_loss: 0.6081 - learning_rate: 2.4414e-06\n",
      "Epoch 29/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7496 - loss: 0.8795\n",
      "Epoch 29: val_loss improved from 0.59117 to 0.59043, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15683s\u001b[0m 9s/step - accuracy: 0.7496 - loss: 0.8795 - val_accuracy: 0.8281 - val_loss: 0.5904 - learning_rate: 2.4414e-06\n",
      "Epoch 30/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:07:00\u001b[0m 9s/step - accuracy: 0.6875 - loss: 1.2865\n",
      "Epoch 30: val_loss did not improve from 0.59043\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1070s\u001b[0m 635ms/step - accuracy: 0.6875 - loss: 1.2865 - val_accuracy: 0.8267 - val_loss: 0.5973 - learning_rate: 2.4414e-06\n",
      "Epoch 31/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7456 - loss: 0.8900\n",
      "Epoch 31: val_loss did not improve from 0.59043\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15671s\u001b[0m 9s/step - accuracy: 0.7456 - loss: 0.8900 - val_accuracy: 0.8210 - val_loss: 0.6124 - learning_rate: 2.4414e-06\n",
      "Epoch 32/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7468 - loss: 0.8893\n",
      "Epoch 32: val_loss did not improve from 0.59043\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15687s\u001b[0m 9s/step - accuracy: 0.7468 - loss: 0.8893 - val_accuracy: 0.8243 - val_loss: 0.6014 - learning_rate: 2.4414e-06\n",
      "Epoch 33/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:07:35\u001b[0m 9s/step - accuracy: 0.7812 - loss: 0.5984\n",
      "Epoch 33: val_loss did not improve from 0.59043\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1070s\u001b[0m 636ms/step - accuracy: 0.7812 - loss: 0.5984 - val_accuracy: 0.8249 - val_loss: 0.6034 - learning_rate: 2.4414e-06\n",
      "Epoch 34/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7446 - loss: 0.8915\n",
      "Epoch 34: val_loss did not improve from 0.59043\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15646s\u001b[0m 9s/step - accuracy: 0.7446 - loss: 0.8915 - val_accuracy: 0.8222 - val_loss: 0.6058 - learning_rate: 2.4414e-06\n",
      "Epoch 35/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7489 - loss: 0.8890\n",
      "Epoch 35: val_loss improved from 0.59043 to 0.58939, saving model to ../model/best_model_adam.keras\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15652s\u001b[0m 9s/step - accuracy: 0.7489 - loss: 0.8890 - val_accuracy: 0.8282 - val_loss: 0.5894 - learning_rate: 1.2207e-06\n",
      "Epoch 36/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:09:33\u001b[0m 9s/step - accuracy: 0.7812 - loss: 0.7564\n",
      "Epoch 36: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1081s\u001b[0m 642ms/step - accuracy: 0.7812 - loss: 0.7564 - val_accuracy: 0.8229 - val_loss: 0.6137 - learning_rate: 1.2207e-06\n",
      "Epoch 37/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7411 - loss: 0.8981\n",
      "Epoch 37: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15701s\u001b[0m 9s/step - accuracy: 0.7411 - loss: 0.8981 - val_accuracy: 0.8307 - val_loss: 0.5928 - learning_rate: 1.2207e-06\n",
      "Epoch 38/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7449 - loss: 0.8918\n",
      "Epoch 38: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15673s\u001b[0m 9s/step - accuracy: 0.7449 - loss: 0.8918 - val_accuracy: 0.8283 - val_loss: 0.5958 - learning_rate: 1.2207e-06\n",
      "Epoch 39/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:04:40\u001b[0m 9s/step - accuracy: 0.6875 - loss: 1.3406\n",
      "Epoch 39: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1072s\u001b[0m 637ms/step - accuracy: 0.6875 - loss: 1.3406 - val_accuracy: 0.8256 - val_loss: 0.6057 - learning_rate: 1.2207e-06\n",
      "Epoch 40/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7470 - loss: 0.8899\n",
      "Epoch 40: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15732s\u001b[0m 9s/step - accuracy: 0.7470 - loss: 0.8899 - val_accuracy: 0.8222 - val_loss: 0.6125 - learning_rate: 1.2207e-06\n",
      "Epoch 41/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7460 - loss: 0.8929\n",
      "Epoch 41: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15680s\u001b[0m 9s/step - accuracy: 0.7460 - loss: 0.8929 - val_accuracy: 0.8241 - val_loss: 0.5942 - learning_rate: 1.0000e-06\n",
      "Epoch 42/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:04:59\u001b[0m 9s/step - accuracy: 0.7188 - loss: 1.0338\n",
      "Epoch 42: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1072s\u001b[0m 637ms/step - accuracy: 0.7188 - loss: 1.0338 - val_accuracy: 0.8260 - val_loss: 0.6026 - learning_rate: 1.0000e-06\n",
      "Epoch 43/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7433 - loss: 0.9032\n",
      "Epoch 43: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15669s\u001b[0m 9s/step - accuracy: 0.7433 - loss: 0.9032 - val_accuracy: 0.8203 - val_loss: 0.6107 - learning_rate: 1.0000e-06\n",
      "Epoch 44/70\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.7417 - loss: 0.9049\n",
      "Epoch 44: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15739s\u001b[0m 9s/step - accuracy: 0.7417 - loss: 0.9049 - val_accuracy: 0.8278 - val_loss: 0.5973 - learning_rate: 1.0000e-06\n",
      "Epoch 45/70\n",
      "\u001b[1m   1/1671\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:06:27\u001b[0m 9s/step - accuracy: 0.7812 - loss: 0.9411\n",
      "Epoch 45: val_loss did not improve from 0.58939\n",
      "\u001b[1m1671/1671\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1081s\u001b[0m 642ms/step - accuracy: 0.7812 - loss: 0.9411 - val_accuracy: 0.8257 - val_loss: 0.6030 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "                    train_generator,\n",
    "                    steps_per_epoch=train_generator.samples // batch_size,\n",
    "                    epochs=70,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_generator.samples // batch_size,\n",
    "                    callbacks=callbacks\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1111s\u001b[0m 3s/step - accuracy: 0.1395 - loss: 4.4459\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 성능 평가\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['accuracy'], label='train_accuracy', c='blue')\n",
    "plt.plot(history.epoch, history.history['val_accuracy'], label='validation_accuracy', c='skyblue', marker='o')\n",
    "plt.plot(history.epoch, history.history['loss'], label='train_loss', c='orange')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='validation_loss', c='salmon', marker='o')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45000 images belonging to 150 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir2 = \"../../../k_food_datasets/test\"\n",
    "test_generator2 = ImageDataGenerator().flow_from_directory(\n",
    "    test_dir2,\n",
    "    target_size=(256, 256),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1070s\u001b[0m 3s/step - accuracy: 0.0918 - loss: 4.5699\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 성능 평가 2\n",
    "test_loss, test_acc = model.evaluate(test_generator2, steps=test_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
