{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tf_keras\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger, TensorBoard\n",
    "from tensorflow.keras.mixed_precision import set_global_policy, LossScaleOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 온라인 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 설계 함수\n",
    "def create_model(input_shape=(256, 256, 3), num_classes=150):\n",
    "    base_model = tf.keras.applications.ResNet101(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Conv1 ~ Conv3 freeze, Conv4 ~ Conv5 학습\n",
    "    for layer in base_model.layers[:143]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    for layer in base_model.layers[143:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # 완전 연결층 추가\n",
    "    x = base_model.output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)  # 150개의 클래스\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    optimizer = SGD(learning_rate=0.01, momentum=0.9, decay=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정 함수\n",
    "def get_callbacks(model_save_path='D:/Work/3rd_pj/k_food_datasets/model_best.keras'):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(model_save_path, monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=1)\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    return [early_stopping, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 제너레이터 함수\n",
    "def get_data_generators(dataset_dir, target_size=(256, 256), batch_size=16):\n",
    "    # ImageDataGenerator 설정\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/train\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/validation\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        f\"{dataset_dir}/test\",\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 훈련 및 평가 함수\n",
    "def train_and_evaluate_model(model, train_generator, val_generator, test_generator, callbacks, epochs=30, batch_size=16):\n",
    "    # 모델 훈련\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=val_generator.samples // batch_size,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # 테스트 데이터로 성능 평가\n",
    "    test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // batch_size)\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 학습 함수\n",
    "def run_training_on_datasets(base_dir, dataset_from, dataset_to, initial_model_path='../model/best_model_with_rn101.keras'):\n",
    "    # 모델이 주어지지 않으면 새로 생성, 또는 기존에 저장된 모델 불러오기\n",
    "    if os.path.exists(initial_model_path):\n",
    "        model = load_model(initial_model_path)  # 기존에 저장된 모델을 불러옴\n",
    "        print(f\"Loaded model from {initial_model_path}\")\n",
    "    else:\n",
    "        model = create_model()  # 처음부터 모델을 새로 생성\n",
    "        print(\"No existing model found, creating a new one.\")\n",
    "\n",
    "    # 지정한 범위 내 데이터셋만 학습\n",
    "    for i in range(dataset_from, dataset_to):\n",
    "        dataset_dir = f\"{base_dir}/dataset{i}\"\n",
    "        \n",
    "        # 모델 저장 경로 (최고 성능 모델을 이 파일에 저장)\n",
    "        model_save_path = initial_model_path  # 경로와 이름을 그대로 사용\n",
    "        \n",
    "        # 콜백 설정\n",
    "        callbacks = get_callbacks(model_save_path)\n",
    "        \n",
    "        # 데이터 제너레이터 생성\n",
    "        train_generator, val_generator, test_generator = get_data_generators(dataset_dir)\n",
    "        \n",
    "        # 모델 훈련 및 성능 평가\n",
    "        test_acc = train_and_evaluate_model(model, train_generator, val_generator, test_generator, callbacks)\n",
    "        \n",
    "        print(f\"Dataset {i} - Test accuracy: {test_acc}\")\n",
    "\n",
    "    return model  # 학습이 끝난 모델을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing model found, creating a new one.\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.0076 - loss: 5.6983\n",
      "Epoch 1: val_loss improved from inf to 4.83258, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6706s\u001b[0m 5s/step - accuracy: 0.0076 - loss: 5.6981 - val_accuracy: 0.0116 - val_loss: 4.8326 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:29\u001b[0m 5s/step - accuracy: 0.0000e+00 - loss: 4.9045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 4.83258 to 4.83192, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 361ms/step - accuracy: 0.0000e+00 - loss: 4.9045 - val_accuracy: 0.0111 - val_loss: 4.8319 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0145 - loss: 4.8225\n",
      "Epoch 3: val_loss did not improve from 4.83192\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6209s\u001b[0m 5s/step - accuracy: 0.0145 - loss: 4.8224 - val_accuracy: 0.0309 - val_loss: 4.8342 - learning_rate: 0.0100\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:28\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.6935\n",
      "Epoch 4: val_loss did not improve from 4.83192\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 350ms/step - accuracy: 0.0000e+00 - loss: 4.6935 - val_accuracy: 0.0309 - val_loss: 4.8530 - learning_rate: 0.0100\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0260 - loss: 4.4706\n",
      "Epoch 5: val_loss improved from 4.83192 to 4.12353, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6237s\u001b[0m 5s/step - accuracy: 0.0260 - loss: 4.4705 - val_accuracy: 0.0830 - val_loss: 4.1235 - learning_rate: 0.0100\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:15\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 4.3030\n",
      "Epoch 6: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 350ms/step - accuracy: 0.0000e+00 - loss: 4.3030 - val_accuracy: 0.0810 - val_loss: 4.1308 - learning_rate: 0.0100\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.0734 - loss: 4.0419\n",
      "Epoch 7: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6183s\u001b[0m 5s/step - accuracy: 0.0734 - loss: 4.0417 - val_accuracy: 0.1552 - val_loss: 36.2028 - learning_rate: 0.0100\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 4s/step - accuracy: 0.0625 - loss: 4.1591\n",
      "Epoch 8: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 355ms/step - accuracy: 0.0625 - loss: 4.1591 - val_accuracy: 0.1559 - val_loss: 35.8441 - learning_rate: 0.0100\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.1770 - loss: 3.3432\n",
      "Epoch 9: val_loss did not improve from 4.12353\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6180s\u001b[0m 5s/step - accuracy: 0.1770 - loss: 3.3432 - val_accuracy: 0.3263 - val_loss: 4.1579 - learning_rate: 0.0100\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:54\u001b[0m 4s/step - accuracy: 0.2500 - loss: 2.7067\n",
      "Epoch 10: val_loss improved from 4.12353 to 4.11211, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 355ms/step - accuracy: 0.2500 - loss: 2.7067 - val_accuracy: 0.3265 - val_loss: 4.1121 - learning_rate: 0.0100\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2465 - loss: 2.9563\n",
      "Epoch 11: val_loss did not improve from 4.11211\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6197s\u001b[0m 5s/step - accuracy: 0.2465 - loss: 2.9563 - val_accuracy: 0.0914 - val_loss: 288.3196 - learning_rate: 0.0100\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:35\u001b[0m 4s/step - accuracy: 0.4375 - loss: 2.5502\n",
      "Epoch 12: val_loss did not improve from 4.11211\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 356ms/step - accuracy: 0.4375 - loss: 2.5502 - val_accuracy: 0.0932 - val_loss: 282.4831 - learning_rate: 0.0100\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2928 - loss: 2.7582\n",
      "Epoch 13: val_loss improved from 4.11211 to 2.06562, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6189s\u001b[0m 5s/step - accuracy: 0.2928 - loss: 2.7582 - val_accuracy: 0.4444 - val_loss: 2.0656 - learning_rate: 0.0100\n",
      "Epoch 14/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:53\u001b[0m 4s/step - accuracy: 0.3125 - loss: 2.3432\n",
      "Epoch 14: val_loss did not improve from 2.06562\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 354ms/step - accuracy: 0.3125 - loss: 2.3432 - val_accuracy: 0.4437 - val_loss: 2.0665 - learning_rate: 0.0100\n",
      "Epoch 15/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3611 - loss: 2.4022\n",
      "Epoch 15: val_loss did not improve from 2.06562\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6192s\u001b[0m 5s/step - accuracy: 0.3611 - loss: 2.4021 - val_accuracy: 0.4824 - val_loss: 2.4574 - learning_rate: 0.0100\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 2s/step - accuracy: 0.4629 - loss: 2.0375\n",
      "Dataset 0 - Test accuracy: 0.4528469741344452\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.2875 - loss: 2.8132\n",
      "Epoch 1: val_loss improved from inf to 1.88420, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6410s\u001b[0m 5s/step - accuracy: 0.2875 - loss: 2.8131 - val_accuracy: 0.4996 - val_loss: 1.8842 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:10\u001b[0m 4s/step - accuracy: 0.2500 - loss: 2.7772\n",
      "Epoch 2: val_loss did not improve from 1.88420\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 362ms/step - accuracy: 0.2500 - loss: 2.7772 - val_accuracy: 0.4973 - val_loss: 1.8853 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001b[1m 779/1312\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m39:29\u001b[0m 4s/step - accuracy: 0.3884 - loss: 2.3034"
     ]
    }
   ],
   "source": [
    "# 첫날 학습\n",
    "best_model_day1 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets', \n",
    "    dataset_from=0, \n",
    "    dataset_to=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3753 - loss: 2.3215\n",
      "Epoch 1: val_loss improved from inf to 1.81550, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6226s\u001b[0m 5s/step - accuracy: 0.3753 - loss: 2.3215 - val_accuracy: 0.5122 - val_loss: 1.8155 - learning_rate: 0.0100\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:31\u001b[0m 4s/step - accuracy: 0.5000 - loss: 2.3280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.81550 to 1.81311, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 354ms/step - accuracy: 0.5000 - loss: 2.3280 - val_accuracy: 0.5125 - val_loss: 1.8131 - learning_rate: 0.0100\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4507 - loss: 2.0064\n",
      "Epoch 3: val_loss improved from 1.81311 to 1.62616, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.4507 - loss: 2.0064 - val_accuracy: 0.5614 - val_loss: 1.6262 - learning_rate: 0.0100\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:18\u001b[0m 4s/step - accuracy: 0.4375 - loss: 2.1665\n",
      "Epoch 4: val_loss did not improve from 1.62616\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 355ms/step - accuracy: 0.4375 - loss: 2.1665 - val_accuracy: 0.5616 - val_loss: 1.6288 - learning_rate: 0.0100\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5173 - loss: 1.7296\n",
      "Epoch 5: val_loss improved from 1.62616 to 1.62431, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6087s\u001b[0m 5s/step - accuracy: 0.5173 - loss: 1.7296 - val_accuracy: 0.5596 - val_loss: 1.6243 - learning_rate: 0.0100\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:22\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.6187\n",
      "Epoch 6: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 343ms/step - accuracy: 0.5000 - loss: 1.6187 - val_accuracy: 0.5596 - val_loss: 1.6287 - learning_rate: 0.0100\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5669 - loss: 1.4853\n",
      "Epoch 7: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6290s\u001b[0m 5s/step - accuracy: 0.5669 - loss: 1.4854 - val_accuracy: 0.5494 - val_loss: 1.7073 - learning_rate: 0.0100\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:02\u001b[0m 4s/step - accuracy: 0.6875 - loss: 1.2153\n",
      "Epoch 8: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 351ms/step - accuracy: 0.6875 - loss: 1.2153 - val_accuracy: 0.5463 - val_loss: 1.7165 - learning_rate: 0.0100\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6256 - loss: 1.2650\n",
      "Epoch 9: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6209s\u001b[0m 5s/step - accuracy: 0.6256 - loss: 1.2650 - val_accuracy: 0.5576 - val_loss: 1.7150 - learning_rate: 0.0100\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:51\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.3297\n",
      "Epoch 10: val_loss did not improve from 1.62431\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 343ms/step - accuracy: 0.5000 - loss: 1.3297 - val_accuracy: 0.5565 - val_loss: 1.7180 - learning_rate: 0.0100\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7244 - loss: 0.9106\n",
      "Epoch 11: val_loss improved from 1.62431 to 1.61108, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6082s\u001b[0m 5s/step - accuracy: 0.7244 - loss: 0.9106 - val_accuracy: 0.6056 - val_loss: 1.6111 - learning_rate: 0.0050\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:51\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.6271\n",
      "Epoch 12: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.5000 - loss: 1.6271 - val_accuracy: 0.6039 - val_loss: 1.6131 - learning_rate: 0.0050\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7967 - loss: 0.6572\n",
      "Epoch 13: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6101s\u001b[0m 5s/step - accuracy: 0.7967 - loss: 0.6573 - val_accuracy: 0.5979 - val_loss: 1.7200 - learning_rate: 0.0050\n",
      "Epoch 14/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:09\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.7110\n",
      "Epoch 14: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 343ms/step - accuracy: 0.8125 - loss: 0.7110 - val_accuracy: 0.5985 - val_loss: 1.7185 - learning_rate: 0.0050\n",
      "Epoch 15/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8278 - loss: 0.5445\n",
      "Epoch 15: val_loss did not improve from 1.61108\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6088s\u001b[0m 5s/step - accuracy: 0.8278 - loss: 0.5445 - val_accuracy: 0.5876 - val_loss: 1.8881 - learning_rate: 0.0050\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 2s/step - accuracy: 0.5784 - loss: 1.6641\n",
      "Dataset 1 - Test accuracy: 0.5787366628646851\n"
     ]
    }
   ],
   "source": [
    "# 두번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day2 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=1,\n",
    "    dataset_to=2,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4479 - loss: 2.2937\n",
      "Epoch 1: val_loss improved from inf to 1.37227, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6286s\u001b[0m 5s/step - accuracy: 0.4479 - loss: 2.2935 - val_accuracy: 0.6259 - val_loss: 1.3723 - learning_rate: 0.0050\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:28\u001b[0m 4s/step - accuracy: 0.4375 - loss: 2.9725"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 348ms/step - accuracy: 0.4375 - loss: 2.9725 - val_accuracy: 0.6252 - val_loss: 1.3727 - learning_rate: 0.0050\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5715 - loss: 1.5536\n",
      "Epoch 3: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6096s\u001b[0m 5s/step - accuracy: 0.5715 - loss: 1.5536 - val_accuracy: 0.6210 - val_loss: 1.3816 - learning_rate: 0.0050\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:50\u001b[0m 4s/step - accuracy: 0.3125 - loss: 2.3637\n",
      "Epoch 4: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 345ms/step - accuracy: 0.3125 - loss: 2.3637 - val_accuracy: 0.6208 - val_loss: 1.3805 - learning_rate: 0.0050\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6502 - loss: 1.2152\n",
      "Epoch 5: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6053s\u001b[0m 5s/step - accuracy: 0.6502 - loss: 1.2152 - val_accuracy: 0.6161 - val_loss: 1.4329 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:51\u001b[0m 4s/step - accuracy: 0.6250 - loss: 1.6757\n",
      "Epoch 6: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.6250 - loss: 1.6757 - val_accuracy: 0.6172 - val_loss: 1.4319 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7437 - loss: 0.8655\n",
      "Epoch 7: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6228s\u001b[0m 5s/step - accuracy: 0.7437 - loss: 0.8655 - val_accuracy: 0.6426 - val_loss: 1.3994 - learning_rate: 0.0025\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:50:17\u001b[0m 5s/step - accuracy: 0.6250 - loss: 0.7405\n",
      "Epoch 8: val_loss did not improve from 1.37227\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 383ms/step - accuracy: 0.6250 - loss: 0.7405 - val_accuracy: 0.6430 - val_loss: 1.4002 - learning_rate: 0.0025\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 2s/step - accuracy: 0.6304 - loss: 1.3595\n",
      "Dataset 2 - Test accuracy: 0.6270017623901367\n"
     ]
    }
   ],
   "source": [
    "# 세번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day3 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=2,\n",
    "    dataset_to=3,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4838 - loss: 1.9577\n",
      "Epoch 1: val_loss improved from inf to 1.32763, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6549s\u001b[0m 5s/step - accuracy: 0.4838 - loss: 1.9577 - val_accuracy: 0.6312 - val_loss: 1.3276 - learning_rate: 0.0050\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:18\u001b[0m 4s/step - accuracy: 0.4375 - loss: 1.7730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss improved from 1.32763 to 1.32750, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 354ms/step - accuracy: 0.4375 - loss: 1.7730 - val_accuracy: 0.6306 - val_loss: 1.3275 - learning_rate: 0.0050\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.5628 - loss: 1.5639\n",
      "Epoch 3: val_loss improved from 1.32750 to 1.31480, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6692s\u001b[0m 5s/step - accuracy: 0.5628 - loss: 1.5640 - val_accuracy: 0.6346 - val_loss: 1.3148 - learning_rate: 0.0050\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:45:32\u001b[0m 5s/step - accuracy: 0.5625 - loss: 1.8617\n",
      "Epoch 4: val_loss improved from 1.31480 to 1.31355, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 382ms/step - accuracy: 0.5625 - loss: 1.8617 - val_accuracy: 0.6352 - val_loss: 1.3135 - learning_rate: 0.0050\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6373 - loss: 1.2348\n",
      "Epoch 5: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6413s\u001b[0m 5s/step - accuracy: 0.6373 - loss: 1.2348 - val_accuracy: 0.6123 - val_loss: 1.4146 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:47:31\u001b[0m 5s/step - accuracy: 0.6250 - loss: 0.9826\n",
      "Epoch 6: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m488s\u001b[0m 368ms/step - accuracy: 0.6250 - loss: 0.9826 - val_accuracy: 0.6137 - val_loss: 1.4145 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7008 - loss: 0.9985\n",
      "Epoch 7: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6349s\u001b[0m 5s/step - accuracy: 0.7008 - loss: 0.9985 - val_accuracy: 0.6137 - val_loss: 1.4485 - learning_rate: 0.0050\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:23\u001b[0m 5s/step - accuracy: 0.6875 - loss: 0.8997\n",
      "Epoch 8: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 344ms/step - accuracy: 0.6875 - loss: 0.8997 - val_accuracy: 0.6099 - val_loss: 1.4507 - learning_rate: 0.0050\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7658 - loss: 0.7708\n",
      "Epoch 9: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6076s\u001b[0m 5s/step - accuracy: 0.7658 - loss: 0.7708 - val_accuracy: 0.6008 - val_loss: 1.5466 - learning_rate: 0.0050\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:15\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.7469\n",
      "Epoch 10: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 347ms/step - accuracy: 0.7500 - loss: 0.7469 - val_accuracy: 0.6012 - val_loss: 1.5488 - learning_rate: 0.0025\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8252 - loss: 0.5677\n",
      "Epoch 11: val_loss did not improve from 1.31355\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6070s\u001b[0m 5s/step - accuracy: 0.8252 - loss: 0.5677 - val_accuracy: 0.6383 - val_loss: 1.4237 - learning_rate: 0.0025\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 2s/step - accuracy: 0.6355 - loss: 1.3219\n",
      "Dataset 3 - Test accuracy: 0.6323398351669312\n"
     ]
    }
   ],
   "source": [
    "# 4번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day4 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=3,\n",
    "    dataset_to=4,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5190 - loss: 1.8278\n",
      "Epoch 1: val_loss improved from inf to 1.24370, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6180s\u001b[0m 5s/step - accuracy: 0.5190 - loss: 1.8278 - val_accuracy: 0.6615 - val_loss: 1.2437 - learning_rate: 0.0050\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:34\u001b[0m 4s/step - accuracy: 0.4375 - loss: 1.9475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 1.24370\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.4375 - loss: 1.9475 - val_accuracy: 0.6613 - val_loss: 1.2448 - learning_rate: 0.0050\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5989 - loss: 1.4193\n",
      "Epoch 3: val_loss improved from 1.24370 to 1.22720, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6134s\u001b[0m 5s/step - accuracy: 0.5989 - loss: 1.4193 - val_accuracy: 0.6581 - val_loss: 1.2272 - learning_rate: 0.0050\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:22\u001b[0m 4s/step - accuracy: 0.6250 - loss: 0.9612\n",
      "Epoch 4: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 350ms/step - accuracy: 0.6250 - loss: 0.9612 - val_accuracy: 0.6581 - val_loss: 1.2286 - learning_rate: 0.0050\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6751 - loss: 1.1224\n",
      "Epoch 5: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6122s\u001b[0m 5s/step - accuracy: 0.6751 - loss: 1.1224 - val_accuracy: 0.6446 - val_loss: 1.2865 - learning_rate: 0.0050\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:31\u001b[0m 4s/step - accuracy: 0.6250 - loss: 1.4102\n",
      "Epoch 6: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.6250 - loss: 1.4102 - val_accuracy: 0.6435 - val_loss: 1.2889 - learning_rate: 0.0050\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7458 - loss: 0.8687\n",
      "Epoch 7: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6123s\u001b[0m 5s/step - accuracy: 0.7458 - loss: 0.8687 - val_accuracy: 0.6479 - val_loss: 1.4055 - learning_rate: 0.0050\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:44\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.5852\n",
      "Epoch 8: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 345ms/step - accuracy: 0.7500 - loss: 0.5852 - val_accuracy: 0.6472 - val_loss: 1.3998 - learning_rate: 0.0050\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8185 - loss: 0.5974\n",
      "Epoch 9: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6110s\u001b[0m 5s/step - accuracy: 0.8185 - loss: 0.5973 - val_accuracy: 0.6628 - val_loss: 1.3402 - learning_rate: 0.0025\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:24\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.2563\n",
      "Epoch 10: val_loss did not improve from 1.22720\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.9375 - loss: 0.2563 - val_accuracy: 0.6630 - val_loss: 1.3408 - learning_rate: 0.0025\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 2s/step - accuracy: 0.6532 - loss: 1.2287\n",
      "Dataset 4 - Test accuracy: 0.6499110460281372\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5582 - loss: 1.6624\n",
      "Epoch 1: val_loss improved from inf to 1.06614, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6180s\u001b[0m 5s/step - accuracy: 0.5582 - loss: 1.6623 - val_accuracy: 0.7046 - val_loss: 1.0661 - learning_rate: 0.0025\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:12\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.6704\n",
      "Epoch 2: val_loss did not improve from 1.06614\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 351ms/step - accuracy: 0.5625 - loss: 1.6704 - val_accuracy: 0.7035 - val_loss: 1.0664 - learning_rate: 0.0025\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6304 - loss: 1.3113\n",
      "Epoch 3: val_loss improved from 1.06614 to 1.02690, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6133s\u001b[0m 5s/step - accuracy: 0.6304 - loss: 1.3113 - val_accuracy: 0.7151 - val_loss: 1.0269 - learning_rate: 0.0025\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:07\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.9041\n",
      "Epoch 4: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 349ms/step - accuracy: 0.7500 - loss: 0.9041 - val_accuracy: 0.7153 - val_loss: 1.0271 - learning_rate: 0.0025\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6952 - loss: 1.0673\n",
      "Epoch 5: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6170s\u001b[0m 5s/step - accuracy: 0.6952 - loss: 1.0673 - val_accuracy: 0.7113 - val_loss: 1.0454 - learning_rate: 0.0025\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:51\u001b[0m 5s/step - accuracy: 0.6250 - loss: 1.0419\n",
      "Epoch 6: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 347ms/step - accuracy: 0.6250 - loss: 1.0419 - val_accuracy: 0.7106 - val_loss: 1.0464 - learning_rate: 0.0025\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7456 - loss: 0.8663\n",
      "Epoch 7: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6102s\u001b[0m 5s/step - accuracy: 0.7456 - loss: 0.8663 - val_accuracy: 0.7066 - val_loss: 1.0963 - learning_rate: 0.0025\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:46\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6310\n",
      "Epoch 8: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 343ms/step - accuracy: 0.7500 - loss: 0.6310 - val_accuracy: 0.7073 - val_loss: 1.0971 - learning_rate: 0.0025\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8144 - loss: 0.6240\n",
      "Epoch 9: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6109s\u001b[0m 5s/step - accuracy: 0.8144 - loss: 0.6240 - val_accuracy: 0.7117 - val_loss: 1.0786 - learning_rate: 0.0012\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:25\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.7847\n",
      "Epoch 10: val_loss did not improve from 1.02690\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 353ms/step - accuracy: 0.5625 - loss: 1.7847 - val_accuracy: 0.7124 - val_loss: 1.0785 - learning_rate: 0.0012\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m473s\u001b[0m 2s/step - accuracy: 0.7040 - loss: 1.0268\n",
      "Dataset 5 - Test accuracy: 0.6977313160896301\n"
     ]
    }
   ],
   "source": [
    "# 5번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day5 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=4,\n",
    "    dataset_to=6,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5965 - loss: 1.5135\n",
      "Epoch 1: val_loss improved from inf to 0.96269, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6129s\u001b[0m 5s/step - accuracy: 0.5965 - loss: 1.5135 - val_accuracy: 0.7260 - val_loss: 0.9627 - learning_rate: 0.0025\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:17\u001b[0m 4s/step - accuracy: 0.5000 - loss: 2.2539\n",
      "Epoch 2: val_loss did not improve from 0.96269\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.5000 - loss: 2.2539 - val_accuracy: 0.7260 - val_loss: 0.9629 - learning_rate: 0.0025\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6685 - loss: 1.1742\n",
      "Epoch 3: val_loss improved from 0.96269 to 0.95593, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6017s\u001b[0m 5s/step - accuracy: 0.6685 - loss: 1.1742 - val_accuracy: 0.7320 - val_loss: 0.9559 - learning_rate: 0.0025\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 4s/step - accuracy: 0.6875 - loss: 0.8449\n",
      "Epoch 4: val_loss improved from 0.95593 to 0.95541, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 347ms/step - accuracy: 0.6875 - loss: 0.8449 - val_accuracy: 0.7322 - val_loss: 0.9554 - learning_rate: 0.0025\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7258 - loss: 0.9246\n",
      "Epoch 5: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6021s\u001b[0m 5s/step - accuracy: 0.7258 - loss: 0.9246 - val_accuracy: 0.7240 - val_loss: 0.9961 - learning_rate: 0.0025\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:40\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4129\n",
      "Epoch 6: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 347ms/step - accuracy: 0.8750 - loss: 0.4129 - val_accuracy: 0.7240 - val_loss: 0.9967 - learning_rate: 0.0025\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7788 - loss: 0.7477\n",
      "Epoch 7: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6015s\u001b[0m 5s/step - accuracy: 0.7788 - loss: 0.7477 - val_accuracy: 0.7293 - val_loss: 1.0039 - learning_rate: 0.0025\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:28\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.5739\n",
      "Epoch 8: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.8125 - loss: 0.5739 - val_accuracy: 0.7293 - val_loss: 1.0043 - learning_rate: 0.0025\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8219 - loss: 0.5659\n",
      "Epoch 9: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6015s\u001b[0m 5s/step - accuracy: 0.8219 - loss: 0.5659 - val_accuracy: 0.7166 - val_loss: 1.0863 - learning_rate: 0.0025\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:55\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4695\n",
      "Epoch 10: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 341ms/step - accuracy: 0.8750 - loss: 0.4695 - val_accuracy: 0.7146 - val_loss: 1.0895 - learning_rate: 0.0012\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8743 - loss: 0.4157\n",
      "Epoch 11: val_loss did not improve from 0.95541\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6035s\u001b[0m 5s/step - accuracy: 0.8743 - loss: 0.4157 - val_accuracy: 0.7233 - val_loss: 1.0669 - learning_rate: 0.0012\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m479s\u001b[0m 2s/step - accuracy: 0.7364 - loss: 0.9066\n",
      "Dataset 6 - Test accuracy: 0.7364323735237122\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5870 - loss: 1.5514\n",
      "Epoch 1: val_loss improved from inf to 0.98256, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6094s\u001b[0m 5s/step - accuracy: 0.5870 - loss: 1.5514 - val_accuracy: 0.7260 - val_loss: 0.9826 - learning_rate: 0.0012\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:35\u001b[0m 5s/step - accuracy: 0.6250 - loss: 2.2156\n",
      "Epoch 2: val_loss did not improve from 0.98256\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 340ms/step - accuracy: 0.6250 - loss: 2.2156 - val_accuracy: 0.7246 - val_loss: 0.9827 - learning_rate: 0.0012\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6502 - loss: 1.2657\n",
      "Epoch 3: val_loss improved from 0.98256 to 0.96856, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6032s\u001b[0m 5s/step - accuracy: 0.6502 - loss: 1.2657 - val_accuracy: 0.7273 - val_loss: 0.9686 - learning_rate: 0.0012\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:45\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.7102\n",
      "Epoch 4: val_loss improved from 0.96856 to 0.96816, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.5625 - loss: 1.7102 - val_accuracy: 0.7275 - val_loss: 0.9682 - learning_rate: 0.0012\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6938 - loss: 1.0840\n",
      "Epoch 5: val_loss improved from 0.96816 to 0.95314, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6039s\u001b[0m 5s/step - accuracy: 0.6938 - loss: 1.0840 - val_accuracy: 0.7324 - val_loss: 0.9531 - learning_rate: 0.0012\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:46\u001b[0m 4s/step - accuracy: 0.5000 - loss: 1.2286\n",
      "Epoch 6: val_loss improved from 0.95314 to 0.95232, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 342ms/step - accuracy: 0.5000 - loss: 1.2286 - val_accuracy: 0.7318 - val_loss: 0.9523 - learning_rate: 0.0012\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7381 - loss: 0.9098\n",
      "Epoch 7: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6008s\u001b[0m 5s/step - accuracy: 0.7381 - loss: 0.9098 - val_accuracy: 0.7351 - val_loss: 0.9675 - learning_rate: 0.0012\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:15\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.9006\n",
      "Epoch 8: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 339ms/step - accuracy: 0.8125 - loss: 0.9006 - val_accuracy: 0.7358 - val_loss: 0.9660 - learning_rate: 0.0012\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7795 - loss: 0.7446\n",
      "Epoch 9: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6004s\u001b[0m 5s/step - accuracy: 0.7795 - loss: 0.7446 - val_accuracy: 0.7200 - val_loss: 1.0399 - learning_rate: 0.0012\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:07\u001b[0m 4s/step - accuracy: 0.6875 - loss: 0.7904\n",
      "Epoch 10: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.6875 - loss: 0.7904 - val_accuracy: 0.7211 - val_loss: 1.0399 - learning_rate: 0.0012\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8224 - loss: 0.5913\n",
      "Epoch 11: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6001s\u001b[0m 5s/step - accuracy: 0.8224 - loss: 0.5914 - val_accuracy: 0.7102 - val_loss: 1.0788 - learning_rate: 0.0012\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:12\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6758\n",
      "Epoch 12: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 339ms/step - accuracy: 0.7500 - loss: 0.6758 - val_accuracy: 0.7089 - val_loss: 1.0828 - learning_rate: 6.2500e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8698 - loss: 0.4491\n",
      "Epoch 13: val_loss did not improve from 0.95232\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5915s\u001b[0m 5s/step - accuracy: 0.8698 - loss: 0.4491 - val_accuracy: 0.7280 - val_loss: 1.0448 - learning_rate: 6.2500e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 2s/step - accuracy: 0.7303 - loss: 0.9197\n",
      "Dataset 7 - Test accuracy: 0.7333185076713562\n"
     ]
    }
   ],
   "source": [
    "# 6번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day6 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=6,\n",
    "    dataset_to=8,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6155 - loss: 1.4214\n",
      "Epoch 1: val_loss improved from inf to 0.91524, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6065s\u001b[0m 5s/step - accuracy: 0.6155 - loss: 1.4214 - val_accuracy: 0.7335 - val_loss: 0.9152 - learning_rate: 0.0012\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:12\u001b[0m 4s/step - accuracy: 0.5625 - loss: 0.9799\n",
      "Epoch 2: val_loss improved from 0.91524 to 0.91380, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 337ms/step - accuracy: 0.5625 - loss: 0.9799 - val_accuracy: 0.7342 - val_loss: 0.9138 - learning_rate: 0.0012\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6678 - loss: 1.1860\n",
      "Epoch 3: val_loss improved from 0.91380 to 0.90831, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5951s\u001b[0m 5s/step - accuracy: 0.6678 - loss: 1.1860 - val_accuracy: 0.7344 - val_loss: 0.9083 - learning_rate: 0.0012\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:35\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.7118\n",
      "Epoch 4: val_loss improved from 0.90831 to 0.90796, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.5625 - loss: 1.7118 - val_accuracy: 0.7353 - val_loss: 0.9080 - learning_rate: 0.0012\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7236 - loss: 0.9656\n",
      "Epoch 5: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6030s\u001b[0m 5s/step - accuracy: 0.7236 - loss: 0.9656 - val_accuracy: 0.7375 - val_loss: 0.9112 - learning_rate: 0.0012\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:55\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.7175\n",
      "Epoch 6: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 340ms/step - accuracy: 0.8750 - loss: 0.7175 - val_accuracy: 0.7391 - val_loss: 0.9107 - learning_rate: 0.0012\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7694 - loss: 0.7893\n",
      "Epoch 7: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6036s\u001b[0m 5s/step - accuracy: 0.7694 - loss: 0.7894 - val_accuracy: 0.7375 - val_loss: 0.9247 - learning_rate: 0.0012\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:03\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.6214\n",
      "Epoch 8: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.8750 - loss: 0.6214 - val_accuracy: 0.7387 - val_loss: 0.9252 - learning_rate: 0.0012\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8145 - loss: 0.6265\n",
      "Epoch 9: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5936s\u001b[0m 5s/step - accuracy: 0.8145 - loss: 0.6265 - val_accuracy: 0.7320 - val_loss: 0.9747 - learning_rate: 0.0012\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:14\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.3501\n",
      "Epoch 10: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 333ms/step - accuracy: 0.8750 - loss: 0.3501 - val_accuracy: 0.7322 - val_loss: 0.9750 - learning_rate: 6.2500e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8634 - loss: 0.4749\n",
      "Epoch 11: val_loss did not improve from 0.90796\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5900s\u001b[0m 4s/step - accuracy: 0.8634 - loss: 0.4749 - val_accuracy: 0.7398 - val_loss: 0.9673 - learning_rate: 6.2500e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 2s/step - accuracy: 0.7547 - loss: 0.8819\n",
      "Dataset 8 - Test accuracy: 0.7473309636116028\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6499 - loss: 1.2749\n",
      "Epoch 1: val_loss improved from inf to 0.78872, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5989s\u001b[0m 5s/step - accuracy: 0.6499 - loss: 1.2749 - val_accuracy: 0.7680 - val_loss: 0.7887 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:28\u001b[0m 4s/step - accuracy: 0.6875 - loss: 1.5735\n",
      "Epoch 2: val_loss improved from 0.78872 to 0.78713, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 340ms/step - accuracy: 0.6875 - loss: 1.5735 - val_accuracy: 0.7685 - val_loss: 0.7871 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6875 - loss: 1.1323\n",
      "Epoch 3: val_loss improved from 0.78713 to 0.77820, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5957s\u001b[0m 5s/step - accuracy: 0.6875 - loss: 1.1323 - val_accuracy: 0.7700 - val_loss: 0.7782 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:32:11\u001b[0m 4s/step - accuracy: 0.7500 - loss: 1.2073\n",
      "Epoch 4: val_loss did not improve from 0.77820\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 334ms/step - accuracy: 0.7500 - loss: 1.2073 - val_accuracy: 0.7702 - val_loss: 0.7788 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7158 - loss: 0.9906\n",
      "Epoch 5: val_loss improved from 0.77820 to 0.76484, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5923s\u001b[0m 5s/step - accuracy: 0.7158 - loss: 0.9906 - val_accuracy: 0.7729 - val_loss: 0.7648 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31:50\u001b[0m 4s/step - accuracy: 0.6875 - loss: 0.9255\n",
      "Epoch 6: val_loss improved from 0.76484 to 0.76300, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 343ms/step - accuracy: 0.6875 - loss: 0.9255 - val_accuracy: 0.7734 - val_loss: 0.7630 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7487 - loss: 0.8777\n",
      "Epoch 7: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6424s\u001b[0m 5s/step - accuracy: 0.7487 - loss: 0.8777 - val_accuracy: 0.7705 - val_loss: 0.7730 - learning_rate: 6.2500e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:26\u001b[0m 4s/step - accuracy: 0.4375 - loss: 1.2839\n",
      "Epoch 8: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 353ms/step - accuracy: 0.4375 - loss: 1.2839 - val_accuracy: 0.7702 - val_loss: 0.7721 - learning_rate: 6.2500e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7802 - loss: 0.7496\n",
      "Epoch 9: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6560s\u001b[0m 5s/step - accuracy: 0.7802 - loss: 0.7496 - val_accuracy: 0.7682 - val_loss: 0.7893 - learning_rate: 6.2500e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:44:00\u001b[0m 5s/step - accuracy: 0.7500 - loss: 0.6175\n",
      "Epoch 10: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 382ms/step - accuracy: 0.7500 - loss: 0.6175 - val_accuracy: 0.7685 - val_loss: 0.7898 - learning_rate: 6.2500e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8052 - loss: 0.6558\n",
      "Epoch 11: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6187s\u001b[0m 5s/step - accuracy: 0.8052 - loss: 0.6558 - val_accuracy: 0.7700 - val_loss: 0.7995 - learning_rate: 6.2500e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:04\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.3186\n",
      "Epoch 12: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 361ms/step - accuracy: 0.8750 - loss: 0.3186 - val_accuracy: 0.7707 - val_loss: 0.8001 - learning_rate: 3.1250e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8437 - loss: 0.5482\n",
      "Epoch 13: val_loss did not improve from 0.76300\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6418s\u001b[0m 5s/step - accuracy: 0.8437 - loss: 0.5482 - val_accuracy: 0.7669 - val_loss: 0.8014 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 2s/step - accuracy: 0.7690 - loss: 0.7846\n",
      "Dataset 9 - Test accuracy: 0.7702401876449585\n"
     ]
    }
   ],
   "source": [
    "# 7번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=8,\n",
    "    dataset_to=10,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6224 - loss: 1.3886\n",
      "Epoch 1: val_loss improved from inf to 0.92480, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6415s\u001b[0m 5s/step - accuracy: 0.6224 - loss: 1.3886 - val_accuracy: 0.7411 - val_loss: 0.9248 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:53\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.9614\n",
      "Epoch 2: val_loss improved from 0.92480 to 0.92296, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 353ms/step - accuracy: 0.5625 - loss: 1.9614 - val_accuracy: 0.7418 - val_loss: 0.9230 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6733 - loss: 1.1813\n",
      "Epoch 3: val_loss improved from 0.92296 to 0.91048, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6089s\u001b[0m 5s/step - accuracy: 0.6733 - loss: 1.1813 - val_accuracy: 0.7418 - val_loss: 0.9105 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:38\u001b[0m 4s/step - accuracy: 0.8125 - loss: 0.8616\n",
      "Epoch 4: val_loss improved from 0.91048 to 0.90927, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 348ms/step - accuracy: 0.8125 - loss: 0.8616 - val_accuracy: 0.7418 - val_loss: 0.9093 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7124 - loss: 1.0065\n",
      "Epoch 5: val_loss improved from 0.90927 to 0.90107, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6098s\u001b[0m 5s/step - accuracy: 0.7124 - loss: 1.0065 - val_accuracy: 0.7476 - val_loss: 0.9011 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:39:01\u001b[0m 5s/step - accuracy: 0.6250 - loss: 0.8521\n",
      "Epoch 6: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.6250 - loss: 0.8521 - val_accuracy: 0.7469 - val_loss: 0.9016 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7420 - loss: 0.8837\n",
      "Epoch 7: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6096s\u001b[0m 5s/step - accuracy: 0.7420 - loss: 0.8837 - val_accuracy: 0.7400 - val_loss: 0.9204 - learning_rate: 6.2500e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:20\u001b[0m 5s/step - accuracy: 0.8750 - loss: 0.4177\n",
      "Epoch 8: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 348ms/step - accuracy: 0.8750 - loss: 0.4177 - val_accuracy: 0.7409 - val_loss: 0.9195 - learning_rate: 6.2500e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7808 - loss: 0.7525\n",
      "Epoch 9: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6102s\u001b[0m 5s/step - accuracy: 0.7808 - loss: 0.7525 - val_accuracy: 0.7364 - val_loss: 0.9273 - learning_rate: 6.2500e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34:38\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.8019\n",
      "Epoch 10: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 351ms/step - accuracy: 0.7500 - loss: 0.8019 - val_accuracy: 0.7369 - val_loss: 0.9288 - learning_rate: 6.2500e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8163 - loss: 0.6151\n",
      "Epoch 11: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6110s\u001b[0m 5s/step - accuracy: 0.8163 - loss: 0.6151 - val_accuracy: 0.7373 - val_loss: 0.9304 - learning_rate: 3.1250e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:47\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.3962\n",
      "Epoch 12: val_loss did not improve from 0.90107\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.9375 - loss: 0.3962 - val_accuracy: 0.7375 - val_loss: 0.9291 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 2s/step - accuracy: 0.7316 - loss: 0.9292\n",
      "Dataset 0 - Test accuracy: 0.7388790249824524\n"
     ]
    }
   ],
   "source": [
    "# 8번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=0,\n",
    "    dataset_to=1,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7498 - loss: 0.8574\n",
      "Epoch 1: val_loss improved from inf to 0.94312, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6263s\u001b[0m 5s/step - accuracy: 0.7498 - loss: 0.8573 - val_accuracy: 0.7411 - val_loss: 0.9431 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:55\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.9336\n",
      "Epoch 2: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 346ms/step - accuracy: 0.7500 - loss: 0.9336 - val_accuracy: 0.7413 - val_loss: 0.9433 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8081 - loss: 0.6584\n",
      "Epoch 3: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6127s\u001b[0m 5s/step - accuracy: 0.8081 - loss: 0.6584 - val_accuracy: 0.7329 - val_loss: 0.9729 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:50\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.4767\n",
      "Epoch 4: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 347ms/step - accuracy: 0.9375 - loss: 0.4767 - val_accuracy: 0.7331 - val_loss: 0.9721 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8349 - loss: 0.5611\n",
      "Epoch 5: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6099s\u001b[0m 5s/step - accuracy: 0.8349 - loss: 0.5611 - val_accuracy: 0.7322 - val_loss: 0.9981 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:52\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.8940\n",
      "Epoch 6: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 344ms/step - accuracy: 0.7500 - loss: 0.8940 - val_accuracy: 0.7329 - val_loss: 0.9985 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8607 - loss: 0.4789\n",
      "Epoch 7: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6093s\u001b[0m 5s/step - accuracy: 0.8607 - loss: 0.4788 - val_accuracy: 0.7338 - val_loss: 1.0056 - learning_rate: 3.1250e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:36:19\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.3969\n",
      "Epoch 8: val_loss did not improve from 0.94312\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.9375 - loss: 0.3969 - val_accuracy: 0.7344 - val_loss: 1.0044 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 2s/step - accuracy: 0.7391 - loss: 0.9222\n",
      "Dataset 1 - Test accuracy: 0.7315391302108765\n"
     ]
    }
   ],
   "source": [
    "# 9번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=1,\n",
    "    dataset_to=2,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Epoch 1/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6545 - loss: 1.2665\n",
      "Epoch 1: val_loss improved from inf to 0.93930, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6228s\u001b[0m 5s/step - accuracy: 0.6545 - loss: 1.2665 - val_accuracy: 0.7369 - val_loss: 0.9393 - learning_rate: 6.2500e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:38:32\u001b[0m 5s/step - accuracy: 0.6250 - loss: 1.1542\n",
      "Epoch 2: val_loss did not improve from 0.93930\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.6250 - loss: 1.1542 - val_accuracy: 0.7362 - val_loss: 0.9401 - learning_rate: 6.2500e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7007 - loss: 1.0596\n",
      "Epoch 3: val_loss improved from 0.93930 to 0.93840, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6153s\u001b[0m 5s/step - accuracy: 0.7007 - loss: 1.0596 - val_accuracy: 0.7391 - val_loss: 0.9384 - learning_rate: 6.2500e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:37:09\u001b[0m 4s/step - accuracy: 0.5625 - loss: 1.1254\n",
      "Epoch 4: val_loss improved from 0.93840 to 0.93696, saving model to ../model/best_model_with_rn101.keras\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 351ms/step - accuracy: 0.5625 - loss: 1.1254 - val_accuracy: 0.7389 - val_loss: 0.9370 - learning_rate: 6.2500e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7387 - loss: 0.8996\n",
      "Epoch 5: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6080s\u001b[0m 5s/step - accuracy: 0.7387 - loss: 0.8996 - val_accuracy: 0.7371 - val_loss: 0.9477 - learning_rate: 6.2500e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:30\u001b[0m 4s/step - accuracy: 0.7500 - loss: 0.6344\n",
      "Epoch 6: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 345ms/step - accuracy: 0.7500 - loss: 0.6344 - val_accuracy: 0.7378 - val_loss: 0.9472 - learning_rate: 6.2500e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7773 - loss: 0.7678\n",
      "Epoch 7: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6115s\u001b[0m 5s/step - accuracy: 0.7773 - loss: 0.7679 - val_accuracy: 0.7329 - val_loss: 0.9686 - learning_rate: 6.2500e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:33:51\u001b[0m 4s/step - accuracy: 0.9375 - loss: 0.3235\n",
      "Epoch 8: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 344ms/step - accuracy: 0.9375 - loss: 0.3235 - val_accuracy: 0.7335 - val_loss: 0.9697 - learning_rate: 6.2500e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8029 - loss: 0.6517\n",
      "Epoch 9: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6098s\u001b[0m 5s/step - accuracy: 0.8029 - loss: 0.6517 - val_accuracy: 0.7226 - val_loss: 0.9975 - learning_rate: 6.2500e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m   1/1312\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:35:24\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.4287\n",
      "Epoch 10: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 344ms/step - accuracy: 0.8750 - loss: 0.4287 - val_accuracy: 0.7222 - val_loss: 0.9967 - learning_rate: 3.1250e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8430 - loss: 0.5202\n",
      "Epoch 11: val_loss did not improve from 0.93696\n",
      "\u001b[1m1312/1312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6074s\u001b[0m 5s/step - accuracy: 0.8430 - loss: 0.5202 - val_accuracy: 0.7226 - val_loss: 1.0159 - learning_rate: 3.1250e-04\n",
      "\u001b[1m281/281\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 2s/step - accuracy: 0.7459 - loss: 0.8915\n",
      "Dataset 2 - Test accuracy: 0.7404359579086304\n"
     ]
    }
   ],
   "source": [
    "# 10번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day7 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=2,\n",
    "    dataset_to=3,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from ../model/best_model_with_rn101.keras\n",
      "Found 21000 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n",
      "Found 4500 images belonging to 150 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\human\\.conda\\envs\\colab\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m 638/1312\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m52:09\u001b[0m 5s/step - accuracy: 0.7701 - loss: 0.7777"
     ]
    }
   ],
   "source": [
    "# 11번째 날 학습 (기존의 베스트 모델 불러오기)\n",
    "best_model_day11 = run_training_on_datasets(\n",
    "    base_dir='../../../k_food_datasets',\n",
    "    dataset_from=0,\n",
    "    dataset_to=10,\n",
    "    initial_model_path='../model/best_model_with_rn101.keras'  # 이전에 저장된 모델 불러오기\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
